{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a78e7f1",
   "metadata": {},
   "source": [
    "# 吃蛋糕问题 II：数值方法\n",
    "\n",
    "```{contents} 目录\n",
    ":depth: 2\n",
    "```\n",
    "\n",
    "## 概述\n",
    "\n",
    "在本讲中，我们将继续研究{doc}`吃蛋糕问题 <cake_eating_problem>`。\n",
    "\n",
    "本讲的目标是使用数值方法来求解该问题。\n",
    "\n",
    "这似乎没有必要，因为我们已经通过解析方法得到了最优策略。\n",
    "\n",
    "然而，吃蛋糕问题如果不加修改就过于简单，几乎没有实际用途。一旦我们对问题进行修改，求解就必须依赖数值方法。\n",
    "\n",
    "因此，现在引入数值方法并在这个简单问题上进行测试是有意义的。\n",
    "\n",
    "由于我们已经知道解析解，这将使我们能够评估不同数值方法的精确度。\n",
    "\n",
    "我们将使用以下导入："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76aff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "FONTPATH = \"fonts/SourceHanSerifSC-SemiBold.otf\"\n",
    "mpl.font_manager.fontManager.addfont(FONTPATH)\n",
    "plt.rcParams['font.family'] = ['Source Han Serif SC']\n",
    "\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize_scalar, bisect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63c67ee",
   "metadata": {},
   "source": [
    "## 回顾模型\n",
    "\n",
    "在开始之前，你可能想要{doc}`回顾一下细节 <cake_eating_problem>`。\n",
    "\n",
    "特别要回顾的是贝尔曼方程：\n",
    "\n",
    "```{math}\n",
    ":label: bellman-cen\n",
    "\n",
    "v(x) = \\max_{0\\leq c \\leq x} \\{u(c) + \\beta v(x-c)\\}\n",
    "\\quad \\text{对所有 } x \\geq 0.\n",
    "```\n",
    "\n",
    "其中 $u$ 是CRRA效用函数。\n",
    "\n",
    "价值函数和最优策略的解析解如下所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ed37c3",
   "metadata": {
    "load": "_static/lecture_specific/cake_eating_numerical/analytical.py"
   },
   "outputs": [],
   "source": [
    "def c_star(x, β, γ):\n",
    "\n",
    "    return (1 - β ** (1/γ)) * x\n",
    "\n",
    "\n",
    "def v_star(x, β, γ):\n",
    "\n",
    "    return (1 - β**(1 / γ))**(-γ) * (x**(1-γ) / (1-γ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fe80a1",
   "metadata": {},
   "source": [
    "我们的第一个目标是用数值方法再现这些解析解。\n",
    "\n",
    "## 价值函数迭代\n",
    "\n",
    "我们将采用的第一种方法是**价值函数迭代**。\n",
    "\n",
    "这是一种**逐次逼近**的方法，在我们关于{doc}`工作搜寻的讲座 <mccall_model>`中已经讨论过。\n",
    "\n",
    "基本思路是：\n",
    "\n",
    "1. 取一个任意的初始猜测 $v$。\n",
    "1. 得到一个更新 $w$，其定义为\n",
    "\n",
    "   $$\n",
    "   w(x) = \\max_{0\\leq c \\leq x} \\{u(c) + \\beta v(x-c)\\}\n",
    "   $$\n",
    "\n",
    "1. 如果 $w$ 与 $v$ 大致相等，则停止；否则设 $v=w$ 并返回第2步。\n",
    "\n",
    "让我们把它写得更数学化一些。\n",
    "\n",
    "### 贝尔曼算子\n",
    "\n",
    "我们引入**贝尔曼算子** $T$，它以函数 $v$ 为输入，返回一个新函数 $Tv$，定义为\n",
    "\n",
    "$$\n",
    "Tv(x) = \\max_{0 \\leq c \\leq x} \\{u(c) + \\beta v(x - c)\\}\n",
    "$$\n",
    "\n",
    "从 $v$ 出发，我们得到 $Tv$，再应用 $T$ 得到 $T^2 v := T(Tv)$，依此类推。\n",
    "\n",
    "这被称为从初始猜测 $v$ 出发，**迭代贝尔曼算子**。\n",
    "\n",
    "正如我们在后面的讲座中详细讨论的那样，可以使用巴纳赫收缩映射定理来证明函数序列 $T^n v$ 收敛到贝尔曼方程的解。\n",
    "\n",
    "### 拟合价值函数迭代\n",
    "\n",
    "消费 $c$ 和状态变量 $x$ 都是连续的。\n",
    "\n",
    "这在数值计算方面造成了一些复杂性。\n",
    "\n",
    "例如，我们需要存储每个函数 $T^n v$ 以计算下一个迭代值 $T^{n+1} v$。\n",
    "\n",
    "但这意味着我们必须在无限多个 $x$ 处存储 $T^n v(x)$，这通常是不可能的。\n",
    "\n",
    "为了解决这个问题，我们将使用拟合价值函数迭代，这在之前关于{doc}`工作搜寻的讲座 <mccall_fitted_vfi>`中已经讨论过。\n",
    "\n",
    "这个过程如下：\n",
    "\n",
    "1. 从一组值 $\\{ v_0, \\ldots, v_I \\}$ 开始，这些值表示初始函数 $v$ 在网格点$\\{ x_0, \\ldots, x_I \\}$ 上的值。\n",
    "1. 通过线性插值，在状态空间 $\\mathbb{R}_+$ 上建立函数 $\\hat{v}$。\n",
    "1. 通过反复求解贝尔曼方程中的最大化问题，获取并记录每个网格点 $x_i$ 上的值 $T \\hat v(x_i)$。\n",
    "1. 除非满足某个停止条件，否则设置 $\\{ v_0, \\ldots, v_I \\} = \\{ T \\hat v(x_0), \\ldots, T \\hat v(x_I) \\}$ 并返回步骤2。\n",
    "\n",
    "在步骤2中，我们将使用连续分段线性插值。\n",
    "\n",
    "### 实现\n",
    "\n",
    "下面的`maximize`函数是一个小型辅助函数，它将SciPy的最小化程序转换为一个最大化程序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089281c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximize(g, a, b, args):\n",
    "    \"\"\"\n",
    "    在区间[a, b]上最大化函数g。\n",
    "\n",
    "    我们利用了这样一个事实：在任意区间上，g 的最大值点，同时也是 -g 的最小值点。\n",
    "    参数元组 args 收集传递给 g 的额外参数。\n",
    "\n",
    "    返回最大值和最大值点。\n",
    "    \"\"\"\n",
    "\n",
    "    objective = lambda x: -g(x, *args)\n",
    "    result = minimize_scalar(objective, bounds=(a, b), method='bounded')\n",
    "    maximizer, maximum = result.x, -result.fun\n",
    "    return maximizer, maximum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f134779",
   "metadata": {},
   "source": [
    "我们将参数 $\\beta$ 和 $\\gamma$ 存储在一个名为 `CakeEating` 的类中。\n",
    "\n",
    "这个类还将提供一个名为 `state_action_value` 的方法。该方法用来返回在给定状态和函数 $v$ 的猜测下，某个消费选择的价值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd490f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CakeEating:\n",
    "\n",
    "    def __init__(self,\n",
    "                 β=0.96,           # 折现因子\n",
    "                 γ=1.5,            # 相对风险厌恶程度\n",
    "                 x_grid_min=1e-3,  # 为了数值稳定性排除零\n",
    "                 x_grid_max=2.5,   # 蛋糕大小\n",
    "                 x_grid_size=120):\n",
    "\n",
    "        self.β, self.γ = β, γ\n",
    "\n",
    "        # 设置网格\n",
    "        self.x_grid = np.linspace(x_grid_min, x_grid_max, x_grid_size)\n",
    "\n",
    "    # 效用函数\n",
    "    def u(self, c):\n",
    "\n",
    "        γ = self.γ\n",
    "\n",
    "        if γ == 1:\n",
    "            return np.log(c)\n",
    "        else:\n",
    "            return (c ** (1 - γ)) / (1 - γ)\n",
    "\n",
    "    # 效用函数的一阶导数\n",
    "    def u_prime(self, c):\n",
    "\n",
    "        return c ** (-self.γ)\n",
    "\n",
    "    def state_action_value(self, c, x, v_array):\n",
    "        \"\"\"\n",
    "        在给定 x 和 c 的情况下，贝尔曼方程右侧的值。\n",
    "        \"\"\"\n",
    "\n",
    "        u, β = self.u, self.β\n",
    "        v = lambda x: np.interp(x, self.x_grid, v_array)\n",
    "\n",
    "        return u(c) + β * v(x - c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e11cbf2",
   "metadata": {},
   "source": [
    "现在，我们定义贝尔曼算子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c072206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def T(v, ce):\n",
    "    \"\"\"\n",
    "    贝尔曼算子。更新价值函数的猜测。\n",
    "\n",
    "    * ce 是 CakeEating 类的一个实例\n",
    "    * v 是一个数组，表示对价值函数的猜测\n",
    "\n",
    "    \"\"\"\n",
    "    v_new = np.empty_like(v)\n",
    "\n",
    "    for i, x in enumerate(ce.x_grid):\n",
    "        # 在状态 x 下最大化贝尔曼方程的右侧\n",
    "        v_new[i] = maximize(ce.state_action_value, 1e-10, x, (x, v))[1]\n",
    "\n",
    "    return v_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5565ba",
   "metadata": {},
   "source": [
    "在定义了贝尔曼算子之后，我们就可以开始求解这个模型了。\n",
    "\n",
    "让我们先用默认参数创建一个`CakeEating`实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726a154c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce = CakeEating()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace4c894",
   "metadata": {},
   "source": [
    "现在让我们看看价值函数的迭代过程。\n",
    "\n",
    "我们从初始猜测 $v = u$开始，即对每个网格点$x$，$v(x) = u(x)$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea08709",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_grid = ce.x_grid\n",
    "v = ce.u(x_grid)       # 初始猜测\n",
    "n = 12                 # 迭代次数\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(x_grid, v, color=plt.cm.jet(0),\n",
    "        lw=2, alpha=0.6, label='初始猜测')\n",
    "\n",
    "for i in range(n):\n",
    "    v = T(v, ce)  # 应用贝尔曼算子\n",
    "    ax.plot(x_grid, v, color=plt.cm.jet(i / n), lw=2, alpha=0.6)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_ylabel('价值', fontsize=12)\n",
    "ax.set_xlabel('蛋糕大小 $x$', fontsize=12)\n",
    "ax.set_title('价值函数迭代')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fea8a9b",
   "metadata": {},
   "source": [
    "为了更系统地完成这项工作，我们引入一个名为`compute_value_function`的包装函数，该函数会一直迭代直到满足某些收敛条件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd02d92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_value_function(ce,\n",
    "                           tol=1e-4,\n",
    "                           max_iter=1000,\n",
    "                           verbose=True,\n",
    "                           print_skip=25):\n",
    "\n",
    "    # 设置循环\n",
    "    v = np.zeros(len(ce.x_grid)) # 初始猜测\n",
    "    i = 0\n",
    "    error = tol + 1\n",
    "\n",
    "    while i < max_iter and error > tol:\n",
    "        v_new = T(v, ce)\n",
    "\n",
    "        error = np.max(np.abs(v - v_new))\n",
    "        i += 1\n",
    "\n",
    "        if verbose and i % print_skip == 0:\n",
    "            print(f\"第 {i} 次迭代的误差是 {error}.\")\n",
    "\n",
    "        v = v_new\n",
    "\n",
    "    if error > tol:\n",
    "        print(\"未能收敛！\")\n",
    "    elif verbose:\n",
    "        print(f\"\\n在第 {i} 次迭代中收敛。\")\n",
    "\n",
    "    return v_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db8b69f",
   "metadata": {},
   "source": [
    "现在让我们调用它。注意，运行需要一点时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7845ddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = compute_value_function(ce)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ad48c8",
   "metadata": {},
   "source": [
    "现在我们可以绘图查看收敛后的价值函数是什么样子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490fc8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(x_grid, v, label='近似价值函数')\n",
    "ax.set_ylabel('$V(x)$', fontsize=12)\n",
    "ax.set_xlabel('$x$', fontsize=12)\n",
    "ax.set_title('价值函数')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fdc765",
   "metadata": {},
   "source": [
    "接下来让我们将其与解析解进行比较。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeec485",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_analytical = v_star(ce.x_grid, ce.β, ce.γ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90edbd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(x_grid, v_analytical, label='解析解')\n",
    "ax.plot(x_grid, v, label='数值解')\n",
    "ax.set_ylabel('$V(x)$', fontsize=12)\n",
    "ax.set_xlabel('$x$', fontsize=12)\n",
    "ax.legend()\n",
    "ax.set_title('解析解与数值解的价值函数对比')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ada902",
   "metadata": {},
   "source": [
    "对于较大的 $x$ 值,近似的质量相当好,但在下边界附近则要差一些。\n",
    "\n",
    "这是因为效用函数以及由此产生的价值函数在接近下边界时非常陡峭，因此难以逼近。\n",
    "\n",
    "### 策略函数\n",
    "\n",
    "下面我们看看如何用它来计算最优策略。\n",
    "\n",
    "在{doc}`吃蛋糕问题的第一讲 <cake_eating_problem>`中,最优消费策略被证明为\n",
    "\n",
    "$$\n",
    "\\sigma^*(x) = \\left(1-\\beta^{1/\\gamma} \\right) x\n",
    "$$\n",
    "\n",
    "让我们看看我们的数值结果是否能得到类似的形式。\n",
    "\n",
    "我们的数值策略将是在一系列 $x$ 点上计算\n",
    "\n",
    "$$\n",
    "\\sigma(x) = \\arg \\max_{0 \\leq c \\leq x} \\{u(c) + \\beta v(x - c)\\}\n",
    "$$\n",
    "\n",
    "然后进行插值。\n",
    "\n",
    "对于 $v$,我们将使用我们上面获得的近似价值函数。\n",
    "\n",
    "这是相关函数:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db47689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def σ(ce, v):\n",
    "    \"\"\"\n",
    "    最优策略函数。给定价值函数,\n",
    "    它找到每个状态下的最优消费。\n",
    "\n",
    "    * ce 是 CakeEating 的一个实例\n",
    "    * v 是一个价值函数数组\n",
    "\n",
    "    \"\"\"\n",
    "    c = np.empty_like(v)\n",
    "\n",
    "    for i in range(len(ce.x_grid)):\n",
    "        x = ce.x_grid[i]\n",
    "        # 在状态 x 下最大化贝尔曼方程的右侧\n",
    "        c[i] = maximize(ce.state_action_value, 1e-10, x, (x, v))[0]\n",
    "\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09af650d",
   "metadata": {},
   "source": [
    "现在让我们传入近似值函数并计算最优消费："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e199486",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = σ(ce, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa73a3d",
   "metadata": {},
   "source": [
    "(pol_an)=\n",
    "\n",
    "让我们将其与真实的解析解进行对比绘图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712189fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_analytical = c_star(ce.x_grid, ce.β, ce.γ)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(ce.x_grid, c_analytical, label='解析解')\n",
    "ax.plot(ce.x_grid, c, label='数值解')\n",
    "ax.set_ylabel(r'$\\sigma(x)$')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3a66c2",
   "metadata": {},
   "source": [
    "拟合效果还算合理，但并不完美。\n",
    "\n",
    "我们可以通过增加网格规模，或者在价值函数迭代过程中降低误差容忍度来改进它。\n",
    "\n",
    "然而，这两种方法都会导致更长的计算时间。\n",
    "\n",
    "另一种可能性是使用一种替代算法，它既有可能缩短计算时间，同时还能提高精确度。\n",
    "\n",
    "接下来我们将探讨这种方法。\n",
    "\n",
    "## 时间迭代\n",
    "\n",
    "现在我们来看另一种计算最优策略的方法。\n",
    "\n",
    "回忆一下，最优策略满足欧拉方程\n",
    "\n",
    "```{math}\n",
    ":label: euler-cen\n",
    "\n",
    "u' (\\sigma(x)) = \\beta u' ( \\sigma(x - \\sigma(x)))\n",
    "\\quad \\text{对所有 } x > 0\n",
    "```\n",
    "\n",
    "在计算上，我们可以从任意初始猜测 $\\sigma_0$ 开始，然后选择 $c$ 来求解\n",
    "\n",
    "$$\n",
    "u^{\\prime}( c ) = \\beta u^{\\prime} (\\sigma_0(x - c))\n",
    "$$\n",
    "\n",
    "在所有 $x > 0$ 上解得的 $c$ 就生成了一个 $x$ 的函数。\n",
    "\n",
    "我们称这个新函数为 $\\sigma_1$，并将它作为新的猜测，重复上述步骤。\n",
    "\n",
    "这被称为**时间迭代**。\n",
    "\n",
    "与值函数迭代一样，我们可以将更新步骤视为一个算子的作用，这次用 $K$ 表示。\n",
    "\n",
    "* 特别地，$K\\sigma$ 是使用刚才描述的程序从 $\\sigma$ 更新得到的策略。\n",
    "* 我们将在下面的练习中使用这个术语。\n",
    "\n",
    "相对于价值函数迭代，时间迭代的主要优势在于它在策略空间而不是价值函数空间中运算。\n",
    "\n",
    "这很有帮助，因为策略函数的曲率较小，因此更容易逼近。\n",
    "\n",
    "在练习中，你将被要求实现时间迭代，并与价值函数迭代进行比较。\n",
    "\n",
    "你会发现这种方法更快，也更精确。\n",
    "\n",
    "这是由于\n",
    "\n",
    "1. 刚才提到的曲率问题，以及\n",
    "1. 我们利用了更多的信息——在这里是一阶条件。\n",
    "\n",
    "## 练习\n",
    "\n",
    "```{exercise}\n",
    ":label: cen_ex1\n",
    "\n",
    "尝试如下对问题的修改：\n",
    "\n",
    "让蛋糕大小不再按照 $x_{t+1} = x_t - c_t$ 变化，而是按照\n",
    "\n",
    "$$\n",
    "x_{t+1} = (x_t - c_t)^{\\alpha}\n",
    "$$\n",
    "\n",
    "变化，其中 $\\alpha$ 是一个满足 $0 < \\alpha < 1$ 的参数。\n",
    "\n",
    "(我们在学习最优增长模型时会看到这种更新规则。)\n",
    "\n",
    "请对价值函数迭代代码进行相应修改，并绘制价值函数和策略函数。\n",
    "\n",
    "尽量重用已有代码。\n",
    "```\n",
    "\n",
    "```{solution-start} cen_ex1\n",
    ":class: dropdown\n",
    "```\n",
    "\n",
    "我们需要创建一个类来保存基本要素，并返回贝尔曼方程的右端。\n",
    "\n",
    "我们将使用[继承](https://developer.baidu.com/article/details/2837714)来最大化代码重用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de630c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimalGrowth(CakeEating):\n",
    "    \"\"\"\n",
    "    CakeEating的一个子类，添加了参数α并重写了\n",
    "    state_action_value方法。\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 β=0.96,           # 折现因子\n",
    "                 γ=1.5,            # 相对风险厌恶程度\n",
    "                 α=0.4,            # 生产力参数\n",
    "                 x_grid_min=1e-3,  # 为了数值稳定性排除零\n",
    "                 x_grid_max=2.5,   # 蛋糕大小\n",
    "                 x_grid_size=120):\n",
    "\n",
    "        self.α = α\n",
    "        CakeEating.__init__(self, β, γ, x_grid_min, x_grid_max, x_grid_size)\n",
    "\n",
    "    def state_action_value(self, c, x, v_array):\n",
    "        \"\"\"\n",
    "       在给定 x 和 c 的情况下，贝尔曼方程右侧的值。\n",
    "        \"\"\"\n",
    "\n",
    "        u, β, α = self.u, self.β, self.α\n",
    "        v = lambda x: np.interp(x, self.x_grid, v_array)\n",
    "\n",
    "        return u(c) + β * v((x - c)**α)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965d35eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "og = OptimalGrowth()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa3b808",
   "metadata": {},
   "source": [
    "以下是计算得到的价值函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38257b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = compute_value_function(og, verbose=False)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(x_grid, v, lw=2, alpha=0.6)\n",
    "ax.set_ylabel('价值', fontsize=12)\n",
    "ax.set_xlabel('状态 $x$', fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce3d766",
   "metadata": {},
   "source": [
    "下面是计算得到的策略函数，并与我们在标准吃蛋糕问题（$\\alpha = 1$）情况下推导出的解进行比较："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61259209",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_new = σ(og, v)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(ce.x_grid, c_analytical, label=r'$\\alpha=1$ 的解')\n",
    "ax.plot(ce.x_grid, c_new, label=fr'$\\alpha={og.α}$ 的解')\n",
    "\n",
    "ax.set_ylabel('消费', fontsize=12)\n",
    "ax.set_xlabel('$x$', fontsize=12)\n",
    "\n",
    "ax.legend(fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ba4f42",
   "metadata": {},
   "source": [
    "当 $\\alpha < 1$ 时，消费水平更高，因为对于较大的 $x$，储蓄的回报较低。\n",
    "\n",
    "```{solution-end}\n",
    "```\n",
    "\n",
    "\n",
    "```{exercise}\n",
    ":label: cen_ex2\n",
    "\n",
    "在原始设定下实现时间迭代(即,去掉上述练习中的修改)。\n",
    "```\n",
    "\n",
    "\n",
    "```{solution-start} cen_ex2\n",
    ":class: dropdown\n",
    "```\n",
    "\n",
    "下面是一种实现时间迭代的方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f2d613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def K(σ_array, ce):\n",
    "    \"\"\"\n",
    "    策略函数算子。给定策略函数,\n",
    "    使用欧拉方程更新最优消费。\n",
    "\n",
    "    * σ_array 是网格上策略函数值的数组\n",
    "    * ce 是 CakeEating 的一个实例\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    u_prime, β, x_grid = ce.u_prime, ce.β, ce.x_grid\n",
    "    σ_new = np.empty_like(σ_array)\n",
    "\n",
    "    σ = lambda x: np.interp(x, x_grid, σ_array)\n",
    "\n",
    "    def euler_diff(c, x):\n",
    "        return u_prime(c) - β * u_prime(σ(x - c))\n",
    "\n",
    "    for i, x in enumerate(x_grid):\n",
    "\n",
    "        # 单独处理小的 x --- 有助于数值稳定性\n",
    "        if x < 1e-12:\n",
    "            σ_new[i] = 0.0\n",
    "\n",
    "        # 处理其他 x\n",
    "        else:\n",
    "            σ_new[i] = bisect(euler_diff, 1e-10, x - 1e-10, x)\n",
    "\n",
    "    return σ_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a8d327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_euler_equation(ce,\n",
    "                           max_iter=500,\n",
    "                           tol=1e-5,\n",
    "                           verbose=True,\n",
    "                           print_skip=25):\n",
    "\n",
    "    x_grid = ce.x_grid\n",
    "\n",
    "    σ = np.copy(x_grid)        # 初始猜测\n",
    "\n",
    "    i = 0\n",
    "    error = tol + 1\n",
    "    while i < max_iter and error > tol:\n",
    "\n",
    "        σ_new = K(σ, ce)\n",
    "\n",
    "        error = np.max(np.abs(σ_new - σ))\n",
    "        i += 1\n",
    "\n",
    "        if verbose and i % print_skip == 0:\n",
    "            print(f\"第 {i} 次迭代的误差是{error}。\")\n",
    "\n",
    "        σ = σ_new\n",
    "\n",
    "    if error > tol:\n",
    "        print(\"未能收敛！\")\n",
    "    elif verbose:\n",
    "        print(f\"\\n在 {i} 次迭代后收敛。\")\n",
    "\n",
    "    return σ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc7326a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce = CakeEating(x_grid_min=0.0)\n",
    "c_euler = iterate_euler_equation(ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb684a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(ce.x_grid, c_analytical, label='解析解')\n",
    "ax.plot(ce.x_grid, c_euler, label='时间迭代解')\n",
    "\n",
    "ax.set_ylabel('消费')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.legend(fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e785c8",
   "metadata": {},
   "source": [
    "```{solution-end}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   10,
   34,
   43,
   61,
   63,
   124,
   139,
   144,
   183,
   187,
   203,
   208,
   210,
   215,
   235,
   239,
   268,
   271,
   273,
   277,
   286,
   290,
   293,
   303,
   332,
   350,
   353,
   355,
   360,
   372,
   457,
   485,
   487,
   491,
   501,
   505,
   519,
   540,
   571,
   603,
   608,
   619
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}