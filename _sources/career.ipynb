{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "515a39cc",
   "metadata": {},
   "source": [
    "(career)=\n",
    "```{raw} jupyter\n",
    "<div id=\"qe-notebook-header\" align=\"right\" style=\"text-align:right;\">\n",
    "        <a href=\"https://quantecon.org/\" title=\"quantecon.org\">\n",
    "                <img style=\"width:250px;display:inline;\" width=\"250px\" src=\"https://assets.quantecon.org/img/qe-menubar-logo.svg\" alt=\"QuantEcon\">\n",
    "        </a>\n",
    "</div>\n",
    "```\n",
    "\n",
    "# 工作搜寻 V：职业选择建模\n",
    "\n",
    "```{index} single: Modeling; Career Choice\n",
    "```\n",
    "\n",
    "```{contents} 目录\n",
    ":depth: 2\n",
    "```\n",
    "\n",
    "除了Anaconda中已有的库外，本讲座还需要以下库："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78602346",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install quantecon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9414cb03",
   "metadata": {},
   "source": [
    "## 概述\n",
    "\n",
    "接下来，我们研究一个关于职业和工作选择的计算问题。\n",
    "\n",
    "这个模型最初由Derek Neal提出{cite}`Neal1999`。\n",
    "\n",
    "本文的讲解借鉴了{cite}`Ljungqvist2012`第6.5节的内容。\n",
    "\n",
    "我们先导入一些包："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64dec4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "FONTPATH = \"fonts/SourceHanSerifSC-SemiBold.otf\"\n",
    "mpl.font_manager.fontManager.addfont(FONTPATH)\n",
    "plt.rcParams['font.family'] = ['Source Han Serif SC']\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (11, 5)  #set default figure size\n",
    "import numpy as np\n",
    "import quantecon as qe\n",
    "from numba import jit, prange\n",
    "from quantecon.distributions import BetaBinomial\n",
    "from scipy.special import binom, beta\n",
    "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9391b6",
   "metadata": {},
   "source": [
    "### 模型特点\n",
    "\n",
    "* 职业和职业内的工作都选择以最大化预期贴现工资流。\n",
    "* 具有两个状态变量的无限期动态规划。\n",
    "\n",
    "## 模型\n",
    "\n",
    "在下文中，我们区分职业和工作，其中\n",
    "\n",
    "* *职业*被理解为包含许多可能工作的一般领域，而\n",
    "* *工作*被理解为在特定公司的一个职位\n",
    "\n",
    "对于工人来说，工资可以分解为工作和职业的贡献\n",
    "\n",
    "* $w_t = \\theta_t + \\epsilon_t$，其中\n",
    "  * $\\theta_t$ 是在时间 t 职业的贡献\n",
    "  * $\\epsilon_t$ 是在时间 t 工作的贡献\n",
    "\n",
    "在时间 t 开始时，工人有以下选择\n",
    "\n",
    "* 保持当前的（职业，工作）组合 $(\\theta_t, \\epsilon_t)$\n",
    "  --- 以下简称为\"原地不动\"\n",
    "* 保持当前职业 $\\theta_t$ 但重新选择工作 $\\epsilon_t$\n",
    "  --- 以下简称为\"新工作\"\n",
    "* 同时重新选择职业 $\\theta_t$ 和工作 $\\epsilon_t$\n",
    "--- 以下简称\"新生活\"\n",
    "\n",
    "$\\theta$ 和 $\\epsilon$ 的抽取彼此独立，且与过去的值无关，其中：\n",
    "\n",
    "* $\\theta_t \\sim F$\n",
    "* $\\epsilon_t \\sim G$\n",
    "\n",
    "注意，工人没有保留工作但重新选择职业的选项 --- 开始新职业总是需要开始新工作。\n",
    "\n",
    "年轻工人的目标是最大化折现工资的预期总和\n",
    "\n",
    "```{math}\n",
    ":label: exw\n",
    "\n",
    "\\mathbb{E} \\sum_{t=0}^{\\infty} \\beta^t w_t\n",
    "```\n",
    "\n",
    "受限于上述选择限制。\n",
    "\n",
    "令 $v(\\theta, \\epsilon)$ 表示价值函数，即在给定初始状态 $(\\theta, \\epsilon)$ 的情况下，所有可行的（职业，工作）策略中 {eq}`exw` 的最大值。\n",
    "\n",
    "价值函数满足\n",
    "\n",
    "$$\n",
    "v(\\theta, \\epsilon) = \\max\\{I, II, III\\}\n",
    "$$\n",
    "\n",
    "其中\n",
    "\n",
    "```{math}\n",
    ":label: eyes\n",
    "\n",
    "\\begin{aligned}\n",
    "& I = \\theta + \\epsilon + \\beta v(\\theta, \\epsilon) \\\\\n",
    "& II = \\theta + \\int \\epsilon' G(d \\epsilon') + \\beta \\int v(\\theta, \\epsilon') G(d \\epsilon') \\nonumber \\\\\n",
    "& III = \\int \\theta' F(d \\theta') + \\int \\epsilon' G(d \\epsilon') + \\beta \\int \\int v(\\theta', \\epsilon') G(d \\epsilon') F(d \\theta') \\nonumber\n",
    "\\end{aligned}\n",
    "```\n",
    "\n",
    "显然 $I$、$II$ 和 $III$ 分别对应\"原地不动\"、\"新工作\"和\"新生活\"。\n",
    "\n",
    "### 参数化\n",
    "\n",
    "如同 {cite}`Ljungqvist2012` 第6.5节所述，我们将关注模型的离散版本，参数设置如下：\n",
    "\n",
    "* $\\theta$ 和 $\\epsilon$ 的取值都在集合 `np.linspace(0, B, grid_size)` 中 --- 在 $0$ 和 $B$ 之间（包含端点）的均匀网格点\n",
    "* `grid_size = 50`\n",
    "* `B = 5`\n",
    "* `β = 0.95`\n",
    "\n",
    "分布 $F$ 和 $G$ 是离散分布，从网格点 `np.linspace(0, B, grid_size)` 中生成抽样。\n",
    "\n",
    "Beta-二项分布族是一个非常有用的离散分布族，其概率质量函数为\n",
    "\n",
    "$$\n",
    "p(k \\,|\\, n, a, b)\n",
    "= {n \\choose k} \\frac{B(k + a, n - k + b)}{B(a, b)},\n",
    "\\qquad k = 0, \\ldots, n\n",
    "$$\n",
    "\n",
    "解释：\n",
    "* 从形状参数为$(a, b)$的Beta分布中抽取$q$\n",
    "* 进行$n$次独立的二项试验，每次试验的成功概率为$q$\n",
    "* $p(k \\,|\\, n, a, b)$是在这$n$次试验中获得$k$次成功的概率\n",
    "\n",
    "优良特性：\n",
    "\n",
    "* 非常灵活的分布类别，包括均匀分布、对称单峰分布等\n",
    "* 仅有三个参数\n",
    "\n",
    "下图展示了当$n=50$时，不同形状参数对概率质量函数的影响。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917c54cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_probs(n, a, b):\n",
    "    probs = np.zeros(n+1)\n",
    "    for k in range(n+1):\n",
    "        probs[k] = binom(n, k) * beta(k + a, n - k + b) / beta(a, b)\n",
    "    return probs\n",
    "\n",
    "n = 50\n",
    "a_vals = [0.5, 1, 100]\n",
    "b_vals = [0.5, 1, 100]\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for a, b in zip(a_vals, b_vals):\n",
    "    ab_label = f'$a = {a:.1f}$, $b = {b:.1f}$'\n",
    "    ax.plot(list(range(0, n+1)), gen_probs(n, a, b), '-o', label=ab_label)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc8315a",
   "metadata": {},
   "source": [
    "## 实现\n",
    "\n",
    "我们首先创建一个类 `CareerWorkerProblem`，它将保存模型的默认参数化和价值函数的初始猜测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073c2fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CareerWorkerProblem:\n",
    "\n",
    "    def __init__(self,\n",
    "                 B=5.0,          # 上界\n",
    "                 β=0.95,         # 贴现因子\n",
    "                 grid_size=50,   # 网格大小\n",
    "                 F_a=1,\n",
    "                 F_b=1,\n",
    "                 G_a=1,\n",
    "                 G_b=1):\n",
    "\n",
    "        self.β, self.grid_size, self.B = β, grid_size, B\n",
    "\n",
    "        self.θ = np.linspace(0, B, grid_size)     # θ值集合\n",
    "        self.ϵ = np.linspace(0, B, grid_size)     # ϵ值集合\n",
    "\n",
    "        self.F_probs = BetaBinomial(grid_size - 1, F_a, F_b).pdf()\n",
    "        self.G_probs = BetaBinomial(grid_size - 1, G_a, G_b).pdf()\n",
    "        self.F_mean = np.sum(self.θ * self.F_probs)\n",
    "        self.G_mean = np.sum(self.ϵ * self.G_probs)\n",
    "\n",
    "        # 存储这些参数用于str和repr方法\n",
    "        self._F_a, self._F_b = F_a, F_b\n",
    "        self._G_a, self._G_b = G_a, G_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712d3541",
   "metadata": {},
   "source": [
    "以下函数接收一个`CareerWorkerProblem`实例，并返回相应的贝尔曼算子$T$和贪婪策略函数。\n",
    "\n",
    "在此模型中，$T$由$Tv(\\theta, \\epsilon) = \\max\\{I, II, III\\}$定义，其中$I$、$II$和$III$如{eq}`eyes`所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09aa8ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def operator_factory(cw, parallel_flag=True):\n",
    "\n",
    "    \"\"\"\n",
    "    返回经过jit编译的贝尔曼算子和贪婪策略函数\n",
    "\n",
    "    cw是一个``CareerWorkerProblem``实例\n",
    "    \"\"\"\n",
    "\n",
    "    θ, ϵ, β = cw.θ, cw.ϵ, cw.β\n",
    "    F_probs, G_probs = cw.F_probs, cw.G_probs\n",
    "    F_mean, G_mean = cw.F_mean, cw.G_mean\n",
    "\n",
    "    @jit(parallel=parallel_flag)\n",
    "    def T(v):\n",
    "        \"贝尔曼算子\"\n",
    "\n",
    "        v_new = np.empty_like(v)\n",
    "\n",
    "        for i in prange(len(v)):\n",
    "            for j in prange(len(v)):\n",
    "                v1 = θ[i] + ϵ[j] + β * v[i, j]                    # 保持现状\n",
    "                v2 = θ[i] + G_mean + β * v[i, :] @ G_probs        # 新工作\n",
    "                v3 = G_mean + F_mean + β * F_probs @ v @ G_probs  # 新生活\n",
    "                v_new[i, j] = max(v1, v2, v3)\n",
    "\n",
    "        return v_new\n",
    "\n",
    "    @jit\n",
    "    def get_greedy(v):\n",
    "        \"计算v-贪婪策略\"\n",
    "\n",
    "        σ = np.empty(v.shape)\n",
    "\n",
    "        for i in range(len(v)):\n",
    "            for j in range(len(v)):\n",
    "                v1 = θ[i] + ϵ[j] + β * v[i, j]\n",
    "                v2 = θ[i] + G_mean + β * v[i, :] @ G_probs\n",
    "                v3 = G_mean + F_mean + β * F_probs @ v @ G_probs\n",
    "                if v1 > max(v2, v3):\n",
    "                    action = 1\n",
    "                elif v2 > max(v1, v3):\n",
    "                    action = 2\n",
    "                else:\n",
    "                    action = 3\n",
    "                σ[i, j] = action\n",
    "\n",
    "        return σ\n",
    "\n",
    "    return T, get_greedy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bcd50f",
   "metadata": {},
   "source": [
    "最后，`solve_model`将接收一个`CareerWorkerProblem`实例，并使用贝尔曼算子进行迭代，以找到贝尔曼方程的不动点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f81d10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_model(cw,\n",
    "                use_parallel=True,\n",
    "                tol=1e-4,\n",
    "                max_iter=1000,\n",
    "                verbose=True,\n",
    "                print_skip=25):\n",
    "\n",
    "    T, _ = operator_factory(cw, parallel_flag=use_parallel)\n",
    "\n",
    "    # 设置循环\n",
    "    v = np.full((cw.grid_size, cw.grid_size), 100.)  # 初始猜测\n",
    "    i = 0\n",
    "    error = tol + 1\n",
    "\n",
    "    while i < max_iter and error > tol:\n",
    "        v_new = T(v)\n",
    "        error = np.max(np.abs(v - v_new))\n",
    "        i += 1\n",
    "        if verbose and i % print_skip == 0:\n",
    "            print(f\"Error at iteration {i} is {error}.\")\n",
    "        v = v_new\n",
    "\n",
    "    if error > tol:\n",
    "        print(\"Failed to converge!\")\n",
    "\n",
    "    elif verbose:\n",
    "        print(f\"\\nConverged in {i} iterations.\")\n",
    "\n",
    "    return v_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bac6eba",
   "metadata": {},
   "source": [
    "这是模型的解决方案 -- 一个近似值函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f241424",
   "metadata": {},
   "outputs": [],
   "source": [
    "cw = CareerWorkerProblem()\n",
    "T, get_greedy = operator_factory(cw)\n",
    "v_star = solve_model(cw, verbose=False)\n",
    "greedy_star = get_greedy(v_star)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "tg, eg = np.meshgrid(cw.θ, cw.ϵ)\n",
    "ax.plot_surface(tg,\n",
    "                eg,\n",
    "                v_star.T,\n",
    "                cmap=cm.jet,\n",
    "                alpha=0.5,\n",
    "                linewidth=0.25)\n",
    "ax.set(xlabel='θ', ylabel='ϵ', zlim=(150, 200))\n",
    "ax.view_init(ax.elev, 225)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b5491c",
   "metadata": {},
   "source": [
    "这就是最优策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a256a4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "tg, eg = np.meshgrid(cw.θ, cw.ϵ)\n",
    "lvls = (0.5, 1.5, 2.5, 3.5)\n",
    "ax.contourf(tg, eg, greedy_star.T, levels=lvls, cmap=cm.winter, alpha=0.5)\n",
    "ax.contour(tg, eg, greedy_star.T, colors='k', levels=lvls, linewidths=2)\n",
    "ax.set(xlabel='θ', ylabel='ϵ')\n",
    "ax.text(1.8, 2.5, '新生活', fontsize=14)\n",
    "ax.text(4.5, 2.5, '新工作', fontsize=14, rotation='vertical')\n",
    "ax.text(4.0, 4.5, '维持现状', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942630a6",
   "metadata": {},
   "source": [
    "解释：\n",
    "\n",
    "* 如果工作和职业都很差或一般，工人会尝试新的工作和新的职业。\n",
    "* 如果职业足够好，工人会保持这个职业，并尝试新的工作直到找到一个足够好的工作。\n",
    "* 如果工作和职业都很好，工人会保持现状。\n",
    "\n",
    "注意，工人总是会保持一个足够好的职业，但不一定会保持即使是最高薪的工作。\n",
    "\n",
    "原因是高终身工资需要这两个变量都很大，而且\n",
    "工人不能在不换工作的情况下换职业。\n",
    "\n",
    "* 有时必须牺牲一个好工作来转向一个更好的职业。\n",
    "\n",
    "## 练习\n",
    "\n",
    "```{exercise-start}\n",
    ":label: career_ex1\n",
    "```\n",
    "\n",
    "使用 `CareerWorkerProblem` 类中的默认参数设置，\n",
    "当工人遵循最优策略时，生成并绘制 $\\theta$ 和 $\\epsilon$ 的典型样本路径。\n",
    "特别是，除了随机性之外，复现以下图形（其中横轴表示时间）\n",
    "\n",
    "```{figure} /_static/lecture_specific/career/career_solutions_ex1_py.png\n",
    "```\n",
    "\n",
    "```{hint}\n",
    ":class: dropdown\n",
    "要从分布$F$和$G$中生成抽样，请使用`quantecon.random.draw()`。\n",
    "```\n",
    "\n",
    "```{exercise-end}\n",
    "```\n",
    "\n",
    "\n",
    "```{solution-start} career_ex1\n",
    ":class: dropdown\n",
    "```\n",
    "\n",
    "模拟工作/职业路径。\n",
    "\n",
    "在阅读代码时，请注意`optimal_policy[i, j]` = 在$(\\theta_i, \\epsilon_j)$处的策略 = 1、2或3；分别表示'保持现状'、'新工作'和'新生活'。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc914e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "F = np.cumsum(cw.F_probs)\n",
    "G = np.cumsum(cw.G_probs)\n",
    "v_star = solve_model(cw, verbose=False)\n",
    "T, get_greedy = operator_factory(cw)\n",
    "greedy_star = get_greedy(v_star)\n",
    "\n",
    "def gen_path(optimal_policy, F, G, t=20):\n",
    "    i = j = 0\n",
    "    θ_index = []\n",
    "    ϵ_index = []\n",
    "    for t in range(t):\n",
    "        if optimal_policy[i, j] == 1:       # 保持现状\n",
    "            pass\n",
    "\n",
    "        elif greedy_star[i, j] == 2:     # 新工作\n",
    "            j = qe.random.draw(G)\n",
    "\n",
    "        else:                            # 新生活\n",
    "            i, j = qe.random.draw(F), qe.random.draw(G)\n",
    "        θ_index.append(i)\n",
    "        ϵ_index.append(j)\n",
    "    return cw.θ[θ_index], cw.ϵ[ϵ_index]\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 8))\n",
    "for ax in axes:\n",
    "    θ_path, ϵ_path = gen_path(greedy_star, F, G)\n",
    "    ax.plot(ϵ_path, label='ϵ')\n",
    "    ax.plot(θ_path, label='θ')\n",
    "    ax.set_ylim(0, 6)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb87937",
   "metadata": {},
   "source": [
    "```{solution-end}\n",
    "```\n",
    "\n",
    "```{exercise}\n",
    ":label: career_ex2\n",
    "\n",
    "现在让我们考虑从起点$(\\theta, \\epsilon) = (0, 0)$开始，工人需要多长时间才能找到一份永久性工作。\n",
    "\n",
    "换句话说，我们要研究这个随机变量的分布\n",
    "\n",
    "$$\n",
    "T^* := \\text{工人的工作不再改变的第一个时间点}\n",
    "$$\n",
    "\n",
    "显然，当且仅当$(\\theta_t, \\epsilon_t)$进入$(\\theta, \\epsilon)$空间的\"保持不变\"区域时，工人的工作才会变成永久性的。\n",
    "\n",
    "令$S$表示这个区域，$T^*$可以表示为在最优策略下首次到达$S$的时间：\n",
    "\n",
    "$$\n",
    "T^* := \\inf\\{t \\geq 0 \\,|\\, (\\theta_t, \\epsilon_t) \\in S\\}\n",
    "$$\n",
    "\n",
    "收集这个随机变量的25,000个样本并计算中位数（应该约为7）。\n",
    "\n",
    "用$\\beta=0.99$重复这个练习并解释变化。\n",
    "```\n",
    "\n",
    "```{solution-start} career_ex2\n",
    ":class: dropdown\n",
    "```\n",
    "\n",
    "原始参数下的中位数可以按如下方式计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649bdbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cw = CareerWorkerProblem()\n",
    "F = np.cumsum(cw.F_probs)\n",
    "G = np.cumsum(cw.G_probs)\n",
    "T, get_greedy = operator_factory(cw)\n",
    "v_star = solve_model(cw, verbose=False)\n",
    "greedy_star = get_greedy(v_star)\n",
    "\n",
    "@jit\n",
    "def passage_time(optimal_policy, F, G):\n",
    "    t = 0\n",
    "    i = j = 0\n",
    "    while True:\n",
    "        if optimal_policy[i, j] == 1:    # 保持不变\n",
    "            return t\n",
    "        elif optimal_policy[i, j] == 2:  # 新工作\n",
    "            j = qe.random.draw(G)\n",
    "        else:                            # 新生活\n",
    "            i, j  = qe.random.draw(F), qe.random.draw(G)\n",
    "        t += 1\n",
    "\n",
    "@jit(parallel=True)\n",
    "def median_time(optimal_policy, F, G, M=25000):\n",
    "    samples = np.empty(M)\n",
    "    for i in prange(M):\n",
    "        samples[i] = passage_time(optimal_policy, F, G)\n",
    "    return np.median(samples)\n",
    "\n",
    "median_time(greedy_star, F, G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cde514d",
   "metadata": {},
   "source": [
    "要计算中位数时使用 $\\beta=0.99$ 而不是默认值 $\\beta=0.95$，请将 `cw = CareerWorkerProblem()` 替换为 `cw = CareerWorkerProblem(β=0.99)`。\n",
    "\n",
    "这些中位数会受随机性影响，但应该分别约为7和14。\n",
    "\n",
    "不出所料，更有耐心的工人会等待更长时间才会安定在最终的工作岗位上。\n",
    "\n",
    "```{solution-end}\n",
    "```\n",
    "\n",
    "\n",
    "```{exercise}\n",
    ":label: career_ex3\n",
    "\n",
    "将参数设置为 `G_a = G_b = 100` 并生成一个新的最优策略图 -- 解释。\n",
    "```\n",
    "\n",
    "```{solution-start} career_ex3\n",
    ":class: dropdown\n",
    "```\n",
    "\n",
    "这是一个解决方案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3558876d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cw = CareerWorkerProblem(G_a=100, G_b=100)\n",
    "T, get_greedy = operator_factory(cw)\n",
    "v_star = solve_model(cw, verbose=False)\n",
    "greedy_star = get_greedy(v_star)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "tg, eg = np.meshgrid(cw.θ, cw.ϵ)\n",
    "lvls = (0.5, 1.5, 2.5, 3.5)\n",
    "ax.contourf(tg, eg, greedy_star.T, levels=lvls, cmap=cm.winter, alpha=0.5)\n",
    "ax.contour(tg, eg, greedy_star.T, colors='k', levels=lvls, linewidths=2)\n",
    "ax.set(xlabel='θ', ylabel='ϵ')\n",
    "ax.text(1.8, 2.5, '新生活', fontsize=14)\n",
    "ax.text(4.5, 1.5, '新工作', fontsize=14, rotation='vertical')\n",
    "ax.text(4.0, 4.5, '保持现状', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687d3ec4",
   "metadata": {},
   "source": [
    "在新图中，你可以看到工人选择留在原地的区域变大了，这是因为 $\\epsilon$ 的分布更加集中在均值附近，使得高薪工作的可能性降低了。\n",
    "\n",
    "```{solution-end}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   10,
   32,
   37,
   48,
   63,
   161,
   177,
   182,
   207,
   212,
   262,
   265,
   295,
   298,
   316,
   319,
   330,
   374,
   408,
   441,
   470,
   493,
   509
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}