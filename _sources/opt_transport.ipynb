{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13a12438",
   "metadata": {},
   "source": [
    "# 最优传输\n",
    "\n",
    "## 概述\n",
    "\n",
    "**运输**或**最优传输**问题之所以有趣，不仅是因为它有许多应用，还因为它在经济理论历史中扮演着重要角色。\n",
    "\n",
    "在本讲座中，我们将描述这个问题，说明{doc}`线性规划 <intro:lp_intro>`是解决它的关键工具，然后提供一些示例。\n",
    "\n",
    "我们将在后续讲座中提供其他应用。\n",
    "\n",
    "最优传输问题在早期关于线性规划的研究中就被研究过，例如在{cite}`DoSSo`中有总结。关于经济学应用的现代参考文献是{cite}`Galichon_2016`。\n",
    "\n",
    "下面，我们将展示如何使用几种线性规划的实现方法来解决最优传输问题，包括：\n",
    "\n",
    "1. 来自SciPy的求解器[linprog](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.linprog.html)，\n",
    "2. 来自QuantEcon的求解器[linprog_simplex](https://quanteconpy.readthedocs.io/en/latest/optimize/linprog_simplex.html)，以及\n",
    "3. [Python Optimal Transport](https://pythonot.github.io/) 包中的基于单纯形法的求解器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f836179",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: quantecon in /home/runner/miniconda3/envs/quantecon/lib/python3.13/site-packages (0.10.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting POT\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading pot-0.9.6.post1-cp313-cp313-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\r\n",
      "  Using cached torch-2.9.0-cp313-cp313-manylinux_2_28_x86_64.whl.metadata (30 kB)\r\n",
      "Requirement already satisfied: numba>=0.49.0 in /home/runner/miniconda3/envs/quantecon/lib/python3.13/site-packages (from quantecon) (0.61.0)\r\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/runner/miniconda3/envs/quantecon/lib/python3.13/site-packages (from quantecon) (2.1.3)\r\n",
      "Requirement already satisfied: requests in /home/runner/miniconda3/envs/quantecon/lib/python3.13/site-packages (from quantecon) (2.32.3)\r\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/runner/miniconda3/envs/quantecon/lib/python3.13/site-packages (from quantecon) (1.15.3)\r\n",
      "Requirement already satisfied: sympy in /home/runner/miniconda3/envs/quantecon/lib/python3.13/site-packages (from quantecon) (1.13.3)\r\n",
      "Requirement already satisfied: filelock in /home/runner/miniconda3/envs/quantecon/lib/python3.13/site-packages (from torch) (3.17.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/runner/miniconda3/envs/quantecon/lib/python3.13/site-packages (from torch) (4.12.2)\r\n",
      "Requirement already satisfied: setuptools in /home/runner/miniconda3/envs/quantecon/lib/python3.13/site-packages (from torch) (72.1.0)\r\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/runner/miniconda3/envs/quantecon/lib/python3.13/site-packages (from torch) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /home/runner/miniconda3/envs/quantecon/lib/python3.13/site-packages (from torch) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /home/runner/miniconda3/envs/quantecon/lib/python3.13/site-packages (from torch) (2025.3.2)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\r\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\r\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\r\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch)\r\n",
      "  Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)\r\n",
      "  Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\r\n",
      "  Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\r\n",
      "  Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\r\n",
      "  Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)\r\n",
      "  Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/runner/miniconda3/envs/quantecon/lib/python3.13/site-packages (from torch) (0.7.1)\r\n",
      "Collecting nvidia-nccl-cu12==2.27.5 (from torch)\r\n",
      "  Using cached nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\r\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/runner/miniconda3/envs/quantecon/lib/python3.13/site-packages (from torch) (3.3.20)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/runner/miniconda3/envs/quantecon/lib/python3.13/site-packages (from torch) (12.8.90)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/runner/miniconda3/envs/quantecon/lib/python3.13/site-packages (from torch) (12.8.93)\r\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\r\n",
      "  Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\r\n",
      "Requirement already satisfied: triton==3.5.0 in /home/runner/miniconda3/envs/quantecon/lib/python3.13/site-packages (from torch) (3.5.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /home/runner/miniconda3/envs/quantecon/lib/python3.13/site-packages (from numba>=0.49.0->quantecon) (0.44.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/runner/miniconda3/envs/quantecon/lib/python3.13/site-packages (from sympy->quantecon) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/runner/miniconda3/envs/quantecon/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/runner/miniconda3/envs/quantecon/lib/python3.13/site-packages (from requests->quantecon) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/runner/miniconda3/envs/quantecon/lib/python3.13/site-packages (from requests->quantecon) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/runner/miniconda3/envs/quantecon/lib/python3.13/site-packages (from requests->quantecon) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/runner/miniconda3/envs/quantecon/lib/python3.13/site-packages (from requests->quantecon) (2025.4.26)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading pot-0.9.6.post1-cp313-cp313-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (1.5 MB)\r\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hUsing cached torch-2.9.0-cp313-cp313-manylinux_2_28_x86_64.whl (899.8 MB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\r\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\r\n",
      "Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\r\n",
      "Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, POT, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch\r\n",
      "\u001b[?25l"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/13\u001b[0m [nvidia-nccl-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/13\u001b[0m [nvidia-nccl-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/13\u001b[0m [nvidia-nccl-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/13\u001b[0m [nvidia-nccl-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/13\u001b[0m [nvidia-nccl-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/13\u001b[0m [nvidia-nccl-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/13\u001b[0m [nvidia-nccl-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/13\u001b[0m [nvidia-nccl-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/13\u001b[0m [nvidia-nccl-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/13\u001b[0m [nvidia-nccl-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/13\u001b[0m [nvidia-nccl-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/13\u001b[0m [nvidia-nccl-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/13\u001b[0m [nvidia-nccl-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/13\u001b[0m [nvidia-nccl-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/13\u001b[0m [nvidia-nccl-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/13\u001b[0m [nvidia-nccl-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/13\u001b[0m [nvidia-nccl-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/13\u001b[0m [nvidia-nccl-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/13\u001b[0m [nvidia-nccl-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/13\u001b[0m [nvidia-nccl-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/13\u001b[0m [nvidia-nccl-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/13\u001b[0m [nvidia-nccl-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/13\u001b[0m [nvidia-nccl-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/13\u001b[0m [nvidia-nccl-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/13\u001b[0m [nvidia-nccl-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/13\u001b[0m [nvidia-nccl-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/13\u001b[0m [nvidia-cusparse-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/13\u001b[0m [nvidia-cusparse-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/13\u001b[0m [nvidia-cusparse-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/13\u001b[0m [nvidia-cusparse-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/13\u001b[0m [nvidia-cusparse-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/13\u001b[0m [nvidia-cusparse-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/13\u001b[0m [nvidia-cusparse-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/13\u001b[0m [nvidia-cusparse-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/13\u001b[0m [nvidia-cusparse-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/13\u001b[0m [nvidia-cusparse-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/13\u001b[0m [nvidia-cusparse-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/13\u001b[0m [nvidia-cusparse-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/13\u001b[0m [nvidia-cusparse-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/13\u001b[0m [nvidia-cusparse-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/13\u001b[0m [nvidia-cusparse-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/13\u001b[0m [nvidia-cusparse-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/13\u001b[0m [nvidia-cusparse-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/13\u001b[0m [nvidia-cusparse-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/13\u001b[0m [nvidia-cusparse-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/13\u001b[0m [nvidia-cusparse-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/13\u001b[0m [nvidia-curand-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/13\u001b[0m [nvidia-curand-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/13\u001b[0m [nvidia-curand-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/13\u001b[0m [nvidia-curand-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/13\u001b[0m [nvidia-curand-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/13\u001b[0m [nvidia-curand-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/13\u001b[0m [nvidia-curand-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/13\u001b[0m [nvidia-curand-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/13\u001b[0m [nvidia-curand-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/13\u001b[0m [nvidia-curand-cu12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/13\u001b[0m [nvidia-curand-cu12]\u001b[31mERROR: Could not install packages due to an OSError: [Errno 28] No space left on device\r\n",
      "\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/13\u001b[0m [nvidia-curand-cu12]\r\n",
      "\u001b[?25h\r",
      "\u001b[1A\u001b[2K"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade quantecon POT torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c500ad1e",
   "metadata": {},
   "source": [
    "让我们从一些导入语句开始。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39b9b316",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m linprog\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mquantecon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimize\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinprog_simplex\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m linprog_simplex\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mot\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m betabinom\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnetworkx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnx\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ot'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "FONTPATH = \"fonts/SourceHanSerifSC-SemiBold.otf\"\n",
    "mpl.font_manager.fontManager.addfont(FONTPATH)\n",
    "plt.rcParams['font.family'] = ['Source Han Serif SC']\n",
    "\n",
    "from scipy.optimize import linprog\n",
    "from quantecon.optimize.linprog_simplex import linprog_simplex\n",
    "import ot\n",
    "from scipy.stats import betabinom\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16a0a5b",
   "metadata": {},
   "source": [
    "## 最优运输问题\n",
    "\n",
    "假设有 $m$ 个工厂生产的商品必须运送到$n$个地点。\n",
    "\n",
    "令\n",
    "\n",
    "* $x_{ij}$ 表示从工厂 $i$ 运往地点 $j$ 的数量\n",
    "\n",
    "* $c_{ij}$ 表示从工厂 $i$ 运往地点 $j$ 每单位的运输成本\n",
    "\n",
    "* $p_i$ 表示工厂 $i$的产能，$q_j$ 表示地点 $j$ 所需的数量\n",
    "\n",
    "* $i = 1, 2, \\dots, m$ 且 $j = 1, 2, \\dots, n$\n",
    "\n",
    "规划者希望在以下约束条件下最小化总运输成本：\n",
    "\n",
    "* 从每个工厂运出的数量必须等于其产能\n",
    "\n",
    "* 运往每个地点的数量必须等于该地点所需的数量\n",
    "\n",
    "下图展示了当工厂和目标地点分布在平面上时的一种可视化表示。\n",
    "\n",
    "```{figure} /_static/lecture_specific/opt_transport/optimal_transport_splitting_experiment.png\n",
    "\n",
    "```\n",
    "\n",
    "图中顶点的大小与以下内容成正比：\n",
    "\n",
    "- 对于工厂来说，是产能，以及\n",
    "\n",
    "- 目标地点的需求量。\n",
    "\n",
    "箭头显示了一个可能的运输方案，该方案遵守上述约束条件。\n",
    "\n",
    "规划者的问题可以表示为以下约束最小化问题：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\min_{x_{ij}} \\ & \\sum_{i=1}^m \\sum_{j=1}^n c_{ij} x_{ij} \\\\\n",
    "    \\text{使得 } \\ & \\sum_{j=1}^n x_{ij} = p_i, & i = 1, 2, \\dots, m \\\\\n",
    "    & \\sum_{i=1}^m x_{ij} = q_j, & j = 1, 2, \\dots, n \\\\\n",
    "    & x_{ij} \\ge 0 \\\\\n",
    "\\end{aligned}\n",
    "$$ (plannerproblem)\n",
    "\n",
    "这是一个**最优运输问题**，包含：\n",
    "\n",
    "* $mn$ 个决策变量，即元素 $x_{ij}$，以及\n",
    "\n",
    "* $m+n$ 个约束条件。\n",
    "\n",
    "将所有 $j$ 的 $q_j$ 相加和所有 $i$ 的 $p_i$ 相加表明，所有工厂的总产能等于所有地点的总需求：\n",
    "\n",
    "$$\n",
    "    \\sum_{j=1}^n q_j\n",
    "    = \\sum_{j=1}^n \\sum_{i=1}^m x_{ij}\n",
    "    = \\sum_{i=1}^m \\sum_{j=1}^n x_{ij}\n",
    "    = \\sum_{i=1}^m p_i\n",
    "$$ (sumconstraints)\n",
    "\n",
    "{eq}`sumconstraints` 中这些约束的存在，将导致我们在下文要描述的完整约束集合中出现一个冗余。\n",
    "\n",
    "稍后会详细讨论这一点。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 线性规划方法\n",
    "\n",
    "在本节中，我们讨论使用标准线性规划求解器来求解最优传输问题。\n",
    "\n",
    "\n",
    "### 决策变量矩阵的向量化\n",
    "\n",
    "在问题 {eq}`plannerproblem` 中出现了决策变量 $x_{ij}$ 的*矩阵*。\n",
    "\n",
    "SciPy 函数 `linprog` 需要接收决策变量的*向量*。\n",
    "\n",
    "这种情况促使我们需要用决策变量的*向量*来重写我们的问题。\n",
    "\n",
    "令：\n",
    "\n",
    "* $X, C$ 是具有元素 $x_{ij}, c_{ij}$ 的 $m \\times n$ 矩阵，\n",
    "\n",
    "* $p$ 是具有元素 $p_i$ 的 $m$ 维向量，\n",
    "\n",
    "* $q$ 是具有元素 $q_j$ 的 $n$ 维向量。\n",
    "\n",
    "用 $\\mathbf{1}_n$ 表示 $n$ 维列向量 $(1, 1, \\dots, 1)'$，我们的问题现在可以简洁地表示为：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_{X} \\ & \\operatorname{tr} (C' X) \\\\\n",
    "    \\text{使得 } \\ & X \\ \\mathbf{1}_n = p \\\\\n",
    "    & X' \\ \\mathbf{1}_m = q \\\\\n",
    "    & X \\ge 0 \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "我们可以通过将矩阵 $X$ 的所有列堆叠成一个列向量来将其转换为向量。\n",
    "\n",
    "这种操作称为**向量化**，我们用$\\operatorname{vec}(X)$表示。\n",
    "\n",
    "同样，我们将矩阵 $C$ 转换为 $mn$ 维向量 $\\operatorname{vec}(C)$。\n",
    "\n",
    "目标函数可以表示为 $\\operatorname{vec}(C)$ 和 $\\operatorname{vec}(X)$ 的内积：\n",
    "\n",
    "$$\n",
    "    \\operatorname{vec}(C)' \\cdot \\operatorname{vec}(X).\n",
    "$$\n",
    "\n",
    "为了用 $\\operatorname{vec}(X)$ 表示约束条件，我们使用**克罗内克积**，用 $\\otimes$ 表示，定义如下。\n",
    "\n",
    "假设$A$是一个 $m \\times s$ 矩阵，其元素为 $(a_{ij})$，而 $B$ 是一个 $n \\times t$ 矩阵。\n",
    "\n",
    "以分块矩阵形式表示的**克罗内克积**是：\n",
    "\n",
    "$$\n",
    "    A \\otimes B =\n",
    "\\begin{pmatrix}\n",
    "    a_{11}B & a_{12}B & \\dots & a_{1s}B \\\\\n",
    "    a_{21}B & a_{22}B & \\dots & a_{2s}B \\\\\n",
    "      &   & \\vdots &   \\\\\n",
    "    a_{m1}B & a_{m2}B & \\dots & a_{ms}B \\\\\n",
    "    \\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "$A \\otimes B$ 是一个 $mn \\times st$ 矩阵。\n",
    "\n",
    "它具有这样的性质：对于任意 $m \\times n$ 矩阵 $X$\n",
    "\n",
    "$$\n",
    "    \\operatorname{vec}(A'XB) = (B' \\otimes A') \\operatorname{vec}(X).\n",
    "$$ (kroneckerprop)\n",
    "\n",
    "现在我们可以用 $\\operatorname{vec}(X)$ 来表示我们的约束条件。\n",
    "\n",
    "令 $A = \\mathbf{I}_m', B = \\mathbf{1}_n$。\n",
    "\n",
    "根据等式 {eq}`kroneckerprop`\n",
    "\n",
    "$$\n",
    "    X \\ \\mathbf{1}_n\n",
    "    = \\operatorname{vec}(X \\ \\mathbf{1}_n)\n",
    "    = \\operatorname{vec}(\\mathbf{I}_m X \\ \\mathbf{1}_n)\n",
    "    = (\\mathbf{1}_n' \\otimes \\mathbf{I}_m) \\operatorname{vec}(X).\n",
    "$$\n",
    "\n",
    "其中 $\\mathbf{I}_m$ 表示 $m \\times m$ 单位矩阵。\n",
    "\n",
    "约束条件 $X \\ \\mathbf{1}_n = p$ 现在可以写成：\n",
    "\n",
    "$$\n",
    "    (\\mathbf{1}_n' \\otimes \\mathbf{I}_m) \\operatorname{vec}(X) = p.\n",
    "$$\n",
    "\n",
    "类似地，约束条件 $X' \\ \\mathbf{1}_m = q$ 可以重写为：\n",
    "\n",
    "$$\n",
    "    (\\mathbf{I}_n \\otimes \\mathbf{1}_m') \\operatorname{vec}(X) = q.\n",
    "$$\n",
    "\n",
    "令 $z := \\operatorname{vec}(X)$，我们的问题现在可以用一个 $mn$ 维的决策变量向量来表示：\n",
    "\n",
    "$$\n",
    "    \\begin{aligned}\n",
    "        \\min_{z} \\ & \\operatorname{vec}(C)' z \\\\\n",
    "        \\text{使得 } \\ & A z = b \\\\\n",
    "        & z \\ge 0 \\\\\n",
    "    \\end{aligned}\n",
    "$$ (decisionvars)\n",
    "\n",
    "其中\n",
    "\n",
    "$$\n",
    "    A =\n",
    "    \\begin{pmatrix}\n",
    "        \\mathbf{1}_n' \\otimes \\mathbf{I}_m \\\\\n",
    "        \\mathbf{I}_n \\otimes \\mathbf{1}_m' \\\\\n",
    "    \\end{pmatrix}\n",
    "    \\quad \\text{和} \\quad\n",
    "    b = \\begin{pmatrix}\n",
    "            p \\\\\n",
    "            q \\\\\n",
    "        \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "### 应用实例\n",
    "\n",
    "\n",
    "我们现在提供一个采用 {eq}`decisionvars` 形式的例子，我们将使用 `linprog` 函数来求解。\n",
    "\n",
    "下表提供了需求向量 $q$、产能向量 $p$ 以及运输成本矩阵 $C$ 中各项 $c_{ij}$ 的数值。\n",
    "\n",
    "```{raw} html\n",
    "<table>\n",
    "    <tr>\n",
    "\t    <th> </th>\n",
    "        <th colspan=\"3\"><center>工厂</center></th>\n",
    "\t    <th rowspan=\"2\">需求量</th>\n",
    "\t</tr >\n",
    "    <tr>\n",
    "        <th> 地点 </th> <th>1</th> <th>2</th> <th>3</th>\n",
    "\t</tr>\n",
    "    <tr>\n",
    "\t    <td>1</td>  <td>10</td> <td>20</td> <td>30</td> <td>25</td>\n",
    "\t</tr>\n",
    "    <tr>\n",
    "\t    <td>2</td> <td>15</td> <td>40</td> <td>35</td> <td>115</td>\n",
    "\t</tr>\n",
    "    <tr>\n",
    "\t    <td>3</td> <td>20</td> <td>15</td> <td>40</td> <td>60</td>\n",
    "\t</tr>\n",
    "    <tr>\n",
    "\t    <td>4</td> <td>20</td> <td>30</td> <td>55</td> <td>30</td>\n",
    "\t</tr>\n",
    "    <tr>\n",
    "\t    <td>5</td> <td>40</td> <td>30</td> <td>25</td> <td>70</td>\n",
    "\t</tr>\n",
    "    <tr>\n",
    "\t    <td>产能</td> <td>50</td> <td>100</td> <td>150</td> <td>300</td>\n",
    "\t</tr>\n",
    "</table>\n",
    "```\n",
    "\n",
    "上表中的数字告诉我们设定 $m = 3$，$n = 5$，并构造以下对象：\n",
    "\n",
    "$$\n",
    "p = \\begin{pmatrix}\n",
    "        50 \\\\\n",
    "        100 \\\\\n",
    "        150\n",
    "    \\end{pmatrix},\n",
    "    \\quad\n",
    "    q =\n",
    "    \\begin{pmatrix}\n",
    "        25 \\\\\n",
    "        115 \\\\\n",
    "        60 \\\\\n",
    "30 \\\\\n",
    "        70\n",
    "    \\end{pmatrix}\n",
    "    \\quad \\text{和} \\quad\n",
    "    C =\n",
    "    \\begin{pmatrix}\n",
    "        10 &15 &20 &20 &40 \\\\\n",
    "        20 &40 &15 &30 &30 \\\\\n",
    "        30 &35 &40 &55 &25\n",
    "    \\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "让我们编写Python代码来设置问题并求解。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488b7979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义参数\n",
    "m = 3\n",
    "n = 5\n",
    "\n",
    "p = np.array([50, 100, 150])\n",
    "q = np.array([25, 115, 60, 30, 70])\n",
    "\n",
    "C = np.array([[10, 15, 20, 20, 40],\n",
    "              [20, 40, 15, 30, 30],\n",
    "              [30, 35, 40, 55, 25]])\n",
    "\n",
    "# 将矩阵C向量化\n",
    "C_vec = C.reshape((m*n, 1), order='F')\n",
    "\n",
    "# 通过克罗内克积构造矩阵A\n",
    "A1 = np.kron(np.ones((1, n)), np.identity(m))\n",
    "A2 = np.kron(np.identity(n), np.ones((1, m)))\n",
    "A = np.vstack([A1, A2])\n",
    "\n",
    "# 构造向量b\n",
    "b = np.hstack([p, q])\n",
    "\n",
    "# 求解原问题\n",
    "res = linprog(C_vec, A_eq=A, b_eq=b)\n",
    "\n",
    "# 打印结果\n",
    "print(\"消息:\", res.message)\n",
    "print(\"迭代次数:\", res.nit)\n",
    "print(\"目标函数值:\", res.fun)\n",
    "print(\"z:\", res.x)\n",
    "print(\"X:\", res.x.reshape((m,n), order='F'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b54f76",
   "metadata": {},
   "source": [
    "注意，在 `C_vec = C.reshape((m*n, 1), order='F')` 这一行中，我们谨慎地使用了选项 `order='F'` 来进行向量化。\n",
    "\n",
    "这与将矩阵 $C$ 转换为向量的方式一致，即将其所有列堆叠成一个列向量。\n",
    "\n",
    "这里的 `'F'` 代表\"Fortran\"，我们使用的是Fortran风格的列优先顺序。\n",
    "\n",
    "（关于使用Python默认的行优先顺序的另一种方法，请参见[Alfred Galichon的这个讲座](https://www.math-econ-code.org/dynamic-programming)。）\n",
    "\n",
    "**解释求解器的行为：**\n",
    "\n",
    "观察矩阵 $A$，我们可以看出它是不满秩的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c952dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.matrix_rank(A) < min(A.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4699c84",
   "metadata": {},
   "source": [
    "这表明该线性规划的设定中包含了一个或多个冗余约束。\n",
    "\n",
    "这里，冗余的来源是限制条件 {eq}`sumconstraints` 的结构。\n",
    "\n",
    "让我们通过打印出 $A$ 并仔细观察来进一步探讨这个问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef32d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be91bd0",
   "metadata": {},
   "source": [
    "$A$ 的奇异性反映了前三个约束和后五个约束都要求{eq}`sumconstraints`中表达的\"总需求等于总容量\"。\n",
    "\n",
    "这里有一个冗余的等式约束。\n",
    "\n",
    "下面我们去掉一个等式约束，只使用其中的7个。\n",
    "\n",
    "这样做之后，我们得到了相同的最小成本。\n",
    "\n",
    "然而，我们找到了一个不同的运输方案。\n",
    "\n",
    "虽然这是一个不同的方案，但它达到了相同的成本！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff82bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "linprog(C_vec, A_eq=A[:-1], b_eq=b[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a9a428",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time linprog(C_vec, A_eq=A[:-1], b_eq=b[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6638a3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time linprog(C_vec, A_eq=A, b_eq=b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ec8028",
   "metadata": {},
   "source": [
    "显然，处理去掉冗余约束的系统会稍微快一些。\n",
    "\n",
    "让我们再深入做些计算，以判断：我们出现**两个**不同的最优传输方案，是否是因为删去了一条冗余的等式约束所致。\n",
    "\n",
    "```{admonition} 提示\n",
    "事实将证明，删除冗余等式约束并不是真正重要的。\n",
    "```\n",
    "\n",
    "为了验证我们的提示，我们将简单地使用**所有**原始的等式约束（包括一个冗余约束），只是重新排列这些约束的顺序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b7b9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(m+n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca6fae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_found = []\n",
    "cost = []\n",
    "\n",
    "# 模拟1000次\n",
    "for i in range(1000):\n",
    "\n",
    "    np.random.shuffle(arr)\n",
    "    res_shuffle = linprog(C_vec, A_eq=A[arr], b_eq=b[arr])\n",
    "\n",
    "    # 如果找到新解\n",
    "    sol = tuple(res_shuffle.x)\n",
    "    if sol not in sol_found:\n",
    "        sol_found.append(sol)\n",
    "        cost.append(res_shuffle.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826ef818",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sol_found)):\n",
    "    print(f\"运输方案 {i}: \", sol_found[i])\n",
    "    print(f\"最小成本 {i}: \", cost[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3693d6",
   "metadata": {},
   "source": [
    "**啊哈！** 如你所见，在这种情况下，仅仅改变约束的顺序，就会显现出两个实现相同最小成本的最优传输方案。\n",
    "\n",
    "这就是我们之前计算出的两个方案。\n",
    "\n",
    "接下来，我们展示\"意外地\"省略第一个约束条件会得到我们最初计算的方案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b4bbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "linprog(C_vec, A_eq=A[1:], b_eq=b[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc61acd",
   "metadata": {},
   "source": [
    "把这个运输方案与下列结果对比："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a550d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b8186a",
   "metadata": {},
   "source": [
    "这里，矩阵 $X$ 中的各元素 $x_{ij}$ 表示从工厂 $i = 1, 2, 3$ **运往**地点 $j=1,2, \\ldots, 5$ 的运输量。\n",
    "\n",
    "向量 $z$ 显然等于 $\\operatorname{vec}(X)$。\n",
    "\n",
    "最优运输方案的最小成本由变量 $fun$ 给出。\n",
    "\n",
    "\n",
    "### 使用即时编译器\n",
    "\n",
    "我们也可以使用 QuantEcon 中的一个强大工具来求解最优运输问题，即 `quantecon.optimize.linprog_simplex`。\n",
    "\n",
    "虽然这个程序使用的是与 `scipy.optimize.linprog` 相同的单纯形算法，但通过使用 `numba` 库中的即时编译器，代码运行速度得到了加速。\n",
    "\n",
    "如你很快就会看到，使用 `scipy.optimize.linprog` 可以显著减少求解最优运输问题所需的时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40e8363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为 linprog_simplex 构造矩阵/向量\n",
    "c = C.flatten()\n",
    "\n",
    "# 等式约束\n",
    "A_eq = np.zeros((m+n, m*n))\n",
    "for i in range(m):\n",
    "    for j in range(n):\n",
    "        A_eq[i, i*n+j] = 1\n",
    "        A_eq[m+j, i*n+j] = 1\n",
    "\n",
    "b_eq = np.hstack([p, q])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e313b2",
   "metadata": {},
   "source": [
    "由于 `quantecon.optimize.linprog_simplex` 执行的是最大化而不是最小化运算，我们需要在向量 `c` 前加上负号。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6d717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_qe = linprog_simplex(-c, A_eq=A_eq, b_eq=b_eq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2085ef55",
   "metadata": {},
   "source": [
    "尽管这两个线性规划（LP）求解器采用的算法不同（HiGHS 与单纯形法），它们都应当能找到最优解。\n",
    "\n",
    "两个求得的解之所以不同，是因为最优解不唯一，但目标函数值相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7d640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(-res_qe.fun, res.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949d72ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_qe.x.reshape((m, n), order='C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09bc207",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.x.reshape((m, n), order='F')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3917e6b8",
   "metadata": {},
   "source": [
    "让我们比较一下 `scipy.optimize.linprog` 和 `quantecon.optimize.linprog_simplex` 的运行速度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c2af99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scipy.optimize.linprog\n",
    "%time res = linprog(C_vec, A_eq=A[:-1, :], b_eq=b[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f95af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantecon.optimize.linprog_simplex\n",
    "%time out = linprog_simplex(-c, A_eq=A_eq, b_eq=b_eq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad81412",
   "metadata": {},
   "source": [
    "如您所见，`quantecon.optimize.linprog_simplex` 的速度要快得多。\n",
    "\n",
    "(但请注意，SciPy 版本可能比 QuantEcon 版本更稳定，因为它经过了更长时间的广泛测试。)\n",
    "\n",
    "\n",
    "## 对偶问题\n",
    "\n",
    "设 $u, v$ 表示对偶决策变量的向量，其分量为 $(u_i), (v_j)$。\n",
    "\n",
    "**最小化**问题{eq}`plannerproblem`的**对偶**是以下**最大化**问题：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\max_{u_i, v_j} \\ & \\sum_{i=1}^m p_i u_i + \\sum_{j=1}^n q_j v_j \\\\\n",
    "\\text{使得 } \\ & u_i + v_j \\le c_{ij}, \\ i = 1, 2, \\dots, m;\\ j = 1, 2, \\dots, n \\\\\n",
    "\\end{aligned}\n",
    "$$ (dualproblem)\n",
    "\n",
    "对偶问题也是一个线性规划问题。\n",
    "\n",
    "它有 $m+n$ 个对偶变量和 $mn$ 个约束。\n",
    "\n",
    "**值**向量 $u$ 和 $v$ 分别附加到原问题的第一组和第二组约束上。\n",
    "\n",
    "因此，$u$ 附加到以下约束上：\n",
    "\n",
    "* $(\\mathbf{1}_n' \\otimes \\mathbf{I}_m) \\operatorname{vec}(X) = p$\n",
    "\n",
    "且 $v$ 与以下约束相关\n",
    "\n",
    "* $(\\mathbf{I}_n \\otimes \\mathbf{1}_m') \\operatorname{vec}(X) = q.$\n",
    "\n",
    "向量 $u$ 和 $v$ 的各个分量（每单位**价值**）即为这些约束右侧所出现数量的**影子价格**。\n",
    "\n",
    "我们可以将对偶问题写作\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\max_{u_i, v_j} \\ & p u + q v \\\\\n",
    "\\text{使得 } \\ & A' \\begin{pmatrix} u \\\\ v \\\\ \\end{pmatrix} = \\operatorname{vec}(C) \\\\\n",
    "\\end{aligned}\n",
    "$$ (dualproblem2)\n",
    "\n",
    "针对上面描述的同一个数值例子，我们来解它的对偶问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc2fde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 求解对偶问题\n",
    "res_dual = linprog(-b, A_ub=A.T, b_ub=C_vec,\n",
    "                   bounds=[(None, None)]*(m+n))\n",
    "\n",
    "# 输出结果\n",
    "print(\"消息：\", res_dual.message)\n",
    "print(\"迭代次数：\", res_dual.nit)\n",
    "print(\"目标函数值\", res_dual.fun)\n",
    "print(\"u:\", res_dual.x[:m])\n",
    "print(\"v:\", res_dual.x[-n:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b4a8fc",
   "metadata": {},
   "source": [
    "`quantecon.optimize.linprog_simplex`会在给出原问题解的同时计算并返回对偶变量。\n",
    "\n",
    "这些对偶变量（影子价格）可以直接从原问题的解中提取："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee7c903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linprog_simplex 会返回对偶变量\n",
    "print(\"来自linprog_simplex的对偶变量:\")\n",
    "print(\"u:\", -res_qe.lambd[:m])\n",
    "print(\"v:\", -res_qe.lambd[m:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6aa7c4",
   "metadata": {},
   "source": [
    "我们可以核对它们与SciPy得到的对偶解一致："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ad6960",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"来自SciPy linprog的对偶变量:\")\n",
    "print(\"u:\", res_dual.x[:m])\n",
    "print(\"v:\", res_dual.x[-n:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423ffd77",
   "metadata": {},
   "source": [
    "### 对偶问题的解释\n",
    "\n",
    "根据**强对偶性**（请参见此讲座\n",
    "{doc}`线性规划 <intro:lp_intro>`），我们知道：\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^m \\sum_{j=1}^n c_{ij} x_{ij}  = \\sum_{i=1}^m p_i u_i + \\sum_{j=1}^n q_j v_j\n",
    "$$\n",
    "\n",
    "工厂 $i$ 增加一个单位的产能，即 $p_i$，将导致运输成本增加 $u_i$。\n",
    "\n",
    "因此，$u_i$ 描述了**从**工厂 $i$ 运出一个单位的成本。\n",
    "\n",
    "我们称之为从工厂 $i$ 运出一个单位的出货成本。\n",
    "\n",
    "类似地，$v_j$ 是运送一个单位**到**地点 $j$ 的成本。\n",
    "\n",
    "我们称之为运送一个单位到地点 $j$ 的进货成本。\n",
    "\n",
    "强对偶性表明总运输成本等于总出货成本**加上**总进货成本。\n",
    "\n",
    "对于一个单位的产品，出货成本 $u_i$ **加上**进货成本 $v_j$ 应该等于运输成本$c_{ij}$，这是合理的。\n",
    "\n",
    "这种相等性由**互补松弛**条件保证，该条件规定当 $x_{ij} > 0$ 时，即当从工厂 $i$ 到地点 $j$ 有正向运输量时，必须满足 $u_i + v_j = c_{ij}$。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Python最优传输包\n",
    "\n",
    "有一个优秀的[Python包](https://pythonot.github.io/)专门用于最优传输，它简化了我们上面采取的一些步骤。\n",
    "\n",
    "特别是，这个包会在把数据交给线性规划求解器之前，先处理好向量化步骤。\n",
    "\n",
    "（话虽如此，上面关于向量化的讨论仍然很重要，因为我们想要了解其内部运作原理。）\n",
    "\n",
    "\n",
    "### 复现之前的结果\n",
    "\n",
    "下面这行代码使用线性规划解决了上面讨论的示例应用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c627284",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ot.emd(p, q, C)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65653b3",
   "metadata": {},
   "source": [
    "果然，我们得到了相同的解决方案和相同的成本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1055fd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cost = np.sum(X * C)\n",
    "total_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cad9b79",
   "metadata": {},
   "source": [
    "### 更大的应用\n",
    "\n",
    "现在让我们尝试在一个稍大一点的应用上使用相同的包。\n",
    "\n",
    "该应用与上面的解读相同，但我们还会为每个结点（即顶点）指定一个平面中的位置。\n",
    "\n",
    "这样就可以把得到的运输方案作为图中的边来绘制。\n",
    "\n",
    "下面这个类用以下信息来定义一个结点：\n",
    "\n",
    "* 它的位置 $(x, y) \\in \\mathbb R^2$，\n",
    "* 它的组别（工厂或地点，用`p`或`q`表示）以及\n",
    "* 它的质量（例如，$p_i$或$q_j$）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c991adfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "\n",
    "    def __init__(self, x, y, mass, group, name):\n",
    "\n",
    "        self.x, self.y = x, y\n",
    "        self.mass, self.group = mass, group\n",
    "        self.name = name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7410d625",
   "metadata": {},
   "source": [
    "接下来我们编写一个函数，重复调用上面的类来构建实例。\n",
    "\n",
    "它为创建的节点分配位置、质量和组别。\n",
    "\n",
    "位置是随机分配的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da511012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_nodes_of_one_type(group='p', n=100, seed=123):\n",
    "\n",
    "    nodes = []\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    for i in range(n):\n",
    "\n",
    "        if group == 'p':\n",
    "            m = 1/n\n",
    "            x = np.random.uniform(-2, 2)\n",
    "            y = np.random.uniform(-2, 2)\n",
    "        else:\n",
    "            m = betabinom.pmf(i, n-1, 2, 2)\n",
    "            x = 0.6 * np.random.uniform(-1.5, 1.5)\n",
    "            y = 0.6 * np.random.uniform(-1.5, 1.5)\n",
    "\n",
    "        name = group + str(i)\n",
    "        nodes.append(Node(x, y, m, group, name))\n",
    "\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a865cc12",
   "metadata": {},
   "source": [
    "现在我们构建两个节点列表，每个列表包含一种类型（工厂或地点）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c14546e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_p = 32\n",
    "n_q = 32\n",
    "p_list = build_nodes_of_one_type(group='p', n=n_p)\n",
    "q_list = build_nodes_of_one_type(group='q', n=n_q)\n",
    "\n",
    "p_probs = [p.mass for p in p_list]\n",
    "q_probs = [q.mass for q in q_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65557902",
   "metadata": {},
   "source": [
    "对于成本矩阵 $C$，我们使用每个工厂和地点之间的欧几里得距离。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6515ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.empty((n_p, n_q))\n",
    "for i in range(n_p):\n",
    "    for j in range(n_q):\n",
    "        x0, y0 = p_list[i].x, p_list[i].y\n",
    "        x1, y1 = q_list[j].x, q_list[j].y\n",
    "        c[i, j] = np.sqrt((x0-x1)**2 + (y0-y1)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85629bdb",
   "metadata": {},
   "source": [
    "现在我们准备应用求解器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a533f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time pi = ot.emd(p_probs, q_probs, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e0a73b",
   "metadata": {},
   "source": [
    "最后，让我们使用`networkx`来绘制结果。\n",
    "\n",
    "在下面的图中，\n",
    "\n",
    "* 节点大小与质量成正比\n",
    "* 当在最优运输方案下从 $i$ 到 $j$ 有正向转移时，会画出一个从 $i$ 到 $j$ 的边（箭头）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820335e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.DiGraph()\n",
    "g.add_nodes_from([p.name for p in p_list])\n",
    "g.add_nodes_from([q.name for q in q_list])\n",
    "\n",
    "for i in range(n_p):\n",
    "    for j in range(n_q):\n",
    "        if pi[i, j] > 0:\n",
    "            g.add_edge(p_list[i].name, q_list[j].name, weight=pi[i, j])\n",
    "\n",
    "node_pos_dict={}\n",
    "for p in p_list:\n",
    "    node_pos_dict[p.name] = (p.x, p.y)\n",
    "\n",
    "for q in q_list:\n",
    "    node_pos_dict[q.name] = (q.x, q.y)\n",
    "\n",
    "node_color_list = []\n",
    "node_size_list = []\n",
    "scale = 8_000\n",
    "for p in p_list:\n",
    "    node_color_list.append('blue')\n",
    "    node_size_list.append(p.mass * scale)\n",
    "for q in q_list:\n",
    "    node_color_list.append('red')\n",
    "    node_size_list.append(q.mass * scale)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 10))\n",
    "plt.axis('off')\n",
    "\n",
    "nx.draw_networkx_nodes(g,\n",
    "                       node_pos_dict,\n",
    "                       node_color=node_color_list,\n",
    "                       node_size=node_size_list,\n",
    "                       edgecolors='grey',\n",
    "                       linewidths=1,\n",
    "                       alpha=0.5,\n",
    "                       ax=ax)\n",
    "\n",
    "nx.draw_networkx_edges(g,\n",
    "                       node_pos_dict,\n",
    "                       arrows=True,\n",
    "                       connectionstyle='arc3,rad=0.1',\n",
    "                       alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cd1cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.14.4"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "source_map": [
   12,
   32,
   36,
   40,
   53,
   309,
   341,
   355,
   357,
   365,
   367,
   381,
   385,
   389,
   391,
   403,
   407,
   424,
   428,
   436,
   438,
   442,
   444,
   461,
   473,
   477,
   479,
   485,
   489,
   493,
   495,
   499,
   504,
   507,
   554,
   565,
   571,
   576,
   580,
   584,
   627,
   630,
   634,
   637,
   653,
   661,
   669,
   690,
   694,
   702,
   706,
   713,
   717,
   719,
   728,
   777
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}