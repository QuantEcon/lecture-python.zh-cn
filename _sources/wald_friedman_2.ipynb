{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d55b423",
   "metadata": {},
   "source": [
    "(wald_friedman_2)=\n",
    "```{raw} jupyter\n",
    "<div id=\"qe-notebook-header\" align=\"right\" style=\"text-align:right;\">\n",
    "        <a href=\"https://quantecon.org/\" title=\"quantecon.org\">\n",
    "                <img style=\"width:250px;display:inline;\" width=\"250px\" src=\"https://assets.quantecon.org/img/qe-menubar-logo.svg\" alt=\"QuantEcon\">\n",
    "        </a>\n",
    "</div>\n",
    "```\n",
    "\n",
    "# {index}`用贝叶斯方法解决弗里德曼和瓦尔德问题 <single: A Bayesian Formulation of Friedman and Wald's Problem>`\n",
    "\n",
    "```{index} single: Models; Sequential analysis\n",
    "```\n",
    "\n",
    "```{contents} 目录\n",
    ":depth: 2\n",
    "```\n",
    "\n",
    "## 概述\n",
    "\n",
    "本讲座重新审视了二战期间弗里德曼和W·艾伦·瓦利斯在哥伦比亚大学美国政府统计研究组担任分析师时面临的统计决策问题。\n",
    "\n",
    "在{doc}`之前的讲座<wald_friedman>`中，我们描述了亚伯拉罕·瓦尔德{cite}`Wald47`如何通过扩展频率论假设检验技术并将问题顺序化来解决这个问题。\n",
    "\n",
    "```{note}\n",
    "瓦尔德将问题顺序化的想法与理查德·贝尔曼在1950年代发展的**动态规划**建立了联系。\n",
    "```\n",
    "\n",
    "正如我们在{doc}`prob_matrix`和{doc}`prob_meaning`中所学到的，频率学派统计学家将概率分布视为从已知概率分布中进行大量独立同分布抽样时所构建的统计量的相对频率的度量。\n",
    "\n",
    "这个已知的概率分布就是他的\"假设\"。\n",
    "\n",
    "频率学派统计学家研究在该已知概率分布下统计量的分布\n",
    "\n",
    "* 当分布是参数化概率分布集合中的一个成员时，他的假设表现为特定的参数向量形式。\n",
    "* 这就是我们所说的频率学派统计学家\"以参数为条件\"的含义\n",
    "* 他将参数视为自然界已知但他本人未知的固定数值。\n",
    "* 统计学家通过构建与频率学派假设检验相关的第一类和第二类错误来应对他对这些参数的无知。\n",
    "\n",
    "在本讲中，我们通过将视角从{doc}`关于沃尔德序贯分析的讲座<wald_friedman>`中的\"客观\"频率学派观点转变为贝叶斯决策者的明确\"主观\"观点来重新构建弗里德曼和沃尔德的问题。贝叶斯决策者将参数视为不是固定数值，而是与他通过从联合分布中抽样可以观察到的随机变量共同分布的（隐藏）随机变量。\n",
    "\n",
    "为了形成联合分布，贝叶斯统计学家在频率派统计学家使用的条件分布基础上，补充了一个表示其个人主观意见的参数先验概率分布。\n",
    "\n",
    "这让贝叶斯统计学家能够计算出他需要的联合分布，从而计算他想要的条件分布。\n",
    "\n",
    "要按这种方式进行，我们需要赋予决策者以下条件：\n",
    "\n",
    "- 一个初始先验主观概率 $\\pi_{-1} \\in (0,1)$，表示自然界使用 $f_1$ 而不是 $f_0$ 生成 i.i.d. 序列 $\\{z_k\\}$ 的概率\n",
    "- 相信贝叶斯定律作为在观察到 $\\{z_k\\}$ 序列时修正其主观信念的方法\n",
    "- 一个损失函数，用于衡量决策者如何评估第一类和第二类错误\n",
    "\n",
    "在我们的{doc}`之前的频率派版本<wald_friedman>`中，主要涉及的概念有：\n",
    "\n",
    "- 第一类和第二类统计错误\n",
    "    - 第一类错误是指在原假设为真时拒绝它\n",
    "    - 第二类错误是指在原假设为假时接受它\n",
    "- Abraham Wald的**序贯概率比检验**\n",
    "- 统计检验的**检验力**\n",
    "- 统计检验的**临界区域**\n",
    "- **一致最优检验**\n",
    "\n",
    "在这个问题的贝叶斯重构讲座中，还包含以下额外概念：\n",
    "- 模型 $f_1$ 生成数据的初始先验概率 $\\pi_{-1}$\n",
    "- 贝叶斯定律\n",
    "\n",
    "- 模型 $f_1$ 生成数据的后验概率序列\n",
    "- 动态规划\n",
    "\n",
    "\n",
    "本讲座使用了在 {doc}`似然比过程<likelihood_ratio_process>`、{doc}`它们在贝叶斯学习中的作用<likelihood_bayes>` 和 {doc}`这个关于可交换性的讲座<exchangeable>` 中研究的概念。\n",
    "\n",
    "\n",
    "让我们从一些导入开始："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8122fae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mpl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m FONTPATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfonts/SourceHanSerifSC-SemiBold.otf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m mpl\u001b[38;5;241m.\u001b[39mfont_manager\u001b[38;5;241m.\u001b[39mfontManager\u001b[38;5;241m.\u001b[39maddfont(FONTPATH)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfont.family\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSource Han Serif SC\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m jit, prange, float64, int64\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mpl' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "FONTPATH = \"fonts/SourceHanSerifSC-SemiBold.otf\"\n",
    "mpl.font_manager.fontManager.addfont(FONTPATH)\n",
    "plt.rcParams['font.family'] = ['Source Han Serif SC']\n",
    "\n",
    "from numba import jit, prange, float64, int64\n",
    "from numba.experimental import jitclass\n",
    "from math import gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9930666",
   "metadata": {},
   "source": [
    "## 动态规划方法\n",
    "\n",
    "以下对问题的介绍主要遵循Dmitri Bertsekas在**动态规划与随机控制**{cite}`Bertsekas75`中的处理方式。\n",
    "\n",
    "决策者可以观察到一个随机变量$z$的一系列抽样。\n",
    "\n",
    "他（或她）想要知道是概率分布$f_0$还是$f_1$支配着$z$。\n",
    "\n",
    "在已知连续观察值是从分布$f_0$中抽取的条件下，这个随机变量序列是独立同分布的(IID)。\n",
    "\n",
    "在已知连续观察值是从分布$f_1$中抽取的条件下，这个随机变量序列也是独立同分布的(IID)。\n",
    "\n",
    "但观察者并不知道是哪个分布生成了这个序列。\n",
    "\n",
    "由[可交换性和贝叶斯更新](https://python.quantecon.org/exchangeable.html)中解释的原因，这意味着该序列不是IID的。\n",
    "\n",
    "观察者有需要学习的东西，即观察值是从$f_0$还是从$f_1$中抽取的。\n",
    "\n",
    "决策者想要确定是哪个分布在生成结果。\n",
    "\n",
    "我们采用贝叶斯方法。\n",
    "\n",
    "决策者从先验概率开始\n",
    "\n",
    "$$\n",
    "\\pi_{-1} =\n",
    "\\mathbb P \\{ f = f_1 \\mid \\textrm{ 无观察值} \\} \\in (0, 1)\n",
    "$$\n",
    "\n",
    "```{note}\n",
    "在{cite:t}`Bertsekas75`中，信念是与分布$f_0$相关联的，但在这里\n",
    "\n",
    "我们将信念与分布 $f_1$ 关联起来,以匹配{doc}`关于Wald序贯分析的讲座<wald_friedman>`中的讨论。\n",
    "```\n",
    "\n",
    "在观察到 $k+1$ 个观测值 $z_k, z_{k-1}, \\ldots, z_0$ 后,他将观测值由分布 $f_1$ 描述的个人概率更新为\n",
    "\n",
    "$$\n",
    "\\pi_k = \\mathbb P \\{ f = f_1 \\mid z_k, z_{k-1}, \\ldots, z_0 \\}\n",
    "$$\n",
    "\n",
    "这是通过应用贝叶斯定律递归计算的:\n",
    "\n",
    "$$\n",
    "\\pi_{k+1} = \\frac{ \\pi_k f_1(z_{k+1})}{ (1-\\pi_k) f_0(z_{k+1}) + \\pi_k f_1 (z_{k+1}) },\n",
    "\\quad k = -1, 0, 1, \\ldots\n",
    "$$\n",
    "\n",
    "在观察到 $z_k, z_{k-1}, \\ldots, z_0$ 后,决策者认为 $z_{k+1}$ 的概率分布为\n",
    "\n",
    "$$\n",
    "f_{{\\pi}_k} (v) = (1-\\pi_k) f_0(v) + \\pi_k f_1 (v) ,\n",
    "$$\n",
    "\n",
    "这是分布 $f_0$ 和 $f_1$ 的混合,其中 $f_1$ 的权重是 $f = f_1$ 的后验概率[^f1]。\n",
    "\n",
    "为了说明这样的分布,让我们检查一些beta分布的混合。\n",
    "\n",
    "参数为 $a$ 和 $b$ 的beta概率分布的密度函数是\n",
    "\n",
    "$$\n",
    "f(z; a, b) = \\frac{\\Gamma(a+b) z^{a-1} (1-z)^{b-1}}{\\Gamma(a) \\Gamma(b)}\n",
    "\\quad \\text{where} \\quad\n",
    "\\Gamma(t) := \\int_{0}^{\\infty} x^{t-1} e^{-x} dx\n",
    "$$\n",
    "\n",
    "下图的上面板显示了两个beta分布。\n",
    "\n",
    "下面板展示了这些分布的混合,使用了不同的混合概率 $\\pi_k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bd9695",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def p(x, a, b):\n",
    "    r = gamma(a + b) / (gamma(a) * gamma(b))\n",
    "    return r * x**(a-1) * (1 - x)**(b-1)\n",
    "\n",
    "f0 = lambda x: p(x, 1, 1)\n",
    "f1 = lambda x: p(x, 9, 9)\n",
    "grid = np.linspace(0, 1, 50)\n",
    "\n",
    "fig, axes = plt.subplots(2, figsize=(10, 8))\n",
    "\n",
    "axes[0].set_title(\"Original Distributions\")\n",
    "axes[0].plot(grid, f0(grid), lw=2, label=\"$f_0$\")\n",
    "axes[0].plot(grid, f1(grid), lw=2, label=\"$f_1$\")\n",
    "\n",
    "axes[1].set_title(\"Mixtures\")\n",
    "for π in 0.25, 0.5, 0.75:\n",
    "    y = (1 - π) * f0(grid) + π * f1(grid)\n",
    "    axes[1].plot(grid, y, lw=2, label=fr\"$\\pi_k$ = {π}\")\n",
    "\n",
    "for ax in axes:\n",
    "    ax.legend()\n",
    "    ax.set(xlabel=\"$z$ values\", ylabel=\"probability of $z_k$\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372763a6",
   "metadata": {},
   "source": [
    "### 损失和成本\n",
    "\n",
    "在观察到 $z_k, z_{k-1}, \\ldots, z_0$ 后，决策者可以在三种不同的行动中选择：\n",
    "\n",
    "- 他确定 $f = f_0$ 并不再抽取 $z$ 值\n",
    "- 他确定 $f = f_1$ 并不再抽取 $z$ 值\n",
    "- 他推迟现在做决定，转而选择抽取一个 $z_{k+1}$\n",
    "\n",
    "与这三种行动相关，决策者可能遭受三种损失：\n",
    "\n",
    "- 当实际上 $f=f_1$ 时，他决定 $f = f_0$ 会遭受损失 $L_0$\n",
    "- 当实际上 $f=f_0$ 时，他决定 $f = f_1$ 会遭受损失 $L_1$\n",
    "- 如果他推迟决定并选择再抽取一个 $z$，会产生成本 $c$\n",
    "\n",
    "### 关于第一类和第二类错误的说明\n",
    "\n",
    "如果我们将 $f=f_0$ 视为零假设，将 $f=f_1$ 视为备择假设，那么 $L_1$ 和 $L_0$ 是与两类统计错误相关的损失\n",
    "\n",
    "- 第一类错误是错误地拒绝了真实的零假设（\"假阳性\"）\n",
    "- 第二类错误是未能拒绝错误的零假设（\"假阴性\"）\n",
    "\n",
    "因此当我们将 $f=f_0$ 作为零假设时\n",
    "\n",
    "- 我们可以将 $L_1$ 视为与第一类错误相关的损失\n",
    "- 我们可以将 $L_0$ 视为与第二类错误相关的损失\n",
    "\n",
    "### 直观理解\n",
    "\n",
    "在继续之前，让我们试着猜测最优决策规则可能是什么样的。\n",
    "\n",
    "假设在某个时间点 $\\pi$ 接近于1。\n",
    "\n",
    "那么我们的先验信念和到目前为止的证据都强烈指向 $f = f_1$。\n",
    "\n",
    "另一方面，如果 $\\pi$ 接近于0，那么 $f = f_0$ 的可能性更大。\n",
    "\n",
    "最后，如果$\\pi$位于区间$[0, 1]$的中间，我们就会面临更多的不确定性。\n",
    "\n",
    "这种推理建议采用一个顺序决策规则，我们在下图中说明：\n",
    "\n",
    "```{figure} /_static/lecture_specific/wald_friedman_2/wald_dec_rule.png\n",
    "\n",
    "```\n",
    "\n",
    "正如我们将看到的，这确实是决策规则的正确形式。\n",
    "\n",
    "我们的问题是确定阈值$A, B$，这些阈值以某种方式依赖于上述参数。\n",
    "\n",
    "在这一点上，你可能想暂停一下，试着预测像$c$或$L_0$这样的参数对$A$或$B$的影响。\n",
    "\n",
    "### 贝尔曼方程\n",
    "\n",
    "让$J(\\pi)$表示当前信念为$\\pi$的决策者在最优选择下的总损失。\n",
    "\n",
    "**动态规划**原理告诉我们，最优损失函数$J$满足以下贝尔曼函数方程\n",
    "\n",
    "```{math}\n",
    ":label: new1\n",
    "\n",
    "J(\\pi) =\n",
    "    \\min\n",
    "    \\left\\{\n",
    "        \\underbrace{\\pi L_0}_{ \\text{接受 } f_0 } \\; , \\; \\underbrace{(1-\\pi) L_1}_{ \\text{接受 } f_1 } \\; , \\;\n",
    "        \\underbrace{c + \\mathbb E [ J (\\pi') ]}_{ \\text{再次抽样} }\n",
    "    \\right\\}\n",
    "```\n",
    "\n",
    "其中$\\pi'$是由贝叶斯法则定义的随机变量\n",
    "\n",
    "$$\n",
    "\\pi' = \\kappa(z', \\pi) = \\frac{ \\pi f_1(z')}{ (1-\\pi) f_0(z') + \\pi f_1 (z') }\n",
    "$$\n",
    "\n",
    "当$\\pi$固定且$z'$从当前最佳猜测分布$f$中抽取时，该分布定义为\n",
    "\n",
    "$$\n",
    "f_{\\pi}(v) = (1-\\pi) f_0(v) + \\pi f_1 (v)\n",
    "$$\n",
    "\n",
    "在贝尔曼方程中，最小化是针对三个行动：\n",
    "\n",
    "1. 接受假设 $f = f_0$\n",
    "1. 接受假设 $f = f_1$\n",
    "1. 推迟决定并再次抽样\n",
    "\n",
    "我们可以将贝尔曼方程表示为\n",
    "\n",
    "```{math}\n",
    ":label: optdec\n",
    "\n",
    "J(\\pi) =\n",
    "\\min \\left\\{ \\pi L_0, \\; (1-\\pi) L_1, \\; h(\\pi) \\right\\}\n",
    "```\n",
    "\n",
    "其中 $\\pi \\in [0,1]$ 且\n",
    "\n",
    "- $\\pi L_0$ 是接受 $f_0$ 的预期损失（即犯第II类错误的成本）。\n",
    "- $(1-\\pi) L_1$ 是接受 $f_1$ 的预期损失（即犯第I类错误的成本）。\n",
    "- $h(\\pi) :=  c + \\mathbb E [J(\\pi')]$；这是继续值；即与再抽取一个 $z$ 相关的预期成本。\n",
    "\n",
    "最优决策规则由两个数 $A, B \\in (0,1) \\times (0,1)$ 来表征，满足\n",
    "\n",
    "$$\n",
    "\\pi L_0 < \\min \\{ (1-\\pi) L_1, c + \\mathbb E [J(\\pi')] \\}  \\textrm { if } \\pi \\leq B\n",
    "$$\n",
    "\n",
    "和\n",
    "\n",
    "$$\n",
    "(1- \\pi) L_1 < \\min \\{ \\pi L_0,  c + \\mathbb E [J(\\pi')] \\} \\textrm { if } \\pi \\geq A\n",
    "$$\n",
    "\n",
    "则最优决策规则为\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\textrm { 接受 } f=f_1 \\textrm{ 如果 } \\pi \\geq A \\\\\n",
    "\\textrm { 接受 } f=f_0 \\textrm{ 如果 } \\pi \\leq B \\\\\n",
    "\\textrm { 再抽取一个 }  z \\textrm{ 如果 }  B < \\pi < A\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "我们的目标是计算成本函数 $J$ 以及相关的临界值 $A$ 和 $B$。\n",
    "\n",
    "为了使我们的计算更易于管理，我们可以使用 {eq}`optdec` 将继续成本 $h(\\pi)$ 写为\n",
    "\n",
    "```{math}\n",
    ":label: optdec2\n",
    "\n",
    "\\begin{aligned}\n",
    "h(\\pi) &= c + \\mathbb E [J(\\pi')] \\\\\n",
    "\n",
    "&= c + \\mathbb E_{\\pi'} \\min \\{ \\pi' L_0, (1 - \\pi') L_1, h(\\pi') \\} \\\\\n",
    "&= c + \\int \\min \\{ \\kappa(z', \\pi) L_0, (1 - \\kappa(z', \\pi) ) L_1, h(\\kappa(z', \\pi) ) \\} f_\\pi (z') dz'\n",
    "\\end{aligned}\n",
    "```\n",
    "\n",
    "等式\n",
    "\n",
    "```{math}\n",
    ":label: funceq\n",
    "\n",
    "h(\\pi) =\n",
    "c + \\int \\min \\{ \\kappa(z', \\pi) L_0, (1 - \\kappa(z', \\pi) ) L_1, h(\\kappa(z', \\pi) ) \\} f_\\pi (z') dz'\n",
    "```\n",
    "\n",
    "是一个未知函数 $h$ 的方程。\n",
    "\n",
    "```{note}\n",
    "这种方程被称为**泛函方程**。\n",
    "```\n",
    "\n",
    "使用延续成本的泛函方程 {eq}`funceq`，我们可以通过 {eq}`optdec` 的右侧推导出最优选择。\n",
    "\n",
    "这个泛函方程可以通过取一个初始猜测并迭代来找到不动点来求解。\n",
    "\n",
    "因此，我们用算子 $Q$ 进行迭代，其中\n",
    "\n",
    "$$\n",
    "Q h(\\pi) =\n",
    "c + \\int \\min \\{ \\kappa(z', \\pi) L_0, (1 - \\kappa(z', \\pi) ) L_1, h(\\kappa(z', \\pi) ) \\} f_\\pi (z') dz'\n",
    "$$\n",
    "\n",
    "## 实现\n",
    "\n",
    "首先，我们将构造一个 `jitclass` 来存储模型的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eb43c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_data = [('a0', float64),          # beta分布的参数\n",
    "           ('b0', float64),\n",
    "           ('a1', float64),\n",
    "           ('b1', float64),\n",
    "           ('c', float64),           # 另一次抽样的成本\n",
    "           ('π_grid_size', int64),\n",
    "           ('L0', float64),          # 当f1为真时选择f0的成本\n",
    "           ('L1', float64),          # 当f0为真时选择f1的成本\n",
    "           ('π_grid', float64[:]),\n",
    "           ('mc_size', int64),\n",
    "           ('z0', float64[:]),\n",
    "           ('z1', float64[:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ec9e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jitclass(wf_data)\n",
    "class WaldFriedman:\n",
    "\n",
    "    def __init__(self,\n",
    "                 c=1.25,\n",
    "                 a0=1,\n",
    "                 b0=1,\n",
    "                 a1=3,\n",
    "                 b1=1.2,\n",
    "                 L0=25,\n",
    "                 L1=25,\n",
    "                 π_grid_size=200,\n",
    "                 mc_size=1000):\n",
    "\n",
    "        self.a0, self.b0 = a0, b0\n",
    "        self.a1, self.b1 = a1, b1\n",
    "        self.c, self.π_grid_size = c, π_grid_size\n",
    "        self.L0, self.L1 = L0, L1\n",
    "        self.π_grid = np.linspace(0, 1, π_grid_size)\n",
    "        self.mc_size = mc_size\n",
    "\n",
    "        self.z0 = np.random.beta(a0, b0, mc_size)\n",
    "        self.z1 = np.random.beta(a1, b1, mc_size)\n",
    "\n",
    "    def f0(self, x):\n",
    "\n",
    "        return p(x, self.a0, self.b0)\n",
    "\n",
    "    def f1(self, x):\n",
    "\n",
    "        return p(x, self.a1, self.b1)\n",
    "\n",
    "    def f0_rvs(self):\n",
    "        return np.random.beta(self.a0, self.b0)\n",
    "\n",
    "    def f1_rvs(self):\n",
    "        return np.random.beta(self.a1, self.b1)\n",
    "\n",
    "    def κ(self, z, π):\n",
    "        \"\"\"\n",
    "        使用贝叶斯法则和当前观测值z更新π\n",
    "        \"\"\"\n",
    "\n",
    "        f0, f1 = self.f0, self.f1\n",
    "\n",
    "        π_f0, π_f1 = (1 - π) * f0(z), π * f1(z)\n",
    "        π_new = π_f1 / (π_f0 + π_f1)\n",
    "\n",
    "        return π_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30c3d89",
   "metadata": {},
   "source": [
    "如同{doc}`最优增长讲座 <optgrowth>`中所述，为了近似连续的值函数\n",
    "\n",
    "* 我们在有限的 $\\pi$ 值网格上进行迭代。\n",
    "* 当我们在网格点之间评估 $\\mathbb E[J(\\pi')]$ 时，我们使用线性插值。\n",
    "\n",
    "我们在下面定义算子函数 `Q`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac749c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True, parallel=True)\n",
    "def Q(h, wf):\n",
    "\n",
    "    c, π_grid = wf.c, wf.π_grid\n",
    "    L0, L1 = wf.L0, wf.L1\n",
    "    z0, z1 = wf.z0, wf.z1\n",
    "    mc_size = wf.mc_size\n",
    "\n",
    "    κ = wf.κ\n",
    "\n",
    "    h_new = np.empty_like(π_grid)\n",
    "    h_func = lambda p: np.interp(p, π_grid, h)\n",
    "\n",
    "    for i in prange(len(π_grid)):\n",
    "        π = π_grid[i]\n",
    "\n",
    "        # Find the expected value of J by integrating over z\n",
    "        integral_f0, integral_f1 = 0, 0\n",
    "        for m in range(mc_size):\n",
    "            π_0 = κ(z0[m], π)  # Draw z from f0 and update π\n",
    "            integral_f0 += min(π_0 * L0, (1 - π_0) * L1, h_func(π_0))\n",
    "\n",
    "            π_1 = κ(z1[m], π)  # Draw z from f1 and update π\n",
    "            integral_f1 += min(π_1 * L0, (1 - π_1) * L1, h_func(π_1))\n",
    "\n",
    "        integral = ((1 - π) * integral_f0 + π * integral_f1) / mc_size\n",
    "\n",
    "        h_new[i] = c + integral\n",
    "\n",
    "    return h_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a3083b",
   "metadata": {},
   "source": [
    "为了求解关键的函数方程，我们将使用`Q`进行迭代以找到不动点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df767f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def solve_model(wf, tol=1e-4, max_iter=1000):\n",
    "    \"\"\"\n",
    "    计算延续成本函数\n",
    "\n",
    "    * wf 是 WaldFriedman 的一个实例\n",
    "    \"\"\"\n",
    "\n",
    "    # 设置循环\n",
    "    h = np.zeros(len(wf.π_grid))\n",
    "    i = 0\n",
    "    error = tol + 1\n",
    "\n",
    "    while i < max_iter and error > tol:\n",
    "        h_new = Q(h, wf)\n",
    "        error = np.max(np.abs(h - h_new))\n",
    "        i += 1\n",
    "        h = h_new\n",
    "\n",
    "    if error > tol:\n",
    "        print(\"未能收敛！\")\n",
    "\n",
    "    return h_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5a060f",
   "metadata": {},
   "source": [
    "## 分析\n",
    "\n",
    "让我们检查结果。\n",
    "\n",
    "我们将使用默认参数化的分布，如下所示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1f26bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = WaldFriedman()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(wf.f0(wf.π_grid), label=\"$f_0$\")\n",
    "ax.plot(wf.f1(wf.π_grid), label=\"$f_1$\")\n",
    "ax.set(ylabel=\"$z_k$的概率\", xlabel=\"$z_k$\", title=\"分布\")\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971d05f7",
   "metadata": {},
   "source": [
    "### 成本函数\n",
    "\n",
    "为了求解模型，我们将调用我们的`solve_model`函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93e9f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_star = solve_model(wf)    # 求解模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0015b60c",
   "metadata": {},
   "source": [
    "我们还将设置一个函数来计算截断值 $A$ 和 $B$，并在成本函数图上绘制这些值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fc3c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def find_cutoff_rule(wf, h):\n",
    "\n",
    "    \"\"\"\n",
    "    该函数接收一个延续成本函数，并返回在继续采样和选择特定模型之间\n",
    "    转换的对应截断点\n",
    "    \"\"\"\n",
    "\n",
    "    π_grid = wf.π_grid\n",
    "    L0, L1 = wf.L0, wf.L1\n",
    "\n",
    "    # 在网格上所有点计算选择模型的成本\n",
    "    cost_f0 = π_grid * L0\n",
    "    cost_f1 = (1 - π_grid) * L1\n",
    "    \n",
    "    # 找到B: cost_f0 <= min(cost_f1, h)时最大的π\n",
    "    optimal_cost = np.minimum(np.minimum(cost_f0, cost_f1), h)\n",
    "    choose_f0 = (cost_f0 <= cost_f1) & (cost_f0 <= h)\n",
    "    \n",
    "    if np.any(choose_f0):\n",
    "        B = π_grid[choose_f0][-1]  # 我们选择f0的最后一点\n",
    "    else:\n",
    "        assert False, \"没有选择f0的点\"\n",
    "    \n",
    "    # 找到A: cost_f1 <= min(cost_f0, h)时最小的π\n",
    "    choose_f1 = (cost_f1 <= cost_f0) & (cost_f1 <= h)\n",
    "    \n",
    "    if np.any(choose_f1):\n",
    "        A = π_grid[choose_f1][0]  # 我们选择f1的第一点\n",
    "    else:\n",
    "        assert False, \"没有选择f1的点\"\n",
    "\n",
    "    return (B, A)\n",
    "\n",
    "B, A = find_cutoff_rule(wf, h_star)\n",
    "cost_L0 = wf.π_grid * wf.L0\n",
    "cost_L1 = (1 - wf.π_grid) * wf.L1\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.plot(wf.π_grid, h_star, label='再次采样')\n",
    "ax.plot(wf.π_grid, cost_L1, label='选择f1')\n",
    "ax.plot(wf.π_grid, cost_L0, label='选择f0')\n",
    "ax.plot(wf.π_grid,\n",
    "        np.amin(np.column_stack([h_star, cost_L0, cost_L1]),axis=1),\n",
    "        lw=15, alpha=0.1, color='b', label=r'$J(\\pi)$')\n",
    "\n",
    "ax.annotate(r\"$B$\", xy=(B + 0.01, 0.5), fontsize=14)\n",
    "ax.annotate(r\"$A$\", xy=(A + 0.01, 0.5), fontsize=14)\n",
    "\n",
    "plt.vlines(B, 0, (1 - B) * wf.L1, linestyle=\"--\")\n",
    "plt.vlines(A, 0, A * wf.L0, linestyle=\"--\")\n",
    "\n",
    "ax.set(xlim=(0, 1), ylim=(0, 0.5 * max(wf.L0, wf.L1)), ylabel=\"成本\",\n",
    "       xlabel=r\"$\\pi$\", title=r\"成本函数 $J(\\pi)$\")\n",
    "\n",
    "plt.legend(borderpad=1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7261053e",
   "metadata": {},
   "source": [
    "成本函数$J$在$\\pi \\leq B$时等于$\\pi L_0$，在$\\pi \\geq A$时等于$(1-\\pi) L_1$。\n",
    "\n",
    "成本函数$J(\\pi)$两个线性部分的斜率由$L_0$和$-L_1$决定。\n",
    "\n",
    "在内部区域，当分配给$f_1$的后验概率处于犹豫区间$\\pi \\in (B, A)$时，成本函数$J$是平滑的。\n",
    "\n",
    "决策者继续采样，直到他对模型$f_1$的概率低于$B$或高于$A$。\n",
    "\n",
    "### 模拟\n",
    "\n",
    "下图显示了决策过程的500次模拟结果。\n",
    "\n",
    "左图是**停止时间**的直方图，即做出决策所需的$z_k$抽样次数。\n",
    "\n",
    "平均抽样次数约为6.6。\n",
    "\n",
    "右图是在停止时间时正确决策的比例。\n",
    "\n",
    "在这种情况下，决策者80%的时间做出正确决策。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e9556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(wf, true_dist, h_star, π_0=0.5):\n",
    "\n",
    "    \"\"\"\n",
    "    该函数接受一个初始条件并进行模拟，直到停止(当做出决策时)\n",
    "    \"\"\"\n",
    "\n",
    "    f0, f1 = wf.f0, wf.f1\n",
    "    f0_rvs, f1_rvs = wf.f0_rvs, wf.f1_rvs\n",
    "    π_grid = wf.π_grid\n",
    "    κ = wf.κ\n",
    "\n",
    "    if true_dist == \"f0\":\n",
    "        f, f_rvs = wf.f0, wf.f0_rvs\n",
    "    elif true_dist == \"f1\":\n",
    "        f, f_rvs = wf.f1, wf.f1_rvs\n",
    "\n",
    "    # 找到截断点\n",
    "    B, A = find_cutoff_rule(wf, h_star)\n",
    "\n",
    "    # 初始化几个有用的变量\n",
    "    decision_made = False\n",
    "    π = π_0\n",
    "    t = 0\n",
    "\n",
    "    while decision_made is False:\n",
    "        z = f_rvs()\n",
    "        t = t + 1\n",
    "        π = κ(z, π)\n",
    "        if π < B:\n",
    "            decision_made = True\n",
    "            decision = 0\n",
    "        elif π > A:\n",
    "            decision_made = True\n",
    "            decision = 1\n",
    "\n",
    "    if true_dist == \"f0\":\n",
    "        if decision == 0:\n",
    "            correct = True\n",
    "        else:\n",
    "            correct = False\n",
    "\n",
    "    elif true_dist == \"f1\":\n",
    "        if decision == 1:\n",
    "            correct = True\n",
    "        else:\n",
    "            correct = False\n",
    "\n",
    "    return correct, π, t\n",
    "\n",
    "def stopping_dist(wf, h_star, ndraws=250, true_dist=\"f0\"):\n",
    "\n",
    "    \"\"\"\n",
    "    重复模拟以获得做出决策所需时间的分布以及正确决策的频率\n",
    "    \"\"\"\n",
    "\n",
    "    tdist = np.empty(ndraws, int)\n",
    "    cdist = np.empty(ndraws, bool)\n",
    "\n",
    "    for i in range(ndraws):\n",
    "        correct, π, t = simulate(wf, true_dist, h_star)\n",
    "        tdist[i] = t\n",
    "        cdist[i] = correct\n",
    "\n",
    "    return cdist, tdist\n",
    "\n",
    "def simulation_plot(wf):\n",
    "    h_star = solve_model(wf)\n",
    "    ndraws = 500\n",
    "    cdist, tdist = stopping_dist(wf, h_star, ndraws)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "    ax[0].hist(tdist, bins=np.max(tdist))\n",
    "    ax[0].set_title(f\"在{ndraws}次重复中的停止时间\")\n",
    "    ax[0].set(xlabel=\"时间\", ylabel=\"停止次数\")\n",
    "    ax[0].annotate(f\"平均值 = {np.mean(tdist)}\", xy=(max(tdist) / 2,\n",
    "                   max(np.histogram(tdist, bins=max(tdist))[0]) / 2))\n",
    "\n",
    "    ax[1].hist(cdist.astype(int), bins=2)\n",
    "    ax[1].set_title(f\"在{ndraws}次重复中的正确决策\")\n",
    "    ax[1].annotate(f\"正确率 = {np.mean(cdist)}\",\n",
    "                   xy=(0.05, ndraws / 2))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "simulation_plot(wf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f05cda",
   "metadata": {},
   "source": [
    "### 比较静态分析\n",
    "\n",
    "现在让我们来看下面这个练习。\n",
    "\n",
    "我们将获取额外观测值的成本提高一倍。\n",
    "\n",
    "在查看结果之前，请思考会发生什么：\n",
    "\n",
    "- 决策者的判断正确率会提高还是降低？\n",
    "- 他会更早还是更晚做出决定？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33262859",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = WaldFriedman(c=2.5)\n",
    "simulation_plot(wf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72567341",
   "metadata": {},
   "source": [
    "由于每次抽样成本的增加，决策者在做出决定前会减少抽样次数。\n",
    "\n",
    "因为他用更少的抽样来做决定，他的正确判断比例下降。\n",
    "\n",
    "当他对两个模型赋予相同权重时，这导致他的预期损失更高。\n",
    "\n",
    "为了便于比较静态分析，我们邀请您调整模型参数并研究：\n",
    "\n",
    "* 当我们增加分段线性近似中的网格点数量时，对不确定中间范围内价值函数平滑性的影响。\n",
    "* 不同成本参数 $L_0, L_1, c$、两个贝塔分布 $f_0$ 和 $f_1$ 的参数，以及用于价值函数分段连续近似的点数和线性函数数量 $m$ 的设置效果。\n",
    "* 从 $f_0$ 进行的各种模拟以及做出决定前等待时间的分布。\n",
    "* 相关的正确和错误决定的直方图。\n",
    "\n",
    "\n",
    "[^f1]: 决策者的行为就像他相信随机变量序列 $[z_{0}, z_{1}, \\ldots]$ 是*可交换的*。关于可交换性的讨论，请参见[可交换性和贝叶斯更新](https://python.quantecon.org/exchangeable.html)和\n",
    "{cite}`Kreps88`第11章。"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.17.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "source_map": [
   12,
   88,
   98,
   170,
   197,
   366,
   381,
   431,
   440,
   471,
   475,
   499,
   507,
   517,
   523,
   525,
   529,
   588,
   610,
   697,
   710,
   713
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}