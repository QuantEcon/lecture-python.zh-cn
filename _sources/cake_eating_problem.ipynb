{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c19cb385",
   "metadata": {},
   "source": [
    "# 吃蛋糕问题 I：最优储蓄导论\n",
    "\n",
    "```{contents} 目录\n",
    ":depth: 2\n",
    "```\n",
    "\n",
    "## 概述\n",
    "\n",
    "在本讲中，我们介绍一个简单的“吃蛋糕”问题。\n",
    "\n",
    "这里的跨期问题是：今天要享受多少，为未来留下多少？\n",
    "\n",
    "尽管这个主题听起来很平凡，但这种“当前效用与未来效用的权衡”正是许多储蓄与消费问题的核心。\n",
    "\n",
    "一旦我们在这个简单环境中掌握了相关思想，我们就会逐步把它们应用到更具挑战性——也更有用——的问题中。\n",
    "\n",
    "我们用来解决吃蛋糕问题的主要工具是动态规划。\n",
    "\n",
    "在阅读本讲之前，读者可能会发现复习以下讲座会有帮助：\n",
    "\n",
    "* {doc}`最短路径讲座 <intro:short_path>`\n",
    "* {doc}`基础McCall模型 <mccall_model>`\n",
    "* {doc}`带分离的McCall模型 <mccall_model_with_separation>`\n",
    "* {doc}`带分离和连续工资分布的McCall模型 <mccall_fitted_vfi>`\n",
    "\n",
    "在接下来的内容中，我们需要导入以下模块："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838f85d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "FONTPATH = \"fonts/SourceHanSerifSC-SemiBold.otf\"\n",
    "mpl.font_manager.fontManager.addfont(FONTPATH)\n",
    "plt.rcParams['font.family'] = ['Source Han Serif SC']\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758d5d44",
   "metadata": {},
   "source": [
    "## 模型\n",
    "\n",
    "我们考虑一个无限期的时间区间 $t=0, 1, 2, 3...$\n",
    "\n",
    "在 $t=0$ 时，决策者获得一个大小为 $\\bar x$ 的完整蛋糕。\n",
    "\n",
    "令 $x_t$ 表示每一期开始时的蛋糕大小。特别地，$x_0 = \\bar{x}$。\n",
    "\n",
    "我们选择在任何给定时期 $t$ 吃掉多少蛋糕。\n",
    "\n",
    "如果在第 $t$ 期选择消费 $c_t$ 单位的蛋糕，那么在第 $t+1$ 期剩余的蛋糕量为\n",
    "\n",
    "$$\n",
    "x_{t+1} = x_t - c_t\n",
    "$$\n",
    "\n",
    "消费数量为 $c$ 的蛋糕会带来当期效用 $u(c)$。\n",
    "\n",
    "我们采用CRRA效用函数\n",
    "\n",
    "```{math}\n",
    ":label: crra_utility\n",
    "\n",
    "u(c) = \\frac{c^{1-\\gamma}}{1-\\gamma} \\qquad (\\gamma \\gt 0, \\, \\gamma \\neq 1)\n",
    "```\n",
    "\n",
    "在 Python 中表示为："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e71168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def u(c, γ):\n",
    "\n",
    "    return c**(1 - γ) / (1 - γ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee016e66",
   "metadata": {},
   "source": [
    "未来的蛋糕消费效用按照折现因子 $\\beta \\in (0,1)$ 进行折现。\n",
    "\n",
    "具体来说，$t$ 期后的 $c$ 单位消费的现值是 $\\beta^t u(c)$。\n",
    "\n",
    "决策者的问题可以写作\n",
    "\n",
    "```{math}\n",
    ":label: cake_objective\n",
    "\n",
    "\\max_{\\{c_t\\}} \\sum_{t=0}^\\infty \\beta^t u(c_t)\n",
    "```\n",
    "\n",
    "约束条件为，对所有 $t$, \n",
    "\n",
    "```{math}\n",
    ":label: cake_feasible\n",
    "\n",
    "x_{t+1} = x_t - c_t\n",
    "\\quad \\text{和} \\quad\n",
    "0\\leq c_t\\leq x_t\n",
    "```\n",
    "\n",
    "一个满足{eq}`cake_feasible`的消费路径 ${c_t}$（其中 $x_0 = \\bar{x}$）被称为**可行的**。\n",
    "\n",
    "在这个问题中，以下术语是标准的：\n",
    "\n",
    "* $x_t$ 被称为**状态变量**\n",
    "* $c_t$ 被称为**控制变量**或**行动**\n",
    "* $\\beta$ 和 $\\gamma$ 是**参数**\n",
    "\n",
    "### 权衡\n",
    "\n",
    "吃蛋糕问题中的关键权衡是：\n",
    "\n",
    "* 推迟消费是有代价的，因为存在折现因子。\n",
    "* 但推迟部分消费也具有吸引力，因为效用函数 $u$ 是凹的。\n",
    "\n",
    "$u$ 的凹性意味着*消费平滑*，即将消费分散在不同时期，给消费者带来价值。\n",
    "\n",
    "这是因为凹性意味着边际效用递减——在同一时期内，每多消费一勺蛋糕所带来的效用增加会逐渐减少。\n",
    "\n",
    "### 直观理解\n",
    "\n",
    "上述推理表明，贴现因子 $\\beta$ 和曲率参数 $\\gamma$ 在决定消费率时将起到关键作用。\n",
    "\n",
    "我们可以合理猜测这些参数的影响：\n",
    "\n",
    "首先，较高的 $\\beta$ 意味着较少的折现，因此个体更有耐心，这应该会降低消费率。\n",
    "\n",
    "其次，较高的 $\\gamma$ 意味着边际效用 $u'(c) = c^{-\\gamma}$ 随着 $c$ 的增加下降得更快。这意味着会有更多的消费平滑，因此消费率会更低。\n",
    "\n",
    "总之，我们预期消费率会*随着这两个参数的增加而减少*。\n",
    "\n",
    "让我们看看这是否正确。\n",
    "\n",
    "## 价值函数\n",
    "\n",
    "我们动态规划处理的第一步是得到贝尔曼方程。\n",
    "\n",
    "下一步是使用它来计算解。\n",
    "\n",
    "### 贝尔曼方程\n",
    "\n",
    "为此，我们令 $v(x)$ 表示当剩余 $x$ 单位蛋糕时，从当前时刻起可获得的最大终身效用。\n",
    "\n",
    "即，\n",
    "\n",
    "```{math}\n",
    ":label: value_fun\n",
    "\n",
    "v(x) = \\max \\sum_{t=0}^{\\infty} \\beta^t u(c_t)\n",
    "```\n",
    "\n",
    "其中最大化是针对从 $x_0 = x$ 开始所有可行的路径 $\\{ c_t \\}$。\n",
    "\n",
    "此时，我们还没有 $v$ 的表达式，但我们仍然可以对它进行推断。\n",
    "\n",
    "例如，就像在{doc}`McCall模型<mccall_model>`中一样，价值函数将满足某种形式的*贝尔曼方程*。\n",
    "\n",
    "在当前情形下，该方程表明 $v$ 满足\n",
    "\n",
    "```{math}\n",
    ":label: bellman-cep\n",
    "\n",
    "v(x) = \\max_{0\\leq c \\leq x} \\{u(c) + \\beta v(x-c)\\}\n",
    "\\quad \\text{对任意给定的 } x \\geq 0.\n",
    "```\n",
    "\n",
    "这里的直观理解本质上与McCall模型相同。\n",
    "\n",
    "最优地选择 $c$ 意味着要在当前和未来回报之间进行权衡。\n",
    "\n",
    "选择 $c$ 带来的当前回报就是 $u(c)$。\n",
    "\n",
    "在当前蛋糕大小为 $x$ 的情况下，假设采取最优行为，从下一期开始计算的未来回报是 $v(x-c)$。\n",
    "\n",
    "经过适当的折现之后，这两项就是 {eq}`bellman-cep` 右边的两项。\n",
    "\n",
    "如果使用这种权衡策略最优地选择 $c$，那么我们就能从当前状态 $x$ 获得最大的终身回报。\n",
    "\n",
    "因此，正如我们声称的，$v(x)$ 等于 {eq}`bellman-cep` 的右边。\n",
    "\n",
    "### 一个解析解\n",
    "\n",
    "已经证明，当 $u$ 是 {eq}`crra_utility` 中的 CRRA 效用函数时，函数\n",
    "\n",
    "```{math}\n",
    ":label: crra_vstar\n",
    "\n",
    "v^*(x_t) = \\left( 1-\\beta^{1/\\gamma} \\right)^{-\\gamma}u(x_t)\n",
    "```\n",
    "\n",
    "是贝尔曼方程的解，因此等于价值函数。\n",
    "\n",
    "在下面的练习中，你需要验证这一点。\n",
    "\n",
    "解 {eq}`crra_vstar` 严重依赖于 CRRA 效用函数。\n",
    "\n",
    "事实上，如果我们不使用CRRA效用函数，通常就完全没有解析解。\n",
    "\n",
    "换句话说，在CRRA效用函数之外，我们知道价值函数仍然满足贝尔曼方程，但我们无法显式地写出它，作为状态变量和参数的函数。\n",
    "\n",
    "在那种情况下，我们会在需要时通过数值方法来处理。\n",
    "\n",
    "下面是价值函数的一个 Python 表示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f703e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def v_star(x, β, γ):\n",
    "\n",
    "    return (1 - β**(1 / γ))**(-γ) * u(x, γ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404c5d01",
   "metadata": {},
   "source": [
    "下面的图，展示了在固定参数下该函数的形状："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ca7e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "β, γ = 0.95, 1.2\n",
    "x_grid = np.linspace(0.1, 5, 100)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(x_grid, v_star(x_grid, β, γ), label='价值函数')\n",
    "\n",
    "ax.set_xlabel('$x$', fontsize=12)\n",
    "ax.legend(fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc194524",
   "metadata": {},
   "source": [
    "## 最优策略\n",
    "\n",
    "既然我们已经得到了价值函数，那么在每个状态下计算最优行动就很直接了。\n",
    "\n",
    "我们应该选择一个消费水平，使得贝尔曼方程{eq}`bellman-cep`的右侧最大化：\n",
    "\n",
    "$$\n",
    "c^* = \\arg \\max_{c} \\{u(c) + \\beta v(x - c)\\}\n",
    "$$\n",
    "\n",
    "我们可以将这个最优选择视为状态 $x$ 的函数，此时称之为**最优策略** (optimal policy)。\n",
    "\n",
    "我们用 $\\sigma^*$ 表示最优策略，因此\n",
    "\n",
    "$$\n",
    "\\sigma^*(x) := \\arg \\max_{c} \\{u(c) + \\beta v(x - c)\\}\n",
    "\\quad \\text{对所有 } x\n",
    "$$\n",
    "\n",
    "如果我们将价值函数的解析表达式{eq}`crra_vstar`代入右侧并计算最优值，可以得到\n",
    "\n",
    "```{math}\n",
    ":label: crra_opt_pol\n",
    "\n",
    "\\sigma^*(x) = \\left( 1-\\beta^{1/\\gamma} \\right) x\n",
    "```\n",
    "\n",
    "现在让我们回顾一下关于参数影响的直觉。\n",
    "\n",
    "我们之前猜测，消费率会随着这两个参数的增加而减少。\n",
    "\n",
    "从{eq}`crra_opt_pol`可以看出，事实确实如此。\n",
    "这里有一些图表来说明。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8508c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_star(x, β, γ):\n",
    "\n",
    "    return (1 - β ** (1/γ)) * x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59041cf",
   "metadata": {},
   "source": [
    "继续使用前面给定的参数 $\\beta$ 和 $\\gamma$，绘制出的图形如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e4426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_grid, c_star(x_grid, β, γ), label='默认参数')\n",
    "ax.plot(x_grid, c_star(x_grid, β + 0.02, γ), label=r'更高的$\\beta$')\n",
    "ax.plot(x_grid, c_star(x_grid, β, γ + 0.2), label=r'更高的$\\gamma$')\n",
    "ax.set_ylabel(r'$\\sigma(x)$')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20921b75",
   "metadata": {},
   "source": [
    "## 欧拉方程\n",
    "\n",
    "在上面的讨论中，我们已经在 CRRA 效用的情形下给出了吃蛋糕问题的完整解。\n",
    "\n",
    "事实上，还有另一种方法可以求解最优策略，即基于所谓的**欧拉方程**(Euler equation)。\n",
    "\n",
    "尽管我们已经得到了完整解，但现在正是研究欧拉方程的好时机。\n",
    "\n",
    "这是因为，对于更复杂的问题，这个方程能够提供一些通过其他方法难以获得的关键洞见。\n",
    "\n",
    "### 陈述和含义\n",
    "\n",
    "当前问题的欧拉方程可以表述为\n",
    "\n",
    "```{math}\n",
    ":label: euler-cep\n",
    "\n",
    "u^{\\prime} (c^*_{t})=\\beta u^{\\prime}(c^*_{t+1})\n",
    "```\n",
    "\n",
    "这是最优路径的必要条件。\n",
    "\n",
    "它表明，在最优路径上，经过适当折现之后，跨期边际收益是相等的。\n",
    "\n",
    "这很合理：最优性是通过平滑消费直到没有额外的边际收益为止得到的。\n",
    "\n",
    "我们也可以用策略函数来表述欧拉方程。\n",
    "**可行消费策略**是一个满足 $0 \\leq \\sigma(x) \\leq x$ 的映射 $x \\mapsto \\sigma(x)$。\n",
    "\n",
    "这里的约束条件表明，我们不能消费超过剩余蛋糕的数量。\n",
    "\n",
    "如果一个可行消费策略 $\\sigma$ 对于所有 $x > 0$ 满足以下条件，则称其**满足欧拉方程**：\n",
    "\n",
    "```{math}\n",
    ":label: euler_pol\n",
    "\n",
    "u^{\\prime}( \\sigma(x) )\n",
    "= \\beta u^{\\prime} (\\sigma(x - \\sigma(x)))\n",
    "```\n",
    "\n",
    "显然，{eq}`euler_pol`只是{eq}`euler-cep`的策略等价形式。\n",
    "\n",
    "事实证明，一个可行策略当且仅当满足欧拉方程时才是最优的。\n",
    "\n",
    "在练习中，你需要验证最优策略{eq}`crra_opt_pol`确实满足这个泛函方程。\n",
    "\n",
    "```{note}\n",
    "**泛函方程**是一个未知对象为函数的方程。\n",
    "```\n",
    "\n",
    "关于欧拉方程在更一般情况下充分性的证明，请参见{cite}`ma2020income`中的命题2.2。\n",
    "\n",
    "下面的论证将聚焦于必要性，解释为什么任何最优路径或最优策略都必须满足欧拉方程。S\n",
    "\n",
    "### 推导 I：扰动法\n",
    "\n",
    "我们把 $c$ 作为消费路径 $\\left\\{{c_t}\\right\\}_{t=0}^\\infty$ 的简写。\n",
    "\n",
    "整个吃蛋糕的最大化问题可以写作\n",
    "\n",
    "$$\n",
    "\\max_{c \\in F} U(c)\n",
    "\\quad \\text{ 其中 } U(c) := \\sum_{t=0}^\\infty \\beta^t u(c_t)\n",
    "$$\n",
    "\n",
    "其中 $F$ 是所有可行消费路径的集合。\n",
    "\n",
    "我们知道，可微函数在极大值点的梯度为零。\n",
    "\n",
    "因此最优路径 $c^* := \\{c^*_t\\}_{t=0}^\\infty$ 必须满足\n",
    "$U'(c^*) = 0$。\n",
    "\n",
    "```{note}\n",
    "如果你想确切了解导数 $U'(c^*)$ 是如何定义的，考虑到参自变量 $c^*$ 是一个无限长的向量，你可以从学习[加托导数](https://baike.baidu.com/item/%E5%8A%A0%E6%89%98%E5%AF%BC%E6%95%B0)开始。不过，下文并不假定需要这些知识。\n",
    "```\n",
    "\n",
    "换句话说，对于任何无穷小的（且可行的）偏离最优路径的扰动，$U$ 的变化率必须为零。\n",
    "\n",
    "因此，考虑这样一个可行的扰动：在 $t$ 期把消费减少为 $c_t^* - h$，并在下一期把消费增加为 $c_{t+1}^* + h$。\n",
    "\n",
    "在其他时期消费不发生变化。\n",
    "\n",
    "我们称这种扰动路径为 $c^h$。\n",
    "\n",
    "根据前面关于零梯度的论证，我们有\n",
    "\n",
    "$$\n",
    "\\lim_{h \\to 0} \\frac{U(c^h) - U(c^*)}{h} = U'(c^*) = 0\n",
    "$$\n",
    "\n",
    "注意到消费只在 $t$ 和 $t+1$ 时刻发生变化，上式可以写为\n",
    "\n",
    "$$\n",
    "\\lim_{h \\to 0}\n",
    "\\frac{\\beta^t u(c^*_t - h) + \\beta^{t+1} u(c^*_{t+1} + h)\n",
    "      - \\beta^t u(c^*_t) - \\beta^{t+1} u(c^*_{t+1}) }{h} = 0\n",
    "$$\n",
    "\n",
    "经过整理，相同的式子可以写作\n",
    "\n",
    "$$\n",
    "\\lim_{h \\to 0}\n",
    "    \\frac{u(c^*_t - h) - u(c^*_t) }{h}\n",
    "+ \\beta \\lim_{h \\to 0}\n",
    "    \\frac{ u(c^*_{t+1} + h) - u(c^*_{t+1}) }{h} = 0\n",
    "$$\n",
    "\n",
    "或者，取极限后得到\n",
    "\n",
    "$$\n",
    "- u'(c^*_t) + \\beta u'(c^*_{t+1}) = 0\n",
    "$$\n",
    "\n",
    "这就是欧拉方程。\n",
    "\n",
    "### 推导 II：使用贝尔曼方程\n",
    "\n",
    "另一种推导欧拉方程的方法是使用贝尔曼方程{eq}`bellman-cep`。\n",
    "\n",
    "对贝尔曼方程右侧关于 $c$ 求导并令其等于零，我们得到\n",
    "\n",
    "```{math}\n",
    ":label: bellman_FOC\n",
    "\n",
    "u^{\\prime}(c)=\\beta v^{\\prime}(x - c)\n",
    "```\n",
    "\n",
    "为了得到 $v^{\\prime}(x - c)$，我们设\n",
    "$g(c,x) = u(c) + \\beta v(x - c)$，这样，在最优消费选择下，\n",
    "\n",
    "```{math}\n",
    ":label: bellman_equality\n",
    "\n",
    "v(x) = g(c,x)\n",
    "```\n",
    "\n",
    "对等式两边求导，同时考虑到最优消费会依赖于 $x$，我们得到\n",
    "\n",
    "$$\n",
    "v' (x) =\n",
    "\\frac{\\partial }{\\partial c} g(c,x) \\frac{\\partial c}{\\partial x}\n",
    " + \\frac{\\partial }{\\partial x} g(c,x)\n",
    "$$\n",
    "\n",
    "当 $g(c,x)$ 在 $c$ 处取得最大值时，我们有 $\\frac{\\partial }{\\partial c} g(c,x) = 0$。\n",
    "\n",
    "因此导数简化为\n",
    "\n",
    "```{math}\n",
    ":label: bellman_envelope\n",
    "\n",
    "v' (x) =\n",
    "\\frac{\\partial g(c,x)}{\\partial x}\n",
    "= \\frac{\\partial }{\\partial x} \\beta v(x - c)\n",
    "= \\beta v^{\\prime}(x - c)\n",
    "```\n",
    "(这个推导是[包络定理](https://blog.csdn.net/qq_25018077/article/details/123295394)的一个例子。)\n",
    "\n",
    "结合{eq}`bellman_FOC`得到\n",
    "\n",
    "```{math}\n",
    ":label: bellman_v_prime\n",
    "\n",
    "u^{\\prime}(c) = v^{\\prime}(x)\n",
    "```\n",
    "\n",
    "因此，价值函数的导数等于边际效用。\n",
    "\n",
    "将这一事实与{eq}`bellman_envelope`结合，就可以得到欧拉方程。\n",
    "\n",
    "## 练习\n",
    "\n",
    "```{exercise}\n",
    ":label: cep_ex1\n",
    "\n",
    "如何得到{eq}`crra_vstar`和{eq}`crra_opt_pol`中给出的价值函数和最优策略的表达式？\n",
    "\n",
    "第一步是对消费策略的函数形式作一个猜测。\n",
    "\n",
    "假设我们不知道解，并从一个假设出发：最优策略是线性的。\n",
    "\n",
    "换句话说，我们猜测存在一个正的 $\\theta$，使得令使得对所有 $t$，设定$c_t^*=\\theta x_t$会产生一个最优路径。\n",
    "\n",
    "从这个猜想出发，尝试获得解 {eq}`crra_vstar` 和 {eq}`crra_opt_pol`。\n",
    "\n",
    "在此过程中，你需要使用价值函数的定义和贝尔曼方程。\n",
    "```\n",
    "\n",
    "```{solution} cep_ex1\n",
    ":class: dropdown\n",
    "\n",
    "我们从猜想 $c_t^*=\\theta x_t$ 开始，这会导致状态变量（蛋糕大小）的路径为\n",
    "\n",
    "$$\n",
    "x_{t+1}=x_t(1-\\theta)\n",
    "$$\n",
    "\n",
    "那么 $x_t = x_{0}(1-\\theta)^t$，因此\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "v(x_0)\n",
    "   & = \\sum_{t=0}^{\\infty} \\beta^t u(\\theta x_t)\\\\\n",
    "   & = \\sum_{t=0}^{\\infty} \\beta^t u(\\theta x_0 (1-\\theta)^t ) \\\\\n",
    "   & = \\sum_{t=0}^{\\infty} \\theta^{1-\\gamma} \\beta^t (1-\\theta)^{t(1-\\gamma)} u(x_0) \\\\\n",
    "   & = \\frac{\\theta^{1-\\gamma}}{1-\\beta(1-\\theta)^{1-\\gamma}}u(x_{0})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "从贝尔曼方程可得，\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    v(x) & = \\max_{0\\leq c\\leq x}\n",
    "        \\left\\{\n",
    "            u(c) +\n",
    "            \\beta\\frac{\\theta^{1-\\gamma}}{1-\\beta(1-\\theta)^{1-\\gamma}}\\cdot u(x-c)\n",
    "        \\right\\} \\\\\n",
    "& = \\max_{0\\leq c\\leq x}\n",
    "            \\left\\{\n",
    "                \\frac{c^{1-\\gamma}}{1-\\gamma} +\n",
    "                \\beta\\frac{\\theta^{1-\\gamma}}\n",
    "                {1-\\beta(1-\\theta)^{1-\\gamma}}\n",
    "                \\cdot\\frac{(x-c)^{1-\\gamma}}{1-\\gamma}\n",
    "            \\right\\}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "根据一阶条件，我们得到\n",
    "\n",
    "$$\n",
    "c^{-\\gamma} + \\beta\\frac{\\theta^{1-\\gamma}}{1-\\beta(1-\\theta)^{1-\\gamma}}\\cdot(x-c)^{-\\gamma}(-1) = 0\n",
    "$$\n",
    "\n",
    "或\n",
    "\n",
    "$$\n",
    "c^{-\\gamma} = \\beta\\frac{\\theta^{1-\\gamma}}{1-\\beta(1-\\theta)^{1-\\gamma}}\\cdot(x-c)^{-\\gamma}\n",
    "$$\n",
    "\n",
    "代入 $c = \\theta x$ 我们得到\n",
    "\n",
    "$$\n",
    "\\left(\\theta x\\right)^{-\\gamma} =  \\beta\\frac{\\theta^{1-\\gamma}}{1-\\beta(1-\\theta)^{1-\\gamma}}\\cdot(x(1-\\theta))^{-\n",
    "\\gamma}\n",
    "$$\n",
    "\n",
    "经过一些整理得到\n",
    "\n",
    "$$\n",
    "\\theta = 1-\\beta^{\\frac{1}{\\gamma}}\n",
    "$$\n",
    "\n",
    "这证实了我们之前得到的最优策略表达式：\n",
    "\n",
    "$$\n",
    "c_t^* = \\left(1-\\beta^{\\frac{1}{\\gamma}}\\right)x_t\n",
    "$$\n",
    "\n",
    "将 $\\theta$ 代入上面的价值函数得到\n",
    "\n",
    "$$\n",
    "v^*(x_t) = \\frac{\\left(1-\\beta^{\\frac{1}{\\gamma}}\\right)^{1-\\gamma}}\n",
    "{1-\\beta\\left(\\beta^{\\frac{{1-\\gamma}}{\\gamma}}\\right)} u(x_t) \\\\\n",
    "$$\n",
    "\n",
    "重新整理得到\n",
    "\n",
    "$$\n",
    "v^*(x_t) = \\left(1-\\beta^\\frac{1}{\\gamma}\\right)^{-\\gamma}u(x_t)\n",
    "$$\n",
    "\n",
    "我们的论述现已得到验证。\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   10,
   39,
   47,
   76,
   80,
   207,
   211,
   215,
   227,
   263,
   267,
   270,
   280
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}