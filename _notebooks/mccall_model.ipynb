{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a58b742",
   "metadata": {},
   "source": [
    "\n",
    "<a id='mccall'></a>\n",
    "<div id=\"qe-notebook-header\" align=\"right\" style=\"text-align:right;\">\n",
    "        <a href=\"https://quantecon.org/\" title=\"quantecon.org\">\n",
    "                <img style=\"width:250px;display:inline;\" width=\"250px\" src=\"https://assets.quantecon.org/img/qe-menubar-logo.svg\" alt=\"QuantEcon\">\n",
    "        </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f1f933",
   "metadata": {},
   "source": [
    "# 工作搜寻 I: McCall搜寻模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b9a0d4",
   "metadata": {},
   "source": [
    "## 目录\n",
    "\n",
    "- [工作搜寻 I: McCall搜寻模型](#工作搜寻-I:-McCall搜寻模型)  \n",
    "  - [概述](#概述)  \n",
    "  - [McCall模型](#McCall模型)  \n",
    "  - [计算最优策略：第一种方法](#计算最优策略：第一种方法)  \n",
    "  - [计算最优策略：方法二](#计算最优策略：方法二)  \n",
    "  - [练习](#练习)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7953cf",
   "metadata": {},
   "source": [
    "> “询问一个McCall劳动者就像与一个失业的朋友对话：‘也许你的期望值定得太高了’，或者’为什么你在找到新工作之前就辞掉了原来的工作？’这就是真正的社会科学：试图通过观察人们所处的情况、他们面临的选择、以及他们自己所认为的优缺点来建模，以理解人类行为。” – 小罗伯特·卢卡斯\n",
    "\n",
    "\n",
    "除了Anaconda中已有的内容外，本讲座还需要以下库："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77381602",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "!pip install quantecon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ec9f97",
   "metadata": {},
   "source": [
    "## 概述\n",
    "\n",
    "McCall 搜索模型 [[McCall, 1970](https://python.quantecon.org/zreferences.html#id202)] 帮助改变了经济学家思考劳动力市场的方式。\n",
    "\n",
    "为了阐明”非自愿”失业等概念，McCall 从以下因素建模了失业劳动者的决策问题：\n",
    "\n",
    "- 当前工资和可能的未来工资  \n",
    "- 耐心程度  \n",
    "- 失业补助  \n",
    "\n",
    "\n",
    "为了解决这个决策问题，McCall 使用了动态规划。\n",
    "\n",
    "在本讲中，我们将建立 McCall 的模型并使用动态规划来分析它。\n",
    "\n",
    "我们将看到，McCall 的模型不仅本身很有趣，而且是学习动态规划的绝佳载体。\n",
    "\n",
    "让我们从一些导入开始："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3c6b14",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "FONTPATH = \"fonts/SourceHanSerifSC-SemiBold.otf\"\n",
    "mpl.font_manager.fontManager.addfont(FONTPATH)\n",
    "plt.rcParams['font.family'] = ['Source Han Serif SC']\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (11, 5)  #设置默认图片尺寸\n",
    "import numpy as np\n",
    "from numba import jit, float64\n",
    "from numba.experimental import jitclass\n",
    "import quantecon as qe\n",
    "from quantecon.distributions import BetaBinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bddcf02",
   "metadata": {},
   "source": [
    "## McCall模型\n",
    "\n",
    "\n",
    "<a id='index-0'></a>\n",
    "一个失业者在每个时期都会收到一个工资为$ w_t $的工作机会。\n",
    "\n",
    "在本讲中，我们采用以下简单环境：\n",
    "\n",
    "- 工资序列$ \\{w_t\\}_{t \\geq 0} $是独立同分布的，其中$ q(w) $是在有限集合$ \\mathbb{W} $中观察到工资$ w $的概率。  \n",
    "- 失业者在$ t $期的开始观察到$ w_t $。  \n",
    "- 失业者知道$ \\{w_t\\} $是具有共同分布$ q $的独立同分布序列，并可以利用这一点计算期望值。  \n",
    "\n",
    "\n",
    "（在后续讲座中，我们将放宽这些假设。）\n",
    "\n",
    "在时间$ t $，失业者有两个选择：\n",
    "\n",
    "1. 接受工作机会，并以固定工资$ w_t $永久工作。  \n",
    "1. 拒绝工作机会，获得失业补助$ c $，并在下一期重新考虑。  \n",
    "\n",
    "\n",
    "假设失业者具有无限长的生命，其目标是最大化折现收益总和的期望值\n",
    "\n",
    "$$\n",
    "\\mathbb{E} \\sum_{t=0}^{\\infty} \\beta^t y_t\n",
    "$$\n",
    "\n",
    "常数$ \\beta $位于$ (0, 1) $之间，被称为**折现因子**。\n",
    "\n",
    "$ \\beta $ 越小，未来效用的折现值越高。\n",
    "\n",
    "变量 $ y_t $ 是收入，\n",
    "\n",
    "- 当就业时，它等于工资 $ w_t $  \n",
    "- 当失业时，它等于失业补助金 $ c $  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c044cc5a",
   "metadata": {},
   "source": [
    "### 权衡取舍\n",
    "\n",
    "劳动者面临一个权衡：\n",
    "\n",
    "- 等待太久以获得好的工作机会是有代价的，因为未来会被折现。  \n",
    "- 过早接受工作机会也是有代价的，因为将来可能会出现更好的机会。  \n",
    "\n",
    "\n",
    "为了在这种权衡中做出最优决策，我们使用动态规划。\n",
    "\n",
    "动态规划可以被视为一个两步骤的过程：\n",
    "\n",
    "1. 首先为”状态”赋值  \n",
    "1. 然后根据这些值推导出最优行动  \n",
    "\n",
    "\n",
    "我们将依次讨论这些步骤。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c2ea83",
   "metadata": {},
   "source": [
    "### 价值函数\n",
    "\n",
    "为了在当前和未来回报之间进行最优权衡，我们需要考虑两个方面：\n",
    "\n",
    "1. 不同选择带来的当前收益  \n",
    "1. 这些选择在下一期会导致的不同状态  \n",
    "\n",
    "\n",
    "为了权衡决策问题的这两个方面，我们需要给状态赋予*价值*。\n",
    "\n",
    "为此，让$ v^*(w) $表示当工资为$ w \\in \\mathbb{W} $时，一个失业劳动者在当前时期开始时的总生命周期*价值*。\n",
    "\n",
    "具体来说，我们考虑这样一种情况：一个失业者现在面临一个工资为 $ w $ 的工作机会。\n",
    "\n",
    "那么，$ v^*(w) $表示的是该失业者在当前和未来所有时间点做出*最优*决策时，目标函数[(43.1)](https://python.quantecon.org/mccall_model_with_separation.html#equation-objective)的价值。\n",
    "\n",
    "当然，计算$ v^*(w) $并不简单，因为我们还不知道哪些决策是最优的，哪些不是！\n",
    "\n",
    "但是可以将$ v^* $看作一个函数，它为每个可能的工资$ w $分配在持有该工作机会时可获得的最大终身价值。\n",
    "\n",
    "一个关键点是，这个函数$ v^* $必须满足以下递归关系： 对于 $ \\mathbb{W} $ 中的每一个可能的 $ w $，我们有\n",
    "\n",
    "\n",
    "<a id='equation-odu-pv'></a>\n",
    "$$\n",
    "v^*(w)\n",
    "= \\max \\left\\{\n",
    "        \\frac{w}{1 - \\beta}, \\, c + \\beta\n",
    "        \\sum_{w' \\in \\mathbb{W}} v^*(w') q (w')\n",
    "    \\right\\} \\tag{42.1}\n",
    "$$\n",
    "\n",
    "这个重要的方程是**贝尔曼方程**的一个版本，这个方程在经济动态学和其他涉及长期规划的领域中无处不在。\n",
    "\n",
    "其背后的直观理解如下：\n",
    "\n",
    "- max运算中的第一项是接受当前工作机会的终身收益，因为  \n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{w}{1 - \\beta} = w + \\beta w + \\beta^2 w + \\cdots\n",
    "$$\n",
    "\n",
    "- max运算中的第二项是**延续值**，即拒绝当前工作机会并在随后所有时期做出最优行为的终身收益。  \n",
    "\n",
    "\n",
    "通过从这两个选项中选择最优的一个，我们就能得到在当前工资报价 $ w $ 下的最大终身价值。\n",
    "\n",
    "而这恰恰就是 [(42.1)](#equation-odu-pv) 左边的 $ v^*(w) $。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd933e7",
   "metadata": {},
   "source": [
    "### 最优策略\n",
    "\n",
    "假设现在我们能够求解 [(42.1)](#equation-odu-pv) 得到未知函数 $ v^* $。\n",
    "\n",
    "一旦我们掌握了这个函数，我们就可以做出最优行为（即在接受和拒绝之间做出正确选择）。\n",
    "\n",
    "我们只需要在[(42.1)](#equation-odu-pv)的右侧选择最大值即可。\n",
    "\n",
    "最优行动最好被理解为一个**策略**，它通常是一个从状态到行动的映射。\n",
    "\n",
    "对于*任何*$ w $，我们都可以通过在[(42.1)](#equation-odu-pv)右侧选择最大值来得到相应的最佳选择（接受或拒绝）。\n",
    "\n",
    "因此，我们有一个从$ \\mathbb R $到$ \\{0, 1\\} $的映射，其中1表示接受，0表示拒绝。\n",
    "\n",
    "我们可以将策略写作如下\n",
    "\n",
    "$$\n",
    "\\sigma(w) := \\mathbf{1}\n",
    "    \\left\\{\n",
    "        \\frac{w}{1 - \\beta} \\geq c + \\beta \\sum_{w' \\in \\mathbb W}\n",
    "        v^*(w') q (w')\n",
    "    \\right\\}\n",
    "$$\n",
    "\n",
    "这里$ \\mathbf{1}\\{ P \\} $在语句$ P $为真时等于1，否则等于0。\n",
    "\n",
    "我们也可以将其写作\n",
    "\n",
    "$$\n",
    "\\sigma(w) := \\mathbf{1} \\{ w \\geq \\bar w \\}\n",
    "$$\n",
    "\n",
    "其中\n",
    "\n",
    "\n",
    "<a id='equation-reswage'></a>\n",
    "$$\n",
    "\\bar w := (1 - \\beta) \\left\\{ c + \\beta \\sum_{w'} v^*(w') q (w') \\right\\} \\tag{42.2}\n",
    "$$\n",
    "\n",
    "这里的 $ \\bar w $（称为*保留工资*）是一个取决于 $ \\beta, c $ 和工资分布的常数。\n",
    "\n",
    "失业者当且仅当当前工作机会的工资超过保留工资时接受该工作。\n",
    "\n",
    "根据[(42.2)](#equation-reswage)，如果我们能计算出价值函数，就能计算出这个保留工资。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbc7433",
   "metadata": {},
   "source": [
    "## 计算最优策略：第一种方法\n",
    "\n",
    "为了将上述想法付诸实践，我们需要计算每个可能状态 $ w \\in \\mathbb W $ 下的价值函数。\n",
    "\n",
    "为了简化符号，让我们设定\n",
    "\n",
    "$$\n",
    "\\mathbb W := \\{w_1, \\ldots, w_n  \\}\n",
    "    \\quad \\text{和} \\quad\n",
    "    v^*(i) := v^*(w_i)\n",
    "$$\n",
    "\n",
    "价值函数则由向量 $ v^* = (v^*(i))_{i=1}^n $ 表示。\n",
    "\n",
    "根据[(42.1)](#equation-odu-pv)，这个向量满足如下非线性方程组\n",
    "\n",
    "\n",
    "<a id='equation-odu-pv2'></a>\n",
    "$$\n",
    "v^*(i)\n",
    "= \\max \\left\\{\n",
    "        \\frac{w(i)}{1 - \\beta}, \\, c + \\beta \\sum_{1 \\leq j \\leq n}\n",
    "            v^*(j) q (j)\n",
    "    \\right\\}\n",
    "\\quad\n",
    "\\text{对于 } i = 1, \\ldots, n \\tag{42.3}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0609d6",
   "metadata": {},
   "source": [
    "### 算法\n",
    "\n",
    "为了计算这个向量，我们使用连续逼近法：\n",
    "\n",
    "第1步：选择一个任意的初始猜测值 $ v \\in \\mathbb R^n $。\n",
    "\n",
    "第2步：通过以下方式计算新向量 $ v' \\in \\mathbb R^n $\n",
    "\n",
    "\n",
    "<a id='equation-odu-pv2p'></a>\n",
    "$$\n",
    "v'(i)\n",
    "= \\max \\left\\{\n",
    "        \\frac{w(i)}{1 - \\beta}, \\, c + \\beta \\sum_{1 \\leq j \\leq n}\n",
    "            v(j) q (j)\n",
    "    \\right\\}\n",
    "\\quad\n",
    "\\text{对于 } i = 1, \\ldots, n \\tag{42.4}\n",
    "$$\n",
    "\n",
    "第3步：计算 $ v $ 和 $ v' $ 之间的差异度量，例如 $ \\max_i |v(i)- v'(i)| $。\n",
    "\n",
    "第4步：如果偏差大于某个固定的容差，则令 $ v = v' $ 并返回第2步，否则继续。\n",
    "\n",
    "第5步：返回 $ v $。\n",
    "\n",
    "对于较小的容差，返回的函数 $ v $ 是价值函数 $ v^* $ 的近似值。\n",
    "\n",
    "下面的理论将详细说明这一点。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c5946d",
   "metadata": {},
   "source": [
    "### 不动点理论\n",
    "\n",
    "这个算法背后的数学原理是什么？\n",
    "\n",
    "首先，通过以下方式定义从 $ \\mathbb R^n $ 到自身的映射 $ T $：\n",
    "\n",
    "\n",
    "<a id='equation-odu-pv3'></a>\n",
    "$$\n",
    "(Tv)(i)\n",
    "= \\max \\left\\{\n",
    "\n",
    "\\frac{w(i)}{1 - \\beta}, \\, c + \\beta \\sum_{1 \\leq j \\leq n}\n",
    "            v(j) q (j)\n",
    "    \\right\\}\n",
    "\\quad\n",
    "\\text{对于 } i = 1, \\ldots, n \\tag{42.5}\n",
    "$$\n",
    "\n",
    "(通过在每个 $ i $ 处计算右侧的值，从给定向量 $ v $ 得到新向量 $ Tv $。)\n",
    "\n",
    "连续近似序列 $ \\{v_k\\} $ 中的元素 $ v_k $ 对应于 $ T^k v $。\n",
    "\n",
    "- 这是从初始猜测 $ v $ 开始，应用 $ k $ 次 $ T $ 的结果  \n",
    "\n",
    "\n",
    "可以证明，$ T $ 在 $ \\mathbb R^n $ 上满足[巴拿赫不动点定理](https://baike.baidu.com/item/%E5%B7%B4%E6%8B%BF%E8%B5%AB%E4%B8%8D%E5%8A%A8%E7%82%B9%E5%AE%9A%E7%90%86/9492042)的条件。\n",
    "\n",
    "一个推论是 $ T $ 在 $ \\mathbb R^n $ 中有唯一的不动点。\n",
    "\n",
    "- 即存在唯一的向量 $ \\bar v $ 使得 $ T \\bar v = \\bar v $。  \n",
    "\n",
    "\n",
    "而且，从 $ T $ 的定义可以直接得出这个不动点就是 $ v^* $。\n",
    "\n",
    "巴拿赫收缩映射定理的第二个推论是，无论 $ v $ 取何值，序列 $ \\{ T^k v \\} $ 都会收敛到不动点 $ v^* $。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cbccf5",
   "metadata": {},
   "source": [
    "### 实现\n",
    "\n",
    "对于状态过程的分布 $ q $，我们的默认选择是[Beta-二项分布](https://docs.scipy.org.cn/doc/scipy/tutorial/stats/discrete_betabinom.html)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c1aa50",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "n, a, b = 50, 200, 100                        # 默认参数\n",
    "q_default = BetaBinomial(n, a, b).pdf()       # q的默认选择"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba5cd8f",
   "metadata": {},
   "source": [
    "我们的工资默认值设置为"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6020a61b",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "w_min, w_max = 10, 60\n",
    "w_default = np.linspace(w_min, w_max, n+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622bb25b",
   "metadata": {},
   "source": [
    "这是不同工资结果的概率分布图："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451ddcfc",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(w_default, q_default, '-o', label='$q(w(i))$')\n",
    "ax.set_xlabel('工资')\n",
    "ax.set_ylabel('概率')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b73711",
   "metadata": {},
   "source": [
    "我们将使用Numba来加速我们的代码。\n",
    "\n",
    "- 参见[我们关于Numba的讲座](https://python-programming.quantecon.org/numba.html)中对`@jitclass`的讨论。  \n",
    "\n",
    "\n",
    "以下内容通过提供一些类型来帮助Numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90917b9",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "mccall_data = [\n",
    "    ('c', float64),      # 失业补偿\n",
    "    ('β', float64),      # 贴现因子\n",
    "    ('w', float64[:]),   # 工资值数组，w[i] = 状态i下的工资\n",
    "    ('q', float64[:])    # 概率数组\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfc42c3",
   "metadata": {},
   "source": [
    "这是一个用于存储数据并计算状态-行动对的值的类，即基于当前状态和任意可行的行动，计算贝尔曼方程 [(42.4)](#equation-odu-pv2p) 右侧最大值括号中的值。\n",
    "\n",
    "类中包含了默认参数值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4115a6",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "@jitclass(mccall_data)\n",
    "class McCallModel:\n",
    "\n",
    "    def __init__(self, c=25, β=0.99, w=w_default, q=q_default):\n",
    "\n",
    "        self.c, self.β = c, β\n",
    "        self.w, self.q = w_default, q_default\n",
    "\n",
    "    def state_action_values(self, i, v):\n",
    "        \"\"\"\n",
    "        状态-动作对的值。\n",
    "        \"\"\"\n",
    "        # 简化名称\n",
    "        c, β, w, q = self.c, self.β, self.w, self.q\n",
    "        # 评估每个状态-行动对的值\n",
    "        # 考虑行动 = 接受或拒绝当前报价\n",
    "        accept = w[i] / (1 - β)\n",
    "        reject = c + β * np.sum(v * q)\n",
    "\n",
    "        return np.array([accept, reject])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd71417d",
   "metadata": {},
   "source": [
    "根据这些默认值，让我们尝试绘制序列 $ \\{ T^k v \\} $ 中最初几个近似值函数。\n",
    "\n",
    "我们将从猜测值 $ v $ 开始，其中 $ v(i) = w(i) / (1 - β) $，这是在每个给定工资下都接受的价值。\n",
    "\n",
    "这里有一个实现该功能的函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da593a9",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def plot_value_function_seq(mcm, ax, num_plots=6):\n",
    "    \"\"\"\n",
    "    绘制一系列值函数。\n",
    "\n",
    "        * mcm 是 McCallModel 的一个实例\n",
    "        * ax 是实现了 plot 方法的轴对象\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(mcm.w)\n",
    "    v = mcm.w / (1 - mcm.β)\n",
    "    v_next = np.empty_like(v)\n",
    "    for i in range(num_plots):\n",
    "        ax.plot(mcm.w, v, '-', alpha=0.4, label=f\"iterate {i}\")\n",
    "        # 更新猜测值\n",
    "        for j in range(n):\n",
    "            v_next[j] = np.max(mcm.state_action_values(j, v))\n",
    "        v[:] = v_next  # 将内容复制到 v 中\n",
    "\n",
    "    ax.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce296125",
   "metadata": {},
   "source": [
    "现在让我们创建一个 `McCallModel` 实例，并观察迭代 $ T^k v $ 从下方收敛的过程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d2e933",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "mcm = McCallModel()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel('工资')\n",
    "ax.set_ylabel('价值')\n",
    "plot_value_function_seq(mcm, ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600bb7ee",
   "metadata": {},
   "source": [
    "你可以看到收敛的发生：连续的迭代值越来越接近。\n",
    "\n",
    "这里有一个更严谨的迭代计算极限的方法，它会持续计算直到连续迭代之间的测量偏差小于容差值。\n",
    "\n",
    "一旦我们获得了对极限的良好近似，我们将用它来计算保留工资。\n",
    "\n",
    "我们将通过Numba的JIT编译来加速我们的循环。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8b5b2f",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def compute_reservation_wage(mcm,\n",
    "                             max_iter=500,\n",
    "                             tol=1e-6):\n",
    "\n",
    "    # 简化名称\n",
    "    c, β, w, q = mcm.c, mcm.β, mcm.w, mcm.q\n",
    "\n",
    "    # == 首先计算价值函数 == #\n",
    "\n",
    "    n = len(w)\n",
    "    v = w / (1 - β)          # 初始猜测\n",
    "    v_next = np.empty_like(v)\n",
    "    j = 0\n",
    "    error = tol + 1\n",
    "    while j < max_iter and error > tol:\n",
    "\n",
    "        for j in range(n):\n",
    "            v_next[j] = np.max(mcm.state_action_values(j, v))\n",
    "\n",
    "        error = np.max(np.abs(v_next - v))\n",
    "        j += 1\n",
    "\n",
    "        v[:] = v_next  # 将内容复制到v中\n",
    "\n",
    "    # == 现在计算保留工资 == #\n",
    "\n",
    "    return (1 - β) * (c + β * np.sum(v * q))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7854f70b",
   "metadata": {},
   "source": [
    "现在我们计算在默认参数下的保留工资"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a143a3",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "compute_reservation_wage(mcm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef9efe9",
   "metadata": {},
   "source": [
    "### 比较静态分析\n",
    "\n",
    "现在我们知道如何计算保留工资，让我们来看看它如何随参数变化。\n",
    "\n",
    "具体来说，让我们看看当我们改变$ \\beta $和$ c $时会发生什么。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42a0644",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "grid_size = 25\n",
    "R = np.empty((grid_size, grid_size))\n",
    "\n",
    "c_vals = np.linspace(10.0, 30.0, grid_size)\n",
    "β_vals = np.linspace(0.9, 0.99, grid_size)\n",
    "\n",
    "for i, c in enumerate(c_vals):\n",
    "    for j, β in enumerate(β_vals):\n",
    "        mcm = McCallModel(c=c, β=β)\n",
    "        R[i, j] = compute_reservation_wage(mcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005a0210",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "cs1 = ax.contourf(c_vals, β_vals, R.T, alpha=0.75)\n",
    "ctr1 = ax.contour(c_vals, β_vals, R.T)\n",
    "\n",
    "plt.clabel(ctr1, inline=1, fontsize=13)\n",
    "plt.colorbar(cs1, ax=ax)\n",
    "\n",
    "\n",
    "ax.set_title(\"保留工资\")\n",
    "ax.set_xlabel(\"$c$\", fontsize=16)\n",
    "ax.set_ylabel(\"$β$\", fontsize=16)\n",
    "\n",
    "ax.ticklabel_format(useOffset=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b12ceae",
   "metadata": {},
   "source": [
    "如预期所示，保留工资随着耐心程度和失业补助的增加而增加。\n",
    "\n",
    "\n",
    "<a id='mm-op2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4191e1a3",
   "metadata": {},
   "source": [
    "## 计算最优策略：方法二\n",
    "\n",
    "刚才描述的动态规划方法是标准且广泛适用的。\n",
    "\n",
    "但对于我们的McCall搜索模型来说，还有一个更简单的方法，可以避免计算价值函数。\n",
    "\n",
    "让 $ h $ 表示延续值：\n",
    "\n",
    "\n",
    "<a id='equation-j1'></a>\n",
    "$$\n",
    "h\n",
    "= c + \\beta\n",
    "    \\sum_{s'} v^*(s') q (s')\n",
    "\\quad \\tag{42.6}\n",
    "$$\n",
    "\n",
    "贝尔曼方程现在可以写作\n",
    "\n",
    "$$\n",
    "v^*(s')\n",
    "= \\max \\left\\{ \\frac{w(s')}{1 - \\beta}, \\, h \\right\\}\n",
    "$$\n",
    "\n",
    "将这个等式代入 [(42.6)](#equation-j1) 得到\n",
    "\n",
    "\n",
    "<a id='equation-j2'></a>\n",
    "$$\n",
    "h\n",
    "= c + \\beta\n",
    "    \\sum_{s' \\in \\mathbb S}\n",
    "    \\max \\left\\{\n",
    "        \\frac{w(s')}{1 - \\beta}, h\n",
    "    \\right\\}  q (s')\n",
    "\\quad \\tag{42.7}\n",
    "$$\n",
    "\n",
    "这是一个我们可以求解 $ h $ 的非线性方程。\n",
    "\n",
    "和之前一样，我们将使用连续近似法：\n",
    "\n",
    "第1步：选择一个初始猜测值 $ h $。\n",
    "\n",
    "第2步：通过以下公式计算更新值 $ h' $\n",
    "\n",
    "\n",
    "<a id='equation-j3'></a>\n",
    "$$\n",
    "h'\n",
    "\n",
    "= c + \\beta\n",
    "    \\sum_{s' \\in \\mathbb S}\n",
    "    \\max \\left\\{\n",
    "        \\frac{w(s')}{1 - \\beta}, h\n",
    "    \\right\\}  q (s')\n",
    "\\quad \\tag{42.8}\n",
    "$$\n",
    "\n",
    "第3步：计算偏差 $ |h - h'| $。\n",
    "\n",
    "第4步：如果偏差大于某个固定的容差，则设置 $ h = h' $ 并返回第2步，否则返回 $ h $。\n",
    "\n",
    "我们可以再次使用巴拿赫不动点定理来证明这个过程总是收敛的。\n",
    "\n",
    "与之前的方法相比，这里有一个重要区别：我们现在是对单个标量 $ h $ 进行迭代，而不是像之前那样对 $ n $ 维向量 $ v(i), i = 1, \\ldots, n $ 进行迭代，这使得计算过程更加简单。\n",
    "\n",
    "以下是实现代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91c71ff",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def compute_reservation_wage_two(mcm,\n",
    "                                 max_iter=500,\n",
    "                                 tol=1e-5):\n",
    "\n",
    "    # 简化名称\n",
    "    c, β, w, q = mcm.c, mcm.β, mcm.w, mcm.q\n",
    "\n",
    "    # == 首先计算h == #\n",
    "\n",
    "    h = np.sum(w * q) / (1 - β)\n",
    "    i = 0\n",
    "    error = tol + 1\n",
    "    while i < max_iter and error > tol:\n",
    "\n",
    "        s = np.maximum(w / (1 - β), h)\n",
    "        h_next = c + β * np.sum(s * q)\n",
    "\n",
    "        error = np.abs(h_next - h)\n",
    "        i += 1\n",
    "\n",
    "        h = h_next\n",
    "\n",
    "    # == 现在计算保留工资 == #\n",
    "\n",
    "    return (1 - β) * h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fa111b",
   "metadata": {},
   "source": [
    "你可以使用以上代码来完成下面的练习。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46bbc7c",
   "metadata": {},
   "source": [
    "## 练习"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d9511a",
   "metadata": {},
   "source": [
    "## Exercise 42.1\n",
    "\n",
    "当 $ \\beta=0.99 $ 且 $ c $ 取以下值时，计算失业的平均持续时间\n",
    "\n",
    "> `c_vals = np.linspace(10, 40, 25)`\n",
    "\n",
    "\n",
    "也就是说，让失业者从失业状态开始，根据给定参数计算其保留工资，然后模拟看需要多长时间才能接受工作。\n",
    "\n",
    "重复多次并取平均值。\n",
    "\n",
    "绘制平均失业持续时间与 `c_vals` 中的 $ c $ 值的函数关系图。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613e32d7",
   "metadata": {},
   "source": [
    "## Solution to[ Exercise 42.1](https://python.quantecon.org/#mm_ex1)\n",
    "\n",
    "参考答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6ca8a5",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "cdf = np.cumsum(q_default)\n",
    "\n",
    "@jit\n",
    "def compute_stopping_time(w_bar, seed=1234):\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    t = 1\n",
    "    while True:\n",
    "        # 生成工资抽样\n",
    "        w = w_default[qe.random.draw(cdf)]\n",
    "        # 当抽样值高于保留工资时停止\n",
    "        if w >= w_bar:\n",
    "            stopping_time = t\n",
    "            break\n",
    "        else:\n",
    "            t += 1\n",
    "    return stopping_time\n",
    "\n",
    "@jit\n",
    "def compute_mean_stopping_time(w_bar, num_reps=100000):\n",
    "    obs = np.empty(num_reps)\n",
    "    for i in range(num_reps):\n",
    "        obs[i] = compute_stopping_time(w_bar, seed=i)\n",
    "    return obs.mean()\n",
    "\n",
    "c_vals = np.linspace(10, 40, 25)\n",
    "stop_times = np.empty_like(c_vals)\n",
    "for i, c in enumerate(c_vals):\n",
    "    mcm = McCallModel(c=c)\n",
    "    w_bar = compute_reservation_wage_two(mcm)\n",
    "    stop_times[i] = compute_mean_stopping_time(w_bar)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(c_vals, stop_times, label=\"平均失业持续时间\")\n",
    "ax.set(xlabel=\"失业补助\", ylabel=\"月数\")\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abca8191",
   "metadata": {},
   "source": [
    "## Exercise 42.2\n",
    "\n",
    "本练习的目的是展示如何将上文使用的离散工资分布替换为连续分布。\n",
    "\n",
    "这是一个重要内容，因为许多常用的分布都是连续的(即具有密度函数)。\n",
    "\n",
    "幸运的是，在我们的简单模型中理论变化很小。\n",
    "\n",
    "回想一下，[(42.6)](#equation-j1)中的$ h $表示在本期不接受工作但在随后所有期间表现最优的价值：\n",
    "\n",
    "要转换为连续分布，我们可以用以下式子替换[(42.6)](#equation-j1)：\n",
    "\n",
    "\n",
    "<a id='equation-j1c'></a>\n",
    "$$\n",
    "h\n",
    "= c + \\beta\n",
    "    \\int v^*(s') q (s') ds'.\n",
    "\\quad \\tag{42.9}\n",
    "$$\n",
    "\n",
    "方程[(42.7)](#equation-j2)变为：\n",
    "\n",
    "\n",
    "<a id='equation-j2c'></a>\n",
    "$$\n",
    "h\n",
    "= c + \\beta\n",
    "    \\int\n",
    "    \\max \\left\\{\n",
    "        \\frac{w(s')}{1 - \\beta}, h\n",
    "    \\right\\}  q (s') d s'\n",
    "\\quad \\tag{42.10}\n",
    "$$\n",
    "\n",
    "目标是通过迭代求解这个非线性方程，并从中得到保留工资。\n",
    "\n",
    "尝试实现这一点，设置\n",
    "\n",
    "- 状态序列 $ \\{ s_t \\} $ 为独立同分布的标准正态分布，且  \n",
    "- 工资函数为 $ w(s) = \\exp(\\mu + \\sigma s) $。  \n",
    "\n",
    "\n",
    "你需要实现一个新版本的 `McCallModel` 类，该类假设工资为对数正态分布。\n",
    "\n",
    "通过蒙特卡洛方法计算积分，即对大量工资抽样进行平均。\n",
    "\n",
    "对于默认参数，使用 `c=25, β=0.99, σ=0.5, μ=2.5`。\n",
    "\n",
    "当你的代码可以运行后，研究保留工资如何随 $ c $ 和 $ \\beta $ 变化。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54221914",
   "metadata": {},
   "source": [
    "## Solution to[ Exercise 42.2](https://python.quantecon.org/#mm_ex2)\n",
    "\n",
    "参考答案："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b16372",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "mccall_data_continuous = [\n",
    "    ('c', float64),          # 失业补助\n",
    "    ('β', float64),          # 贴现因子\n",
    "    ('σ', float64),          # 对数正态分布的尺度参数\n",
    "    ('μ', float64),          # 对数正态分布的位置参数\n",
    "    ('w_draws', float64[:])  # 蒙特卡洛的工资抽样\n",
    "]\n",
    "\n",
    "@jitclass(mccall_data_continuous)\n",
    "class McCallModelContinuous:\n",
    "\n",
    "    def __init__(self, c=25, β=0.99, σ=0.5, μ=2.5, mc_size=1000):\n",
    "\n",
    "        self.c, self.β, self.σ, self.μ = c, β, σ, μ\n",
    "\n",
    "        # 抽样并存储随机冲击\n",
    "        np.random.seed(1234)\n",
    "        s = np.random.randn(mc_size)\n",
    "        self.w_draws = np.exp(μ+ σ * s)\n",
    "\n",
    "\n",
    "@jit\n",
    "def compute_reservation_wage_continuous(mcmc, max_iter=500, tol=1e-5):\n",
    "\n",
    "    c, β, σ, μ, w_draws = mcmc.c, mcmc.β, mcmc.σ, mcmc.μ, mcmc.w_draws\n",
    "\n",
    "    h = np.mean(w_draws) / (1 - β)  # 初始值猜测\n",
    "    i = 0\n",
    "    error = tol + 1\n",
    "    while i < max_iter and error > tol:\n",
    "\n",
    "        integral = np.mean(np.maximum(w_draws / (1 - β), h))\n",
    "        h_next = c + β * integral\n",
    "\n",
    "        error = np.abs(h_next - h)\n",
    "        i += 1\n",
    "\n",
    "        h = h_next\n",
    "\n",
    "    # == 现在计算保留工资 == #\n",
    "\n",
    "    return (1 - β) * h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafc81e9",
   "metadata": {},
   "source": [
    "现在我们研究保留工资如何随着 $ c $ 和 $ \\beta $ 变化。\n",
    "\n",
    "我们将使用等值线图来分析这个问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f0a2c7",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "grid_size = 25\n",
    "R = np.empty((grid_size, grid_size))\n",
    "\n",
    "c_vals = np.linspace(10.0, 30.0, grid_size)\n",
    "β_vals = np.linspace(0.9, 0.99, grid_size)\n",
    "\n",
    "for i, c in enumerate(c_vals):\n",
    "    for j, β in enumerate(β_vals):\n",
    "        mcmc = McCallModelContinuous(c=c, β=β)\n",
    "        R[i, j] = compute_reservation_wage_continuous(mcmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ef54b0",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "cs1 = ax.contourf(c_vals, β_vals, R.T, alpha=0.75)\n",
    "ctr1 = ax.contour(c_vals, β_vals, R.T)\n",
    "\n",
    "plt.clabel(ctr1, inline=1, fontsize=13)\n",
    "plt.colorbar(cs1, ax=ax)\n",
    "\n",
    "\n",
    "ax.set_title(\"保留工资\")\n",
    "ax.set_xlabel(\"$c$\", fontsize=16)\n",
    "ax.set_ylabel(\"$β$\", fontsize=16)\n",
    "\n",
    "ax.ticklabel_format(useOffset=False)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "date": 1761257073.3885837,
  "filename": "mccall_model.md",
  "kernelspec": {
   "display_name": "Python",
   "language": "python3",
   "name": "python3"
  },
  "title": "工作搜寻 I: McCall搜寻模型"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}