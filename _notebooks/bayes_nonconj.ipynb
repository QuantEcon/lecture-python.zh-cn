{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4c5de2f",
   "metadata": {},
   "source": [
    "# 非共轭先验\n",
    "\n",
    "本讲是[quantecon讲座](https://python.quantecon.org/prob_meaning.html)的续篇。\n",
    "\n",
    "那节课在似然函数和参数先验分布恰好形成**共轭**对的情况下，提供了概率的贝叶斯解释，其中：\n",
    "\n",
    "- 应用贝叶斯法则产生的后验分布与先验具有相同的函数形式  \n",
    "\n",
    "\n",
    "具有共轭关系的似然和先验可以简化后验的计算，有助于进行解析或近似解析计算。\n",
    "\n",
    "但在许多情况下，似然和先验不需要形成共轭对。\n",
    "\n",
    "- 毕竟，一个人的先验是他或她自己的事情，只有在极小的巧合下才会采取与似然共轭的形式\n",
    "  在这些情况下，计算后验概率会变得非常具有挑战性。  \n",
    "\n",
    "\n",
    "在本讲中，我们将说明现代贝叶斯学者如何通过使用蒙特卡洛技术来处理非共轭先验，这涉及到：\n",
    "\n",
    "- 首先巧妙地构建一个马尔可夫链，其不变分布就是我们想要的后验分布  \n",
    "- 模拟该马尔可夫链直到其收敛，然后从不变分布中采样以近似后验分布  \n",
    "\n",
    "\n",
    "我们将通过使用两个强大的Python模块来说明这种方法，这些模块实现了这种方法以及下面将要描述的另一种密切相关的方法。\n",
    "\n",
    "这两个Python模块是：\n",
    "\n",
    "- `numpyro`  \n",
    "- `pymc4`  \n",
    "\n",
    "\n",
    "像往常一样，我们首先导入一些Python代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21790be3",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "!pip install numpyro pyro-ppl torch jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b0e3eb",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "FONTPATH = \"fonts/SourceHanSerifSC-SemiBold.otf\"\n",
    "mpl.font_manager.fontManager.addfont(FONTPATH)\n",
    "plt.rcParams['font.family'] = ['Source Han Serif SC']\n",
    "\n",
    "from scipy.stats import binom\n",
    "import scipy.stats as st\n",
    "import torch\n",
    "\n",
    "# jax\n",
    "import jax.numpy as jnp\n",
    "from jax import lax, random\n",
    "\n",
    "# pyro\n",
    "import pyro\n",
    "from pyro import distributions as dist\n",
    "import pyro.distributions.constraints as constraints\n",
    "from pyro.infer import MCMC, NUTS, SVI, ELBO, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "\n",
    "# numpyro\n",
    "import numpyro\n",
    "from numpyro import distributions as ndist\n",
    "import numpyro.distributions.constraints as nconstraints\n",
    "from numpyro.infer import MCMC as nMCMC\n",
    "from numpyro.infer import NUTS as nNUTS\n",
    "from numpyro.infer import SVI as nSVI\n",
    "from numpyro.infer import ELBO as nELBO\n",
    "from numpyro.infer import Trace_ELBO as nTrace_ELBO\n",
    "from numpyro.optim import Adam as nAdam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e614cb7f",
   "metadata": {},
   "source": [
    "## 在二项分布似然上释放MCMC\n",
    "\n",
    "本讲座从[quantecon讲座](https://python.quantecon.org/prob_meaning.html)中的二项分布示例开始。\n",
    "\n",
    "该讲座通过以下方式计算后验分布：\n",
    "\n",
    "- 通过选择共轭先验进行解析计算  \n",
    "\n",
    "\n",
    "本讲座则通过以下方式计算后验分布：\n",
    "\n",
    "- 通过MCMC方法对后验分布进行数值采样，以及  \n",
    "- 使用变分推断(VI)近似  \n",
    "\n",
    "\n",
    "我们使用`pyro`和`numpyro`包，并借助`jax`来近似后验分布\n",
    "\n",
    "我们使用几种不同的先验分布\n",
    "\n",
    "我们将计算得到的后验分布与[quantecon讲座](https://python.quantecon.org/prob_meaning.html)中描述的共轭先验相关的后验分布进行比较"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae8c8d9",
   "metadata": {},
   "source": [
    "### 解析后验分布\n",
    "\n",
    "假设随机变量$ X\\sim Binom\\left(n,\\theta\\right) $。\n",
    "\n",
    "这定义了一个似然函数\n",
    "\n",
    "$$\n",
    "L\\left(Y\\vert\\theta\\right) = \\textrm{Prob}(X =  k | \\theta) =\n",
    "\\left(\\frac{n!}{k! (n-k)!} \\right) \\theta^k (1-\\theta)^{n-k}\n",
    "$$\n",
    "\n",
    "其中 $ Y=k $ 是一个观测数据点。\n",
    "\n",
    "我们将 $ \\theta $ 视为一个随机变量，为其指定一个具有密度 $ f(\\theta) $ 的先验分布。\n",
    "\n",
    "我们稍后会尝试其他先验分布，但现在，假设先验分布为 $ \\theta\\sim Beta\\left(\\alpha,\\beta\\right) $，即：\n",
    "\n",
    "$$\n",
    "f(\\theta) = \\textrm{Prob}(\\theta) = \\frac{\\theta^{\\alpha - 1} (1 - \\theta)^{\\beta - 1}}{B(\\alpha, \\beta)}\n",
    "$$\n",
    "\n",
    "我们现在选择这个作为先验分布，是因为我们知道二项分布似然函数的共轭先验是贝塔分布。\n",
    "\n",
    "在 $ N $ 个样本观测中观察到 $ k $ 次成功后，$ \\theta $ 的后验概率分布为：\n",
    "\n",
    "$$\n",
    "\\textrm{Prob}(\\theta|k) = \\frac{\\textrm{Prob}(\\theta,k)}{\\textrm{Prob}(k)}=\\frac{\\textrm{Prob}(k|\\theta)\\textrm{Prob}(\\theta)}{\\textrm{Prob}(k)}=\\frac{\\textrm{Prob}(k|\\theta) \\textrm{Prob}(\\theta)}{\\int_0^1 \\textrm{Prob}(k|\\theta)\\textrm{Prob}(\\theta) d\\theta}\n",
    "$$\n",
    "\n",
    "=\\frac{B(\\alpha, \\beta)}}{\\int_0^1 {N \\choose k} (1 - \\theta)^{N-k} \\theta^k\\frac{\\theta^{\\alpha - 1} (1 - \\theta)^{\\beta - 1}}{B(\\alpha, \\beta)} d\\theta}\n",
    "\\$\\$\n",
    "\n",
    "$$\n",
    "=\\frac{(1 -\\theta)^{\\beta+N-k-1} \\theta^{\\alpha+k-1}}{\\int_0^1 (1 - \\theta)^{\\beta+N-k-1} \\theta^{\\alpha+k-1} d\\theta} .\n",
    "$$\n",
    "\n",
    "因此，\n",
    "\n",
    "$$\n",
    "\\textrm{Prob}(\\theta|k) \\sim {Beta}(\\alpha + k, \\beta+N-k)\n",
    "$$\n",
    "\n",
    "以下Python代码实现了给定共轭beta先验的解析后验。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f1965f",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def simulate_draw(theta, n):\n",
    "    \"\"\"\n",
    "    生成一个大小为n的伯努利样本，其中P(Y=1) = theta\n",
    "    \"\"\"\n",
    "    rand_draw = np.random.rand(n)\n",
    "    draw = (rand_draw < theta).astype(int)\n",
    "    return draw\n",
    "\n",
    "\n",
    "def analytical_beta_posterior(data, alpha0, beta0):\n",
    "    \"\"\"\n",
    "    给定观测数据，用参数(alpha, beta)的beta先验分布\n",
    "    解析计算后验分布\n",
    "\n",
    "    参数\n",
    "    ---------\n",
    "    num : int.\n",
    "        计算后验时的观测数量\n",
    "    alpha0, beta0 : float.\n",
    "        beta先验分布的参数\n",
    "\n",
    "    返回值\n",
    "    ---------\n",
    "    后验beta分布\n",
    "    \"\"\"\n",
    "    num = len(data)\n",
    "    up_num = data.sum()\n",
    "    down_num = num - up_num\n",
    "    return st.beta(alpha0 + up_num, beta0 + down_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549c957d",
   "metadata": {},
   "source": [
    "### 近似后验分布的两种方法\n",
    "\n",
    "假设我们没有共轭先验。\n",
    "\n",
    "那么我们就无法解析地计算后验分布。\n",
    "\n",
    "相反，我们使用计算工具来近似一组替代先验分布的后验分布，这需要用到Python中的`Pyro`和`Numpyro`包。\n",
    "\n",
    "我们首先使用**马尔可夫链蒙特卡洛**（MCMC）算法。\n",
    "\n",
    "我们实现NUTS采样器来从后验分布中采样。\n",
    "\n",
    "通过这种方式，我们构建一个近似后验分布的采样分布。\n",
    "\n",
    "在此之后，我们部署另一个称为**变分推断**（VI）的程序。\n",
    "\n",
    "特别是，我们在`Pyro`和`Numpyro`中都实现了随机变分推断（SVI）机制。\n",
    "\n",
    "MCMC算法据说能产生更准确的近似，因为原则上它直接从后验分布中采样。\n",
    "\n",
    "但是它在计算上可能很昂贵，尤其是当维度很大时。\n",
    "VI方法可能更便宜，但很可能会产生较差的后验近似，原因很简单，因为它需要猜测一个用于近似后验的参数化**指导函数形式**。\n",
    "\n",
    "这个指导函数充其量也只能是一个不完美的近似。\n",
    "\n",
    "通过限制假定后验具有受限函数形式所付出的代价，后验近似问题被转化为一个明确的优化问题，该问题寻求假定后验的参数，以最小化真实后验和假定后验分布之间的Kullback-Leibler (KL)散度。\n",
    "\n",
    "- 最小化KL散度等价于最大化一个称为**证据下界**（ELBO）的标准，我们很快就会验证这一点。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c93fd1",
   "metadata": {},
   "source": [
    "## 先验分布\n",
    "\n",
    "为了能够应用MCMC采样或VI，`Pyro`和`Numpyro`要求先验分布满足特殊性质：\n",
    "\n",
    "- 我们必须能够从中进行采样；  \n",
    "- 我们必须能够逐点计算对数概率密度函数；  \n",
    "- 概率密度函数必须对参数可微。  \n",
    "\n",
    "\n",
    "我们需要定义一个分布`class`。\n",
    "\n",
    "我们将使用以下先验：\n",
    "\n",
    "- 在区间$ [\\underline \\theta, \\overline \\theta] $上的均匀分布，其中$ 0 \\leq \\underline \\theta < \\overline \\theta \\leq 1 $。  \n",
    "- 支撑在$ [0,1] $上的截断对数正态分布，参数为$ (\\mu,\\sigma) $。  \n",
    "  - 要实现这一点，令$ Z\\sim Normal(\\mu,\\sigma) $且$ \\tilde{Z} $为支撑在$ [\\log(0),\\log(1)] $上的截断正态分布，则$ \\exp(Z) $具有支撑在$ [0,1] $上的对数正态分布。这很容易编码，因为`Numpyro`内置了截断正态分布，而`Torch`提供了包含指数变换的`TransformedDistribution`类。  \n",
    "- 另外，我们可以使用拒绝采样策略，将界限外的概率率设为$ 0 $，并通过原始分布的CDF计算的总概率来重新缩放被接受的样本（即在界限内的实现值）。这可以通过使用`pyro`的`dist.Rejector`类来定义截断分布类来实现。  \n",
    "  - 我们在下面的部分实现这两种方法，并验证它们产生相同的结果。  \n",
    "- 一个支撑限制在$ [0,1] $区间内的偏移冯·米塞斯分布，其参数为$ (\\mu,\\kappa) $。  \n",
    "  - 设$ X\\sim vonMises(0,\\kappa) $。我们知道$ X $的支撑范围是$ [-\\pi, \\pi] $。我们可以定义一个偏移的冯·米塞斯随机变量$ \\tilde{X}=a+bX $，其中$ a=0.5, b=1/(2 \\pi) $，这样$ \\tilde{X} $的支撑范围就在$ [0,1] $上。  \n",
    "  - 这可以使用`Torch`的`TransformedDistribution`类及其`AffineTransform`方法来实现。  \n",
    "- 如果我们想要先验服从冯·米塞斯分布(von-Mises)且中心为$ \\mu=0.5 $,我们可以选择一个较高的集中度参数$ \\kappa $,使得大部分概率质量位于$ 0 $和$ 1 $之间。然后我们可以使用上述策略进行截断。这可以通过`pyro`的`dist.Rejector`类来实现。在这种情况下,我们选择$ \\kappa > 40 $。  \n",
    "- 一个截断的拉普拉斯分布。  \n",
    "  - 我们还考虑了截断的拉普拉斯分布,因为它的密度函数呈现分段非光滑的形式,并具有独特的尖峰形状。  \n",
    "  - 可以使用`Numpyro`的`TruncatedDistribution`类创建截断的拉普拉斯分布。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac82479f",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# 由Numpyro使用\n",
    "def TruncatedLogNormal_trans(loc, scale):\n",
    "    \"\"\"\n",
    "    使用numpyro的TruncatedNormal和ExpTransform获取截断对数正态分布\n",
    "    \"\"\"\n",
    "    base_dist = ndist.TruncatedNormal(low=jnp.log(0), high=jnp.log(1), loc=loc, scale=scale)\n",
    "    return ndist.TransformedDistribution(\n",
    "        base_dist,ndist.transforms.ExpTransform()\n",
    "        )\n",
    "\n",
    "def ShiftedVonMises(kappa):\n",
    "    \"\"\"\n",
    "    使用AffineTransform获取平移的冯·米塞斯分布\n",
    "    \"\"\"\n",
    "    base_dist = ndist.VonMises(0, kappa)\n",
    "    return ndist.TransformedDistribution(\n",
    "        base_dist, ndist.transforms.AffineTransform(loc=0.5, scale=1/(2*jnp.pi))\n",
    "        )\n",
    "\n",
    "def TruncatedLaplace(loc, scale):\n",
    "    \"\"\"\n",
    "    获取区间[0,1]上的截断拉普拉斯分布\n",
    "    \"\"\"\n",
    "    base_dist = ndist.Laplace(loc, scale)\n",
    "    return ndist.TruncatedDistribution(\n",
    "        base_dist, low=0.0, high=1.0\n",
    "    )\n",
    "\n",
    "# 由Pyro使用\n",
    "class TruncatedLogNormal(dist.Rejector):\n",
    "    \"\"\"\n",
    "    通过Pyro中的拒绝采样定义截断对数正态分布\n",
    "    \"\"\"\n",
    "    def __init__(self, loc, scale_0, upp=1):\n",
    "        self.upp = upp\n",
    "        propose = dist.LogNormal(loc, scale_0)\n",
    "\n",
    "        def log_prob_accept(x):\n",
    "            return (x < upp).type_as(x).log()\n",
    "\n",
    "        log_scale = dist.LogNormal(loc, scale_0).cdf(torch.as_tensor(upp)).log()\n",
    "        super(TruncatedLogNormal, self).__init__(propose, log_prob_accept, log_scale)\n",
    "\n",
    "    @constraints.dependent_property\n",
    "    def support(self):\n",
    "        return constraints.interval(0, self.upp)\n",
    "\n",
    "\n",
    "class TruncatedvonMises(dist.Rejector):\n",
    "    \"\"\"\n",
    "    通过Pyro中的拒绝采样定义截断冯·米塞斯分布\n",
    "    \"\"\"\n",
    "    def __init__(self, kappa, mu=0.5, low=0.0, upp=1.0):\n",
    "        self.low, self.upp = low, upp\n",
    "        propose = dist.VonMises(mu, kappa)\n",
    "\n",
    "        def log_prob_accept(x):\n",
    "            return ((x > low) & (x < upp)).type_as(x).log()\n",
    "\n",
    "        log_scale = torch.log(\n",
    "            torch.tensor(\n",
    "                st.vonmises(kappa=kappa, loc=mu).cdf(upp)\n",
    "                - st.vonmises(kappa=kappa, loc=mu).cdf(low))\n",
    "        )\n",
    "        super(TruncatedvonMises, self).__init__(propose, log_prob_accept, log_scale)\n",
    "\n",
    "    @constraints.dependent_property\n",
    "    def support(self):\n",
    "        return constraints.interval(self.low, self.upp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7db994",
   "metadata": {},
   "source": [
    "### 变分推断\n",
    "\n",
    "变分推断方法不直接从后验分布中采样，而是用一族可处理的分布/密度来近似未知的后验分布。\n",
    "\n",
    "然后，它寻求最小化近似分布与真实后验分布之间的统计差异度量。\n",
    "\n",
    "因此，变分推断(VI)通过求解最小化问题来近似后验分布。\n",
    "\n",
    "设我们要推断的潜在参数/变量为$ \\theta $。\n",
    "\n",
    "设先验分布为$ p(\\theta) $，似然函数为$ p\\left(Y\\vert\\theta\\right) $。\n",
    "\n",
    "我们想要求得$ p\\left(\\theta\\vert Y\\right) $。\n",
    "\n",
    "根据贝叶斯法则：\n",
    "\n",
    "$$\n",
    "p\\left(\\theta\\vert Y\\right)=\\frac{p\\left(Y,\\theta\\right)}{p\\left(Y\\right)}=\\frac{p\\left(Y\\vert\\theta\\right)p\\left(\\theta\\right)}{p\\left(Y\\right)}\n",
    "$$\n",
    "\n",
    "其中\n",
    "\n",
    "\n",
    "<a id='equation-eq-intchallenge'></a>\n",
    "$$\n",
    "p\\left(Y\\right)=\\int d\\theta p\\left(Y\\mid\\theta\\right)p\\left(Y\\right). \\tag{46.1}\n",
    "$$\n",
    "\n",
    "[(46.1)](#equation-eq-intchallenge)右侧的积分通常很难计算。\n",
    "考虑一个由参数$ \\phi $参数化的**引导分布**$ q_{\\phi}(\\theta) $，我们将用它来近似后验分布。\n",
    "\n",
    "我们选择引导分布的参数$ \\phi $，以最小化近似后验分布$ q_{\\phi}(\\theta) $与后验分布之间的Kullback-Leibler (KL)散度：\n",
    "\n",
    "$$\n",
    "D_{KL}(q(\\theta;\\phi)\\;\\|\\;p(\\theta\\mid Y)) \\equiv -\\int d\\theta q(\\theta;\\phi)\\log\\frac{p(\\theta\\mid Y)}{q(\\theta;\\phi)}\n",
    "$$\n",
    "\n",
    "因此，我们需要一个能解决以下问题的**变分分布**$ q $：\n",
    "\n",
    "$$\n",
    "\\min_{\\phi}\\quad D_{KL}(q(\\theta;\\phi)\\;\\|\\;p(\\theta\\mid Y))\n",
    "$$\n",
    "\n",
    "注意到：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}D_{KL}(q(\\theta;\\phi)\\;\\|\\;p(\\theta\\mid Y)) & =-\\int d\\theta q(\\theta;\\phi)\\log\\frac{P(\\theta\\mid Y)}{q(\\theta;\\phi)}\\\\\n",
    " & =-\\int d\\theta q(\\theta)\\log\\frac{\\frac{p(\\theta,Y)}{p(Y)}}{q(\\theta)}\\\\\n",
    " & =-\\int d\\theta q(\\theta)\\log\\frac{p(\\theta,Y)}{p(\\theta)q(Y)}\\\\\n",
    " & =-\\int d\\theta q(\\theta)\\left[\\log\\frac{p(\\theta,Y)}{q(\\theta)}-\\log p(Y)\\right]\\\\\n",
    "$$\n",
    "\n",
    "& =-\\int d\\theta q(\\theta)\\log\\frac{p(\\theta,Y)}{q(\\theta)}+\\int d\\theta q(\\theta)\\log p(Y)\\\n",
    "& =-\\int d\\theta q(\\theta)\\log\\frac{p(\\theta,Y)}{q(\\theta)}+\\log p(Y)\\\n",
    "\\log p(Y)&=D_{KL}(q(\\theta;\\phi);|;p(\\theta\\mid Y))+\\int d\\theta q_{\\phi}(\\theta)\\log\\frac{p(\\theta,Y)}{q_{\\phi}(\\theta)}\n",
    "\\end{aligned}\n",
    "\\$\\$\n",
    "\n",
    "对于观测数据$ Y $，$ p(\\theta,Y) $是一个常数，所以最小化KL散度等价于最大化\n",
    "\n",
    "\n",
    "<a id='equation-eq-elbo'></a>\n",
    "$$\n",
    "ELBO\\equiv\\int d\\theta q_{\\phi}(\\theta)\\log\\frac{p(\\theta,Y)}{q_{\\phi}(\\theta)}=\\mathbb{E}_{q_{\\phi}(\\theta)}\\left[\\log p(\\theta,Y)-\\log q_{\\phi}(\\theta)\\right] \\tag{46.2}\n",
    "$$\n",
    "\n",
    "公式[(46.2)](#equation-eq-elbo)被称为证据下界(ELBO)。\n",
    "\n",
    "可以使用标准优化程序来搜索我们参数化分布$ q_{\\phi}(\\theta) $中的最优$ \\phi $。\n",
    "\n",
    "参数化分布$ q_{\\phi}(\\theta) $被称为**变分分布**。\n",
    "我们可以在Pyro和Numpyro中使用`Adam`梯度下降算法来实现随机变分推断(SVI)以近似后验分布。\n",
    "\n",
    "我们使用两组变分分布：Beta分布和支撑在$ [0,1] $上的截断正态分布\n",
    "\n",
    "- Beta分布的可学习参数是(alpha, beta)，两者都是正数。  \n",
    "- 截断正态分布的可学习参数是(loc, scale)。  \n",
    "\n",
    "\n",
    "我们将截断正态分布的’loc’参数限制在区间$ [0,1] $内。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95c74e8",
   "metadata": {},
   "source": [
    "## 实现\n",
    "\n",
    "我们构建了一个Python类`BaysianInference`，初始化时需要以下参数：\n",
    "\n",
    "- `param`：依赖于分布类型的参数元组/标量  \n",
    "- `name_dist`：指定分布名称的字符串  \n",
    "\n",
    "\n",
    "(`param`, `name_dist`)配对包括：\n",
    "\n",
    "- (‘beta’, alpha, beta)  \n",
    "- (‘uniform’, upper_bound, lower_bound)  \n",
    "- (‘lognormal’, loc, scale)  \n",
    "  - 注意：这是截断的对数正态分布。  \n",
    "- (‘vonMises’, kappa)，其中kappa表示集中参数，中心位置设为$ 0.5 $。  \n",
    "  - 注意：在使用`Pyro`时，这是原始vonMises分布的截断版本；  \n",
    "  - 注意：在使用`Numpyro`时，这是**平移后**的分布。  \n",
    "- (‘laplace’, loc, scale)  \n",
    "  - 注意：这是截断的拉普拉斯分布  \n",
    "\n",
    "\n",
    "类`BaysianInference`有几个关键方法：\n",
    "\n",
    "- `sample_prior`:  \n",
    "  - 可用于从给定的先验分布中抽取单个样本。  \n",
    "- `show_prior`:  \n",
    "  - 通过重复抽样并拟合核密度曲线来绘制近似的先验分布。  \n",
    "- `MCMC_sampling`:  \n",
    "  - 输入：(data, num_samples, num_warmup=1000)  \n",
    "  - 接收一个`np.array`数据并生成大小为`num_samples`的后验MCMC采样。  \n",
    "- `SVI_run`:  \n",
    "  - 输入：(data, guide_dist, n_steps=10000)  \n",
    "  - guide_dist = ‘normal’ - 使用**截断的**正态分布作为参数化的guide  \n",
    "- guide_dist = ‘beta’ - 使用beta分布作为参数化的指导分布  \n",
    "  - 返回值: (params, losses) - 以`dict`形式存储的学习参数和每一步的损失向量。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d08c21e",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "class BayesianInference:\n",
    "    def __init__(self, param, name_dist, solver):\n",
    "        \"\"\"\n",
    "        参数\n",
    "        ---------\n",
    "        param : tuple.\n",
    "            包含分布所有相关参数的元组对象\n",
    "        dist : str.\n",
    "            分布的名称 - 'beta', 'uniform', 'lognormal', 'vonMises', 'tent'\n",
    "        solver : str.\n",
    "            pyro或numpyro\n",
    "        \"\"\"\n",
    "        self.param = param\n",
    "        self.name_dist = name_dist\n",
    "        self.solver = solver\n",
    "\n",
    "        # jax需要显式传入PRNG状态\n",
    "        self.rng_key = random.PRNGKey(0)\n",
    "\n",
    "\n",
    "    def sample_prior(self):\n",
    "        \"\"\"\n",
    "        定义在Pyro/Numpyro模型中用于采样的先验分布。\n",
    "        \"\"\"\n",
    "        if self.name_dist=='beta':\n",
    "            # 解包参数\n",
    "            alpha0, beta0 = self.param\n",
    "            if self.solver=='pyro':\n",
    "                sample = pyro.sample('theta', dist.Beta(alpha0, beta0))\n",
    "            else:\n",
    "                sample = numpyro.sample('theta', ndist.Beta(alpha0, beta0), rng_key=self.rng_key)\n",
    "\n",
    "        elif self.name_dist=='uniform':\n",
    "            # 解包参数\n",
    "            lb, ub = self.param\n",
    "            if self.solver=='pyro':\n",
    "                sample = pyro.sample('theta', dist.Uniform(lb, ub))\n",
    "            else:\n",
    "                sample = numpyro.sample('theta', ndist.Uniform(lb, ub), rng_key=self.rng_key)\n",
    "\n",
    "        elif self.name_dist=='lognormal':\n",
    "            # 解包参数\n",
    "            loc, scale = self.param\n",
    "            if self.solver=='pyro':\n",
    "                sample = pyro.sample('theta', TruncatedLogNormal(loc, scale))\n",
    "            else:\n",
    "                sample = numpyro.sample('theta', TruncatedLogNormal_trans(loc, scale), rng_key=self.rng_key)\n",
    "\n",
    "        elif self.name_dist=='vonMises':\n",
    "            # 解包参数\n",
    "            kappa = self.param\n",
    "            if self.solver=='pyro':\n",
    "                sample = pyro.sample('theta', TruncatedvonMises(kappa))\n",
    "            else:\n",
    "                sample = numpyro.sample('theta', ShiftedVonMises(kappa), rng_key=self.rng_key)\n",
    "\n",
    "        elif self.name_dist=='laplace':\n",
    "            # 解包参数\n",
    "            loc, scale = self.param\n",
    "            if self.solver=='pyro':\n",
    "                print(\"警告：请使用Numpyro进行截断拉普拉斯分布。\")\n",
    "                sample = None\n",
    "            else:\n",
    "                sample = numpyro.sample('theta', TruncatedLaplace(loc, scale), rng_key=self.rng_key)\n",
    "\n",
    "        return sample\n",
    "\n",
    "\n",
    "    def show_prior(self, size=1e5, bins=20, disp_plot=1):\n",
    "        \"\"\"\n",
    "        通过从先验分布采样并绘制近似采样分布来可视化先验分布\n",
    "        \"\"\"\n",
    "        self.bins = bins\n",
    "\n",
    "        if self.solver=='pyro':\n",
    "            with pyro.plate('show_prior', size=size):\n",
    "                sample = self.sample_prior()\n",
    "            # 转换为numpy\n",
    "            sample_array = sample.numpy()\n",
    "\n",
    "        elif self.solver=='numpyro':\n",
    "            with numpyro.plate('show_prior', size=size):\n",
    "                sample = self.sample_prior()\n",
    "            # 转换为numpy\n",
    "            sample_array=jnp.asarray(sample)\n",
    "\n",
    "        # 绘制直方图和核密度估计\n",
    "        if disp_plot==1:\n",
    "            sns.displot(sample_array, kde=True, stat='density', bins=bins, height=5, aspect=1.5)\n",
    "            plt.xlim(0, 1)\n",
    "            plt.show()\n",
    "        else:\n",
    "            return sample_array\n",
    "\n",
    "\n",
    "    def model(self, data):\n",
    "        \"\"\"\n",
    "        通过指定先验分布、条件似然和数据条件来定义概率模型\n",
    "        \"\"\"\n",
    "        if not torch.is_tensor(data):\n",
    "            data = torch.tensor(data)\n",
    "        # 设置先验\n",
    "        theta = self.sample_prior()\n",
    "\n",
    "        # 从条件似然中采样\n",
    "        if self.solver=='pyro':\n",
    "            output = pyro.sample('obs', dist.Binomial(len(data), theta), obs=torch.sum(data))\n",
    "        else:\n",
    "            # 注意：numpyro.sample()要求obs=np.ndarray\n",
    "            output = numpyro.sample('obs', ndist.Binomial(len(data), theta), obs=torch.sum(data).numpy())\n",
    "        return output\n",
    "\n",
    "\n",
    "    def MCMC_sampling(self, data, num_samples, num_warmup=1000):\n",
    "        \"\"\"\n",
    "        使用MCMC数值计算给定数据下的后验分布，先验为由(alpha0, beta0)参数化的beta分布\n",
    "        \"\"\"\n",
    "        # 使用pyro\n",
    "        if self.solver=='pyro':\n",
    "            # 张量化\n",
    "            data = torch.tensor(data)\n",
    "            nuts_kernel = NUTS(self.model)\n",
    "            mcmc = MCMC(nuts_kernel, num_samples=num_samples, warmup_steps=num_warmup, disable_progbar=True)\n",
    "            mcmc.run(data)\n",
    "\n",
    "        # 使用numpyro\n",
    "        elif self.solver=='numpyro':\n",
    "            data = np.array(data, dtype=float)\n",
    "            nuts_kernel = nNUTS(self.model)\n",
    "            mcmc = nMCMC(nuts_kernel, num_samples=num_samples, num_warmup=num_warmup, progress_bar=False)\n",
    "            mcmc.run(self.rng_key, data=data)\n",
    "\n",
    "        # 收集样本\n",
    "        samples = mcmc.get_samples()['theta']\n",
    "        return samples\n",
    "\n",
    "\n",
    "    def beta_guide(self, data):\n",
    "        \"\"\"\n",
    "        定义用于在Pyro/Numpyro中近似后验的候选参数化变分分布\n",
    "        这里我们使用参数化beta分布\n",
    "        \"\"\"\n",
    "        if self.solver=='pyro':\n",
    "            alpha_q = pyro.param('alpha_q', torch.tensor(0.5),\n",
    "                            constraint=constraints.positive)\n",
    "            beta_q = pyro.param('beta_q', torch.tensor(0.5),\n",
    "                            constraint=constraints.positive)\n",
    "            pyro.sample('theta', dist.Beta(alpha_q, beta_q))\n",
    "\n",
    "        else:\n",
    "            alpha_q = numpyro.param('alpha_q', 10,\n",
    "                            constraint=nconstraints.positive)\n",
    "            beta_q = numpyro.param('beta_q', 10,\n",
    "                            constraint=nconstraints.positive)\n",
    "\n",
    "            numpyro.sample('theta', ndist.Beta(alpha_q, beta_q))\n",
    "\n",
    "\n",
    "    def truncnormal_guide(self, data):\n",
    "        \"\"\"\n",
    "        定义用于在Pyro/Numpyro中近似后验的候选参数化变分分布\n",
    "        这里我们使用[0,1]上的截断正态分布\n",
    "        \"\"\"\n",
    "        loc = numpyro.param('loc', 0.5,\n",
    "                        constraint=nconstraints.interval(0.0, 1.0))\n",
    "        scale = numpyro.param('scale', 1,\n",
    "                        constraint=nconstraints.positive)\n",
    "        numpyro.sample('theta', ndist.TruncatedNormal(loc, scale, low=0.0, high=1.0))\n",
    "\n",
    "\n",
    "    def SVI_init(self, guide_dist, lr=0.0005):\n",
    "        \"\"\"\n",
    "        使用Adam优化器初始化SVI训练模式\n",
    "        注意：truncnormal_guide只能与numpyro求解器一起使用\n",
    "        \"\"\"\n",
    "        adam_params = {\"lr\": lr}\n",
    "\n",
    "        if guide_dist=='beta':\n",
    "            if self.solver=='pyro':\n",
    "                optimizer = Adam(adam_params)\n",
    "                svi = SVI(self.model, self.beta_guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "            elif self.solver=='numpyro':\n",
    "                optimizer = nAdam(step_size=lr)\n",
    "                svi = nSVI(self.model, self.beta_guide, optimizer, loss=nTrace_ELBO())\n",
    "\n",
    "        elif guide_dist=='normal':\n",
    "            # 仅允许numpyro\n",
    "            if self.solver=='pyro':\n",
    "                print(\"警告：请使用Numpyro和TruncatedNormal指导\")\n",
    "                svi = None\n",
    "\n",
    "            elif self.solver=='numpyro':\n",
    "                optimizer = nAdam(step_size=lr)\n",
    "                svi = nSVI(self.model, self.truncnormal_guide, optimizer, loss=nTrace_ELBO())\n",
    "        else:\n",
    "            print(\"警告：请输入'beta'或'normal'\")\n",
    "            svi = None\n",
    "\n",
    "        return svi\n",
    "\n",
    "    def SVI_run(self, data, guide_dist, n_steps=10000):\n",
    "        \"\"\"\n",
    "        运行SVI并返回优化后的参数和损失\n",
    "\n",
    "        返回值\n",
    "        --------\n",
    "        params : 指导分布的学习参数\n",
    "        losses : 每一步的损失向量\n",
    "        \"\"\"\n",
    "\n",
    "        # 初始化SVI\n",
    "        svi = self.SVI_init(guide_dist=guide_dist)\n",
    "\n",
    "        # 执行梯度步骤\n",
    "        if self.solver=='pyro':\n",
    "             # 张量化数据\n",
    "            if not torch.is_tensor(data):\n",
    "                data = torch.tensor(data)\n",
    "            # 存储损失向量\n",
    "            losses = np.zeros(n_steps)\n",
    "            for step in range(n_steps):\n",
    "                losses[step] = svi.step(data)\n",
    "\n",
    "            # pyro仅支持beta VI分布\n",
    "            params = {\n",
    "                'alpha_q': pyro.param('alpha_q').item(),\n",
    "                'beta_q': pyro.param('beta_q').item()\n",
    "                }\n",
    "\n",
    "        elif self.solver=='numpyro':\n",
    "            data = np.array(data, dtype=float)\n",
    "            result = svi.run(self.rng_key, n_steps, data, progress_bar=False)\n",
    "            params = dict(\n",
    "                (key, np.asarray(value)) for key, value in result.params.items()\n",
    "                )\n",
    "            losses = np.asarray(result.losses)\n",
    "\n",
    "        return params, losses"
   ]
  }
 ],
 "metadata": {
  "date": 1750032241.0719717,
  "filename": "bayes_nonconj.md",
  "kernelspec": {
   "display_name": "Python",
   "language": "python3",
   "name": "python3"
  },
  "title": "非共轭先验"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}