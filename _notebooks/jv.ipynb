{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5937429a",
   "metadata": {},
   "source": [
    "\n",
    "<a id='jv'></a>\n",
    "<div id=\"qe-notebook-header\" align=\"right\" style=\"text-align:right;\">\n",
    "        <a href=\"https://quantecon.org/\" title=\"quantecon.org\">\n",
    "                <img style=\"width:250px;display:inline;\" width=\"250px\" src=\"https://assets.quantecon.org/img/qe-menubar-logo.svg\" alt=\"QuantEcon\">\n",
    "        </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed710b62",
   "metadata": {},
   "source": [
    "# 工作搜寻 VI：在职搜索\n",
    "\n",
    "\n",
    "<a id='index-1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fe966f",
   "metadata": {},
   "source": [
    "## 目录\n",
    "\n",
    "- [工作搜寻 VI：在职搜索](#工作搜寻-VI：在职搜索)  \n",
    "  - [概述](#概述)  \n",
    "  - [模型](#模型)  \n",
    "  - [实施](#实施)  \n",
    "  - [求解政策](#求解政策)  \n",
    "  - [练习](#练习)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb84704b",
   "metadata": {},
   "source": [
    "## 概述\n",
    "\n",
    "在本节中，我们将解决一个简单的在职搜索模型\n",
    "\n",
    "- 基于 [[Ljungqvist and Sargent, 2018](https://python.quantecon.org/zreferences.html#id186)] 的练习 6.18 和 [[Jovanovic, 1979](https://python.quantecon.org/zreferences.html#id100)]  \n",
    "\n",
    "\n",
    "让我们从一些导入开始："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c5ff48",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "FONTPATH = \"fonts/SourceHanSerifSC-SemiBold.otf\"\n",
    "mpl.font_manager.fontManager.addfont(FONTPATH)\n",
    "plt.rcParams['font.family'] = ['Source Han Serif SC']\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from numba import jit, prange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2177e6f5",
   "metadata": {},
   "source": [
    "### 模型特点\n",
    "\n",
    "\n",
    "<a id='index-2'></a>\n",
    "- 结合在职搜索的工作特定人力资本积累  \n",
    "- 具有一个状态变量和两个控制变量的无限期动态规划  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d78d0b",
   "metadata": {},
   "source": [
    "## 模型\n",
    "\n",
    "\n",
    "<a id='index-3'></a>\n",
    "令 $ x_t $ 表示在特定公司就职的工人在 t 时刻的工作特定人力资本，$ w_t $ 表示当前工资。\n",
    "\n",
    "令 $ w_t = x_t(1 - s_t - \\phi_t) $，其中\n",
    "\n",
    "- $ \\phi_t $ 是对当前职位的工作特定人力资本投资，且  \n",
    "- $ s_t $ 是用于获取其他公司新工作机会的搜索努力。  \n",
    "\n",
    "\n",
    "只要工人继续留在当前工作，$ \\{x_t\\} $ 的演变由 $ x_{t+1} = g(x_t, \\phi_t) $ 给出。\n",
    "\n",
    "当 t 时刻的搜索努力为 $ s_t $ 时，工人以概率 $ \\pi(s_t) \\in [0, 1] $ 收到新的工作机会。\n",
    "\n",
    "这个机会的价值（以工作特定人力资本衡量）是 $ u_{t+1} $，其中 $ \\{u_t\\} $ 是具有共同分布 $ f $ 的独立同分布序列。\n",
    "\n",
    "工人可以拒绝当前的工作机会并继续现有的工作。\n",
    "\n",
    "因此，如果接受则 $ x_{t+1} = u_{t+1} $，否则 $ x_{t+1} = g(x_t, \\phi_t) $。\n",
    "\n",
    "令 $ b_{t+1} \\in \\{0,1\\} $ 为二元随机变量，其中 $ b_{t+1} = 1 $ 表示工人在时间 $ t $ 结束时收到一个工作机会。\n",
    "\n",
    "我们可以写成\n",
    "\n",
    "\n",
    "<a id='equation-jd'></a>\n",
    "$$\n",
    "x_{t+1}\n",
    "= (1 - b_{t+1}) g(x_t, \\phi_t) + b_{t+1}\n",
    "    \\max \\{ g(x_t, \\phi_t), u_{t+1}\\} \\tag{32.1}\n",
    "$$\n",
    "\n",
    "代理人的目标：通过控制变量 $ \\{s_t\\} $ 和 $ \\{\\phi_t\\} $ 来最大化预期折现工资总和。\n",
    "\n",
    "对 $ v(x_{t+1}) $ 取期望并使用 [(32.1)](#equation-jd)，\n",
    "这个问题的贝尔曼方程可以写成\n",
    "\n",
    "\n",
    "<a id='equation-jvbell'></a>\n",
    "$$\n",
    "v(x)\n",
    "= \\max_{s + \\phi \\leq 1}\n",
    "    \\left\\{\n",
    "        x (1 - s - \\phi) + \\beta (1 - \\pi(s)) v[g(x, \\phi)] +\n",
    "        \\beta \\pi(s) \\int v[g(x, \\phi) \\vee u] f(du)\n",
    "     \\right\\} \\tag{32.2}\n",
    "$$\n",
    "\n",
    "这里默认 $ s $ 和 $ \\phi $ 非负，而\n",
    "$ a \\vee b := \\max\\{a, b\\} $。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c9d0b1",
   "metadata": {},
   "source": [
    "### 参数化\n",
    "\n",
    "\n",
    "<a id='index-4'></a>\n",
    "在下面的实现中，我们将关注参数化\n",
    "\n",
    "$$\n",
    "g(x, \\phi) = A (x \\phi)^{\\alpha},\n",
    "\\quad\n",
    "\\pi(s) = \\sqrt s\n",
    "\\quad \\text{和} \\quad\n",
    "f = \\text{Beta}(2, 2)\n",
    "$$\n",
    "\n",
    "默认参数值为\n",
    "\n",
    "- $ A = 1.4 $  \n",
    "- $ \\alpha = 0.6 $  \n",
    "- $ \\beta = 0.96 $  \n",
    "\n",
    "\n",
    "$ \\text{Beta}(2,2) $ 分布的支撑集是 $ (0,1) $ - 它具有单峰、对称的密度函数，峰值在0.5。\n",
    "\n",
    "\n",
    "<a id='jvboecalc'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e011c0dd",
   "metadata": {},
   "source": [
    "### 粗略计算\n",
    "\n",
    "在我们求解模型之前，让我们做一些快速计算，以直观地了解解应该是什么样子。\n",
    "\n",
    "首先，注意到工人有两种方式来积累资本从而提高工资：\n",
    "\n",
    "1. 通过 $ \\phi $ 投资于当前工作的特定资本  \n",
    "1. 通过 $ s $ 搜索具有更好的工作特定资本匹配的新工作  \n",
    "\n",
    "\n",
    "由于工资是 $ x (1 - s - \\phi) $，通过 $ \\phi $ 或 $ s $ 进行投资的边际成本是相同的。\n",
    "\n",
    "我们的风险中性工人应该专注于预期回报最高的工具。\n",
    "\n",
    "相对预期回报将取决于$ x $。\n",
    "\n",
    "例如，首先假设$ x = 0.05 $\n",
    "\n",
    "- 如果$ s=1 $且$ \\phi = 0 $，由于$ g(x,\\phi) = 0 $，\n",
    "  对[(32.1)](#equation-jd)取期望值得到下一期的预期资本等于$ \\pi(s) \\mathbb{E} u\n",
    "  = \\mathbb{E} u = 0.5 $。  \n",
    "- 如果$ s=0 $且$ \\phi=1 $，那么下一期资本是$ g(x, \\phi) = g(0.05, 1) \\approx 0.23 $。  \n",
    "\n",
    "\n",
    "两种回报率都不错，但搜索的回报更好。\n",
    "\n",
    "接下来，假设$ x = 0.4 $\n",
    "\n",
    "- 如果$ s=1 $且$ \\phi = 0 $，那么下一期的预期资本仍然是$ 0.5 $  \n",
    "- 如果$ s=0 $且$ \\phi = 1 $，那么$ g(x, \\phi) = g(0.4, 1) \\approx 0.8 $  \n",
    "\n",
    "\n",
    "通过$ \\phi $投资的回报超过了搜索的预期回报。\n",
    "\n",
    "综合这些观察，我们得到两个非正式的预测：\n",
    "\n",
    "1. 在任何给定状态$ x $下，两个控制变量$ \\phi $和$ s $将  \n",
    "\n",
    "\n",
    "主要作为替代品 — 工人会专注于预期回报较高的工具。\n",
    "\n",
    "1. 对于足够小的 $ x $，搜索会比投资工作特定人力资本更可取。对于较大的 $ x $，则相反。  \n",
    "\n",
    "\n",
    "现在让我们转向实施，看看是否能验证我们的预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b02c2dc",
   "metadata": {},
   "source": [
    "## 实施\n",
    "\n",
    "\n",
    "<a id='index-5'></a>\n",
    "我们将设置一个`JVWorker`类来保存上述模型的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1165e4",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "class JVWorker:\n",
    "    r\"\"\"\n",
    "    一个Jovanovic类型的就业模型，包含在职搜索。\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 A=1.4,\n",
    "                 α=0.6,\n",
    "                 β=0.96,         # 折现因子\n",
    "                 π=np.sqrt,      # 搜索努力函数\n",
    "                 a=2,            # f的参数\n",
    "                 b=2,            # f的参数\n",
    "                 grid_size=50,\n",
    "                 mc_size=100,\n",
    "                 ɛ=1e-4):\n",
    "\n",
    "        self.A, self.α, self.β, self.π = A, α, β, π\n",
    "        self.mc_size, self.ɛ = mc_size, ɛ\n",
    "\n",
    "        self.g = jit(lambda x, ϕ: A * (x * ϕ)**α)    # 转移函数\n",
    "        self.f_rvs = np.random.beta(a, b, mc_size)\n",
    "\n",
    "        # 网格的最大值是f的大分位数值和固定点y = g(y, 1)的最大值\n",
    "        ɛ = 1e-4\n",
    "        grid_max = max(A**(1 / (1 - α)), stats.beta(a, b).ppf(1 - ɛ))\n",
    "\n",
    "        # 人力资本\n",
    "        self.x_grid = np.linspace(ɛ, grid_max, grid_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e98c4f",
   "metadata": {},
   "source": [
    "函数`operator_factory`接收这个类的实例并返回Bellman算子`T`的jit编译版本，即：\n",
    "\n",
    "$$\n",
    "Tv(x)\n",
    "= \\max_{s + \\phi \\leq 1} w(s, \\phi)\n",
    "$$\n",
    "\n",
    "其中\n",
    "\n",
    "\n",
    "<a id='equation-defw'></a>\n",
    "$$\n",
    "w(s, \\phi)\n",
    " := x (1 - s - \\phi) + \\beta (1 - \\pi(s)) v[g(x, \\phi)] +\n",
    "         \\beta \\pi(s) \\int v[g(x, \\phi) \\vee u] f(du) \\tag{32.3}\n",
    "$$\n",
    "\n",
    "当我们表示$ v $时，将使用NumPy数组`v`在网格`x_grid`上给出值。\n",
    "\n",
    "但要计算[(32.3)](#equation-defw)右侧，我们需要一个函数，所以我们用函数`v_func`替换数组`v`和`x_grid`，该函数在`x_grid`上对`v`进行线性插值。\n",
    "\n",
    "在`for`循环内部，对状态空间网格中的每个`x`，我们设置函数$ w(z) = w(s, \\phi) $，如[(32.3)](#equation-defw)中定义。\n",
    "\n",
    "该函数在所有可行的$ (s, \\phi) $对上最大化。\n",
    "\n",
    "另一个函数`get_greedy`在给定值函数的情况下，返回每个$ x $处$ s $和$ \\phi $的最优选择。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c0e47e",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def operator_factory(jv, parallel_flag=True):\n",
    "\n",
    "    \"\"\"\n",
    "    返回Bellman算子T的jit编译版本\n",
    "\n",
    "    jv是JVWorker的一个实例\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    π, β = jv.π, jv.β\n",
    "    x_grid, ɛ, mc_size = jv.x_grid, jv.ɛ, jv.mc_size\n",
    "    f_rvs, g = jv.f_rvs, jv.g\n",
    "\n",
    "    @jit\n",
    "    def state_action_values(z, x, v):\n",
    "        s, ϕ = z\n",
    "        v_func = lambda x: np.interp(x, x_grid, v)\n",
    "\n",
    "        integral = 0\n",
    "        for m in range(mc_size):\n",
    "            u = f_rvs[m]\n",
    "            integral += v_func(max(g(x, ϕ), u))\n",
    "        integral = integral / mc_size\n",
    "\n",
    "        q = π(s) * integral + (1 - π(s)) * v_func(g(x, ϕ))\n",
    "        return x * (1 - ϕ - s) + β * q\n",
    "\n",
    "    @jit(parallel=parallel_flag)\n",
    "    def T(v):\n",
    "        \"\"\"\n",
    "        Bellman算子\n",
    "        \"\"\"\n",
    "\n",
    "        v_new = np.empty_like(v)\n",
    "        for i in prange(len(x_grid)):\n",
    "            x = x_grid[i]\n",
    "\n",
    "            # 在网格上搜索\n",
    "            search_grid = np.linspace(ɛ, 1, 15)\n",
    "            max_val = -1\n",
    "            for s in search_grid:\n",
    "                for ϕ in search_grid:\n",
    "                    current_val = state_action_values((s, ϕ), x, v) if s + ϕ <= 1 else -1\n",
    "                    if current_val > max_val:\n",
    "                        max_val = current_val\n",
    "            v_new[i] = max_val\n",
    "\n",
    "        return v_new\n",
    "\n",
    "    @jit\n",
    "    def get_greedy(v):\n",
    "        \"\"\"\n",
    "        计算给定函数v的v-贪婪策略\n",
    "        \"\"\"\n",
    "        s_policy, ϕ_policy = np.empty_like(v), np.empty_like(v)\n",
    "\n",
    "        for i in range(len(x_grid)):\n",
    "            x = x_grid[i]\n",
    "            # 在网格上搜索\n",
    "            search_grid = np.linspace(ɛ, 1, 15)\n",
    "            max_val = -1\n",
    "            for s in search_grid:\n",
    "                for ϕ in search_grid:\n",
    "                    current_val = state_action_values((s, ϕ), x, v) if s + ϕ <= 1 else -1\n",
    "                    if current_val > max_val:\n",
    "                        max_val = current_val\n",
    "                        max_s, max_ϕ = s, ϕ\n",
    "                        s_policy[i], ϕ_policy[i] = max_s, max_ϕ\n",
    "        return s_policy, ϕ_policy\n",
    "\n",
    "    return T, get_greedy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05605271",
   "metadata": {},
   "source": [
    "为了求解模型，我们将编写一个使用贝尔曼算子并通过迭代寻找不动点的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39767e4",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def solve_model(jv,\n",
    "                use_parallel=True,\n",
    "                tol=1e-4,\n",
    "                max_iter=1000,\n",
    "                verbose=True,\n",
    "                print_skip=25):\n",
    "\n",
    "    \"\"\"\n",
    "    通过值函数迭代求解模型\n",
    "\n",
    "    * jv 是 JVWorker 的一个实例\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    T, _ = operator_factory(jv, parallel_flag=use_parallel)\n",
    "\n",
    "    # 设置循环\n",
    "    v = jv.x_grid * 0.5  # 初始条件\n",
    "    i = 0\n",
    "    error = tol + 1\n",
    "\n",
    "    while i < max_iter and error > tol:\n",
    "        v_new = T(v)\n",
    "        error = np.max(np.abs(v - v_new))\n",
    "        i += 1\n",
    "        if verbose and i % print_skip == 0:\n",
    "            print(f\"第{i}次迭代的误差为{error}。\")\n",
    "        v = v_new\n",
    "\n",
    "    if error > tol:\n",
    "        print(\"未能收敛！\")\n",
    "    elif verbose:\n",
    "        print(f\"\\n在第{i}次迭代后收敛。\")\n",
    "\n",
    "    return v_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42289a81",
   "metadata": {},
   "source": [
    "## 求解政策\n",
    "\n",
    "\n",
    "<a id='index-6'></a>\n",
    "让我们生成最优政策并看看它们是什么样子。\n",
    "\n",
    "\n",
    "<a id='jv-policies'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f580048d",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "jv = JVWorker()\n",
    "T, get_greedy = operator_factory(jv)\n",
    "v_star = solve_model(jv)\n",
    "s_star, ϕ_star = get_greedy(v_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4a06b2",
   "metadata": {},
   "source": [
    "以下是这些图表："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7bac4b",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "plots = [s_star, ϕ_star, v_star]\n",
    "titles = [\"s策略\", \"ϕ策略\",  \"价值函数\"]\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 12))\n",
    "\n",
    "for ax, plot, title in zip(axes, plots, titles):\n",
    "    ax.plot(jv.x_grid, plot)\n",
    "    ax.set(title=title)\n",
    "    ax.grid()\n",
    "\n",
    "axes[-1].set_xlabel(\"x\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ccc821",
   "metadata": {},
   "source": [
    "横轴表示状态 $ x $，纵轴表示 $ s(x) $ 和 $ \\phi(x) $。\n",
    "\n",
    "总的来说，这些策略与我们在[上文](#jvboecalc)中的预测相符\n",
    "\n",
    "- 工人根据相对回报在两种投资策略之间切换。  \n",
    "- 对于较低的 $ x $ 值，最佳选择是寻找新工作。  \n",
    "- 一旦 $ x $ 变大，工人通过投资于当前职位的特定人力资本会获得更好的回报。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a5decd",
   "metadata": {},
   "source": [
    "## 练习"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f621403",
   "metadata": {},
   "source": [
    "## Exercise 32.1\n",
    "\n",
    "让我们看看与这些策略相关的状态过程 $ \\{x_t\\} $ 的动态特征。\n",
    "\n",
    "当根据最优策略选择 $ \\phi_t $ 和 $ s_t $，且 $ \\mathbb{P}\\{b_{t+1} = 1\\} = \\pi(s_t) $ 时，动态特征由[(32.1)](#equation-jd)给出。\n",
    "\n",
    "由于动态是随机的，分析会有些微妙。\n",
    "\n",
    "一种方法是对一个相对精细的网格（称为`plot_grid`）中的每个 $ x $，绘制大量（$ K $个）在给定 $ x_t = x $ 条件下 $ x_{t+1} $ 的实现值。\n",
    "\n",
    "用以下方式绘制每个实现对应一个点的45度图,设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de1ad30",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "jv = JVWorker(grid_size=25, mc_size=50)\n",
    "plot_grid_max, plot_grid_size = 1.2, 100\n",
    "plot_grid = np.linspace(0, plot_grid_max, plot_grid_size)\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim(0, plot_grid_max)\n",
    "ax.set_ylim(0, plot_grid_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1847503",
   "metadata": {},
   "source": [
    "通过观察图表,可以论证在最优策略下,状态 $ x_t $ 将收敛到接近1的常数值 $ \\bar x $。\n",
    "\n",
    "论证在稳态时, $ s_t \\approx 0 $ 且 $ \\phi_t \\approx 0.6 $。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22520343",
   "metadata": {},
   "source": [
    "## Solution to[ Exercise 32.1](https://python.quantecon.org/#jv_ex1)\n",
    "\n",
    "以下是生成45度图的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9fc899",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "jv = JVWorker(grid_size=25, mc_size=50)\n",
    "π, g, f_rvs, x_grid = jv.π, jv.g, jv.f_rvs, jv.x_grid\n",
    "T, get_greedy = operator_factory(jv)\n",
    "v_star = solve_model(jv, verbose=False)\n",
    "s_policy, ϕ_policy = get_greedy(v_star)\n",
    "\n",
    "# 将策略函数数组转换为实际函数\n",
    "s = lambda y: np.interp(y, x_grid, s_policy)\n",
    "ϕ = lambda y: np.interp(y, x_grid, ϕ_policy)\n",
    "\n",
    "def h(x, b, u):\n",
    "    return (1 - b) * g(x, ϕ(x)) + b * max(g(x, ϕ(x)), u)\n",
    "\n",
    "\n",
    "plot_grid_max, plot_grid_size = 1.2, 100\n",
    "plot_grid = np.linspace(0, plot_grid_max, plot_grid_size)\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ticks = (0.25, 0.5, 0.75, 1.0)\n",
    "ax.set(xticks=ticks, yticks=ticks,\n",
    "       xlim=(0, plot_grid_max),\n",
    "       ylim=(0, plot_grid_max),\n",
    "       xlabel='$x_t$', ylabel='$x_{t+1}$')\n",
    "\n",
    "ax.plot(plot_grid, plot_grid, 'k--', alpha=0.6)  # 45度线\n",
    "for x in plot_grid:\n",
    "    for i in range(jv.mc_size):\n",
    "        b = 1 if np.random.uniform(0, 1) < π(s(x)) else 0\n",
    "        u = f_rvs[i]\n",
    "        y = h(x, b, u)\n",
    "        ax.plot(x, y, 'go', alpha=0.25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45700536",
   "metadata": {},
   "source": [
    "观察动态变化，我们可以看到\n",
    "\n",
    "- 如果 $ x_t $ 低于约0.2，动态变化是随机的，但\n",
    "  $ x_{t+1} > x_t $ 的可能性很大。  \n",
    "- 随着 $ x_t $ 增加，动态变化变得确定性，并且\n",
    "  $ x_t $ 收敛到接近1的稳态值。  \n",
    "\n",
    "\n",
    "参考回 [这里](#jv-policies) 的图表，我们看到 $ x_t \\approx 1 $ 意味着\n",
    "$ s_t = s(x_t) \\approx 0 $ 且\n",
    "$ \\phi_t = \\phi(x_t) \\approx 0.6 $。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5841fd",
   "metadata": {},
   "source": [
    "## Exercise 32.2\n",
    "\n",
    "在 Exercise 32.1 中，我们发现 $ s_t $ 收敛到零，\n",
    "而 $ \\phi_t $ 收敛到约0.6。\n",
    "\n",
    "由于这些结果是在 $ \\beta $ 接近1的情况下计算的，\n",
    "让我们将它们与*无限*耐心的工人的最佳选择进行比较。\n",
    "\n",
    "直观地说，无限耐心的工人会希望最大化稳态工资，\n",
    "而稳态工资是稳态资本的函数。\n",
    "\n",
    "你可以认为这是既定事实——这确实是真的——无限耐心的工人\n",
    "在长期内不会搜索（即，对于较大的 $ t $，$ s_t = 0 $）。\n",
    "\n",
    "因此，给定 $ \\phi $，稳态资本是映射 $ x \\mapsto g(x, \\phi) $ 的正固定点 $ x^*(\\phi) $。\n",
    "\n",
    "稳态工资可以写作 $ w^*(\\phi) = x^*(\\phi) (1 - \\phi) $。\n",
    "\n",
    "绘制 $ w^*(\\phi) $ 关于 $ \\phi $ 的图像，并研究 $ \\phi $ 的最佳选择。\n",
    "\n",
    "你能对你看到的值给出一个大致的解释吗？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93afd28e",
   "metadata": {},
   "source": [
    "## Solution to[ Exercise 32.2](https://python.quantecon.org/#jv_ex2)\n",
    "\n",
    "可以用以下方法生成图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322fab36",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "jv = JVWorker()\n",
    "\n",
    "def xbar(ϕ):\n",
    "    A, α = jv.A, jv.α\n",
    "    return (A * ϕ**α)**(1 / (1 - α))\n",
    "\n",
    "ϕ_grid = np.linspace(0, 1, 100)\n",
    "fig, ax = plt.subplots(figsize=(9, 7))\n",
    "ax.set(xlabel='$\\phi$')\n",
    "ax.plot(ϕ_grid, [xbar(ϕ) * (1 - ϕ) for ϕ in ϕ_grid], label='$w^*(\\phi)$')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcc9c94",
   "metadata": {},
   "source": [
    "观察到最大值约在0.6处。\n",
    "\n",
    "这与Exercise 32.1中得到的$ \\phi $的长期值相似。\n",
    "\n",
    "因此，无限耐心的工人的行为与$ \\beta = 0.96 $的工人的行为相似。\n",
    "\n",
    "这看起来是合理的，并且帮助我们确认我们的动态规划解可能是正确的。"
   ]
  }
 ],
 "metadata": {
  "date": 1747366409.5750039,
  "filename": "jv.md",
  "kernelspec": {
   "display_name": "Python",
   "language": "python3",
   "name": "python3"
  },
  "title": "工作搜寻 VI：在职搜索"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}