{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28d1a032",
   "metadata": {},
   "source": [
    "\n",
    "<a id='likelihood-ratio-process'></a>\n",
    "<div id=\"qe-notebook-header\" align=\"right\" style=\"text-align:right;\">\n",
    "        <a href=\"https://quantecon.org/\" title=\"quantecon.org\">\n",
    "                <img style=\"width:250px;display:inline;\" width=\"250px\" src=\"https://assets.quantecon.org/img/qe-menubar-logo.svg\" alt=\"QuantEcon\">\n",
    "        </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3576f4fd",
   "metadata": {},
   "source": [
    "# 似然比过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44313380",
   "metadata": {},
   "source": [
    "## 目录\n",
    "\n",
    "- [似然比过程](#似然比过程)  \n",
    "  - [概述](#概述)  \n",
    "  - [似然比过程](#似然比过程)  \n",
    "  - [自然永久地从密度 g 中抽取](#自然永久地从密度-g-中抽取)  \n",
    "  - [特殊性质](#特殊性质)  \n",
    "  - [自然永久地从密度f中抽样](#自然永久地从密度f中抽样)  \n",
    "  - [似然比检验](#似然比检验)  \n",
    "  - [Kullback–Leibler 散度](#Kullback–Leibler-散度)  \n",
    "  - [后续内容](#后续内容)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f477572b",
   "metadata": {},
   "source": [
    "## 概述\n",
    "\n",
    "本讲座介绍似然比过程及其一些用途。\n",
    "\n",
    "我们将使用[本讲座](https://python.quantecon.org/exchangeable.html)中描述的设置。\n",
    "\n",
    "我们将学习的内容包括：\n",
    "\n",
    "- 似然比过程的一个特殊性质  \n",
    "- 似然比过程如何成为频率派假设检验中的关键要素  \n",
    "- **接收者操作特征曲线**如何总结频率论假设检验中的虚警概率和检验效能的信息  \n",
    "- 在第二次世界大战期间，美国海军制定了一个决策规则，Garret L. Schyler上尉对此提出质疑，并要求Milton Friedman向他解释其合理性，这个话题将在[本讲座中](https://python.quantecon.org/wald_friedman.html)进行研究  \n",
    "\n",
    "\n",
    "让我们先导入一些Python工具。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d10421",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "FONTPATH = \"fonts/SourceHanSerifSC-SemiBold.otf\"\n",
    "mpl.font_manager.fontManager.addfont(FONTPATH)\n",
    "plt.rcParams['font.family'] = ['Source Han Serif SC']\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (11, 5)  #设置默认图形大小\n",
    "import numpy as np\n",
    "from numba import vectorize, jit\n",
    "from math import gamma\n",
    "from scipy.integrate import quad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfff96f",
   "metadata": {},
   "source": [
    "## 似然比过程\n",
    "\n",
    "一个非负随机变量 $ W $ 具有两个概率密度函数之一，要么是 $ f $，要么是 $ g $。\n",
    "\n",
    "在时间开始之前，自然界一劳永逸地决定是从 $ f $ 还是 $ g $ 中抽取一系列独立同分布的样本。\n",
    "\n",
    "我们有时会用 $ q $ 表示自然界一劳永逸选择的密度函数，所以 $ q $ 要么是 $ f $ 要么是 $ g $，且是永久性的。\n",
    "\n",
    "自然界知道它永久性地从哪个密度函数中抽样，但我们这些观察者并不知道。\n",
    "\n",
    "我们知道 $ f $ 和 $ g $ 这两个密度函数，但不知道自然界选择了哪一个。\n",
    "\n",
    "但我们想要知道。\n",
    "\n",
    "为此，我们使用观测值。\n",
    "\n",
    "我们观察到一个序列 $ \\{w_t\\}_{t=1}^T $，它包含 $ T $ 个从 $ f $ 或 $ g $ 中抽取的独立同分布样本。\n",
    "\n",
    "我们想要利用这些观测值来推断自然界选择了 $ f $ 还是 $ g $。\n",
    "\n",
    "**似然比过程**是完成这项任务的有用工具。\n",
    "\n",
    "首先，我们定义似然比过程的一个关键组成部分，即时间 $ t $ 的似然比，它是如下随机变量\n",
    "\n",
    "$$\n",
    "\\ell (w_t)=\\frac{f\\left(w_t\\right)}{g\\left(w_t\\right)},\\quad t\\geq1.\n",
    "$$\n",
    "\n",
    "我们假设 $ f $ 和 $ g $ 在随机变量 $ W $ 的相同可能实现区间上都具有正概率。\n",
    "\n",
    "这意味着在 $ g $ 密度下，$ \\ell (w_t)=\n",
    "\\frac{f\\left(w_{t}\\right)}{g\\left(w_{t}\\right)} $\n",
    "显然是一个均值为1的非负随机变量。\n",
    "\n",
    "对序列 $ \\left\\{ w_{t}\\right\\} _{t=1}^{\\infty} $ 的**似然比过程**定义为\n",
    "\n",
    "$$\n",
    "L\\left(w^{t}\\right)=\\prod_{i=1}^{t} \\ell (w_i),\n",
    "$$\n",
    "\n",
    "其中 $ w^t=\\{ w_1,\\dots,w_t\\} $ 是直到时间 $ t $ （包括 $ t $）的观测历史。\n",
    "\n",
    "有时为简便起见，我们会写作 $ L_t =  L(w^t) $。\n",
    "\n",
    "注意，似然比过程满足以下*递归*或*乘法分解*\n",
    "\n",
    "$$\n",
    "L(w^t) = \\ell (w_t) L (w^{t-1}) .\n",
    "$$\n",
    "\n",
    "似然比及其对数是使用 Neyman 和 Pearson [[Neyman and Pearson, 1933](https://python.quantecon.org/zreferences.html#id255)] 的经典频率派方法进行推断的关键工具。\n",
    "\n",
    "为了帮助我们理解其工作原理，以下Python代码将$ f $和$ g $评估为两个不同的beta分布，然后通过从两个概率分布之一生成序列$ w^t $（例如，从$ g $生成的IID序列）来计算和模拟相关的似然比过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc4d217",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# 两个beta分布中的参数\n",
    "F_a, F_b = 1, 1\n",
    "G_a, G_b = 3, 1.2\n",
    "\n",
    "@vectorize\n",
    "def p(x, a, b):\n",
    "    r = gamma(a + b) / (gamma(a) * gamma(b))\n",
    "    return r * x** (a-1) * (1 - x) ** (b-1)\n",
    "\n",
    "# 两个密度函数\n",
    "f = jit(lambda x: p(x, F_a, F_b))\n",
    "g = jit(lambda x: p(x, G_a, G_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0585095",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def simulate(a, b, T=50, N=500):\n",
    "    '''\n",
    "    生成N组T个似然比观测值，\n",
    "    以N x T矩阵形式返回。\n",
    "\n",
    "    '''\n",
    "\n",
    "    l_arr = np.empty((N, T))\n",
    "\n",
    "    for i in range(N):\n",
    "\n",
    "        for j in range(T):\n",
    "            w = np.random.beta(a, b)\n",
    "            l_arr[i, j] = f(w) / g(w)\n",
    "\n",
    "    return l_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e693ca7",
   "metadata": {},
   "source": [
    "## 自然永久地从密度 g 中抽取\n",
    "\n",
    "我们首先模拟当自然永久地从 $ g $ 中抽取时的似然比过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d4cda1",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "l_arr_g = simulate(G_a, G_b)\n",
    "l_seq_g = np.cumprod(l_arr_g, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08e41d1",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "N, T = l_arr_g.shape\n",
    "\n",
    "for i in range(N):\n",
    "\n",
    "    plt.plot(range(T), l_seq_g[i, :], color='b', lw=0.8, alpha=0.5)\n",
    "\n",
    "plt.ylim([0, 3])\n",
    "plt.title(\"$L(w^{t})$ 路径\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2aaacb",
   "metadata": {},
   "source": [
    "显然，随着样本长度 $ T $ 的增长，大部分概率质量向零偏移\n",
    "\n",
    "为了更清楚地看到这一点，我们绘制了随时间变化的路径分数 $ L\\left(w^{t}\\right) $ 落在区间 $ \\left[0, 0.01\\right] $ 内的比例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058c63f5",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "plt.plot(range(T), np.sum(l_seq_g <= 0.01, axis=0) / N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4a9818",
   "metadata": {},
   "source": [
    "尽管大部分概率质量明显收敛到接近$ 0 $的一个很小区间内，但在概率密度$ g $下，$ L\\left(w^t\\right) $的无条件均值对所有$ t $恒等于$ 1 $。\n",
    "\n",
    "为了验证这个断言，首先注意到如前所述，对所有$ t $，无条件均值$ E\\left[\\ell \\left(w_{t}\\right)\\bigm|q=g\\right] $等于$ 1 $：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "E\\left[\\ell \\left(w_{t}\\right)\\bigm|q=g\\right]  &=\\int\\frac{f\\left(w_{t}\\right)}{g\\left(w_{t}\\right)}g\\left(w_{t}\\right)dw_{t} \\\\\n",
    "    &=\\int f\\left(w_{t}\\right)dw_{t} \\\\\n",
    "    &=1,\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "这直接推出\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "E\\left[L\\left(w^{1}\\right)\\bigm|q=g\\right]  &=E\\left[\\ell \\left(w_{1}\\right)\\bigm|q=g\\right]\\\\\n",
    "    &=1.\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "因为$ L(w^t) = \\ell(w_t) L(w^{t-1}) $且$ \\{w_t\\}_{t=1}^t $是IID序列，我们有\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "E\\left[L\\left(w^{t}\\right)\\bigm|q=g\\right]  &=E\\left[L\\left(w^{t-1}\\right)\\ell \\left(w_{t}\\right)\\bigm|q=g\\right] \\\\\n",
    "\n",
    "&=E\\left[L\\left(w^{t-1}\\right)E\\left[\\ell \\left(w_{t}\\right)\\bigm|q=g,w^{t-1}\\right]\\bigm|q=g\\right] \\\\\n",
    "    &=E\\left[L\\left(w^{t-1}\\right)E\\left[\\ell \\left(w_{t}\\right)\\bigm|q=g\\right]\\bigm|q=g\\right] \\\\\n",
    "    &=E\\left[L\\left(w^{t-1}\\right)\\bigm|q=g\\right] \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "对任意 $ t \\geq 1 $。\n",
    "\n",
    "数学归纳法表明\n",
    "$ E\\left[L\\left(w^{t}\\right)\\bigm|q=g\\right]=1 $ 对所有\n",
    "$ t \\geq 1 $ 成立。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d2d74a",
   "metadata": {},
   "source": [
    "## 特殊性质\n",
    "\n",
    "当似然比过程的大部分概率质量在\n",
    "$ t \\rightarrow + \\infty $ 时堆积在0附近时，\n",
    "$ E\\left[L\\left(w^{t}\\right)\\bigm|q=g\\right]=1 $ 怎么可能成立？\n",
    "\n",
    "答案必须是当 $ t \\rightarrow + \\infty $ 时，\n",
    "$ L_t $ 的分布变得越来越重尾：\n",
    "足够多的质量转移到越来越大的 $ L_t $ 值上，使得\n",
    "尽管大部分概率质量堆积在0附近，$ L_t $ 的均值仍然保持为1。\n",
    "\n",
    "为了说明这个特殊性质，我们模拟了多条路径并且\n",
    "\n",
    "通过在每个时刻$ t $对这些路径取平均值来计算$ L\\left(w^t\\right) $的无条件均值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc75821b",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "l_arr_g = simulate(G_a, G_b, N=50000)\n",
    "l_seq_g = np.cumprod(l_arr_g, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcab824f",
   "metadata": {},
   "source": [
    "使用模拟来验证无条件期望值$ E\\left[L\\left(w^{t}\\right)\\right] $等于1(通过对样本路径取平均)会很有用。\n",
    "\n",
    "但是在这里仅仅使用标准蒙特卡洛模拟方法会消耗太多计算时间,因此我们不会这样做。\n",
    "\n",
    "原因是对于较大的$ t $值，$ L\\left(w^{t}\\right) $的分布极度偏斜。\n",
    "\n",
    "因为右尾部的概率密度接近于0，从右尾部采样足够多的点需要太多计算时间。\n",
    "\n",
    "我们在[这篇讲座](https://python.quantecon.org/imp_sample.html)中更详细地解释了这个问题。\n",
    "\n",
    "在那里我们描述了一种替代方法来计算似然比的均值，即通过从一个_不同的_概率分布中采样来计算一个_不同的_随机变量的均值。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacf7984",
   "metadata": {},
   "source": [
    "## 自然永久地从密度f中抽样\n",
    "\n",
    "现在假设在时间0之前，自然界永久地决定反复从密度f中抽样。\n",
    "\n",
    "虽然似然比 $ \\ell \\left(w_{t}\\right) $ 在密度 $ g $ 下的均值为 $ 1 $，但在密度 $ f $ 下的均值大于 1。\n",
    "\n",
    "为了证明这一点，我们计算：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "E\\left[\\ell \\left(w_{t}\\right)\\bigm|q=f\\right]  &=\\int\\frac{f\\left(w_{t}\\right)}{g\\left(w_{t}\\right)}f\\left(w_{t}\\right)dw_{t} \\\\\n",
    "    &=\\int\\frac{f\\left(w_{t}\\right)}{g\\left(w_{t}\\right)}\\frac{f\\left(w_{t}\\right)}{g\\left(w_{t}\\right)}g\\left(w_{t}\\right)dw_{t} \\\\\n",
    "    &=\\int \\ell \\left(w_{t}\\right)^{2}g\\left(w_{t}\\right)dw_{t} \\\\\n",
    "    &=E\\left[\\ell \\left(w_{t}\\right)^{2}\\mid q=g\\right] \\\\\n",
    "    &=E\\left[\\ell \\left(w_{t}\\right)\\mid q=g\\right]^{2}+Var\\left(\\ell \\left(w_{t}\\right)\\mid q=g\\right) \\\\\n",
    "    &>E\\left[\\ell \\left(w_{t}\\right)\\mid q=g\\right]^{2} = 1 \\\\\n",
    "       \\end{aligned}\n",
    "$$\n",
    "\n",
    "这反过来意味着似然比过程 $ L(w^t) $ 的无条件均值趋向于 $ + \\infty $。\n",
    "\n",
    "下面的模拟验证了这个结论。\n",
    "\n",
    "请注意 $ y $ 轴的刻度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58455190",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "l_arr_f = simulate(F_a, F_b, N=50000)\n",
    "l_seq_f = np.cumprod(l_arr_f, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaadf536",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "N, T = l_arr_f.shape\n",
    "plt.plot(range(T), np.mean(l_seq_f, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5484b01",
   "metadata": {},
   "source": [
    "我们还绘制了 $ L\\left(w^t\\right) $ 落入区间 $ [10000, \\infty) $ 的概率随时间的变化图，观察概率质量向 $ +\\infty $ 发散的速度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f376ef0a",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "plt.plot(range(T), np.sum(l_seq_f > 10000, axis=0) / N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad7cdc8",
   "metadata": {},
   "source": [
    "## 似然比检验\n",
    "\n",
    "我们现在描述如何运用Neyman和Pearson [[Neyman and Pearson, 1933](https://python.quantecon.org/zreferences.html#id255)]的方法来检验历史数据$ w^t $是否由密度函数$ g $的重复独立同分布抽样生成。\n",
    "\n",
    "设$ q $为数据生成过程，即$ q=f \\text{ 或 } g $。\n",
    "\n",
    "在观察到样本$ \\{W_i\\}_{i=1}^t $后，我们想通过执行（频率学派的）假设检验来判断自然是从$ g $还是从$ f $中抽样。\n",
    "\n",
    "我们指定：\n",
    "\n",
    "- 原假设$ H_0 $：$ q=f $  \n",
    "- 备择假设$ H_1 $：$ q=g $  \n",
    "\n",
    "\n",
    "Neyman和Pearson证明，检验这个假设的最佳方法是使用**似然比检验**，其形式为：\n",
    "\n",
    "- 当$ L(W^t) < c $时拒绝$ H_0 $  \n",
    "- 否则接受$ H_0 $  \n",
    "\n",
    "\n",
    "其中$ c $是一个给定的判别阈值，我们稍后将描述如何选择它。\n",
    "\n",
    "这个检验是*最佳的*，因为它是一个**一致最优**检验。\n",
    "\n",
    "为了理解这意味着什么，我们需要定义两个重要事件的概率：\n",
    "\n",
    "让我们描述与给定阈值 $ c $ 相关的检验特征。\n",
    "\n",
    "这两个概率是：\n",
    "\n",
    "- 检测概率（= 检验效力 = 1减去第II类错误概率）：  \n",
    "  $$\n",
    "  1-\\beta \\equiv \\Pr\\left\\{ L\\left(w^{t}\\right)<c\\mid q=g\\right\\}\n",
    "  $$\n",
    "- 虚警概率（= 显著性水平 = 第I类错误概率）：  \n",
    "  $$\n",
    "  \\alpha \\equiv  \\Pr\\left\\{ L\\left(w^{t}\\right)<c\\mid q=f\\right\\}\n",
    "  $$\n",
    "\n",
    "\n",
    "[奈曼-皮尔逊引理](https://en.wikipedia.org/wiki/Neyman%E2%80%93Pearson_lemma)指出，在所有可能的检验中，似然比检验在给定虚警概率的情况下能最大化检测概率。\n",
    "\n",
    "换句话说，在所有可能的检验中，似然比检验在给定**显著性水平**的情况下能最大化**检验效力**。\n",
    "\n",
    "为了得到良好的推断结果，我们希望虚警概率较小而检测概率较大。\n",
    "\n",
    "当样本量 $ t $ 固定时，我们可以通过调整 $ c $ 来改变这两个概率。\n",
    "\n",
    "一个令人困扰的”生活就是如此”的事实是，当我们改变临界值$ c $时，这两个概率会朝着相同的方向变化。\n",
    "\n",
    "在没有具体量化第一类和第二类错误所带来的损失的情况下，我们很难说应该*如何*权衡这两种错误的概率。\n",
    "\n",
    "我们知道增加样本量$ t $可以改善统计推断。\n",
    "\n",
    "下面我们将绘制一些说明性的图表来展示这一点。\n",
    "\n",
    "我们还将介绍一个用于选择样本量$ t $的经典频率派方法。\n",
    "\n",
    "让我们从一个将阈值$ c $固定为$ 1 $的情况开始。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a598f582",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "c = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad0f6d0",
   "metadata": {},
   "source": [
    "下面我们绘制上面模拟的累积似然比的对数的经验分布，这些分布是由$ f $或$ g $生成的。\n",
    "\n",
    "取对数不会影响概率的计算，因为对数是单调变换。\n",
    "\n",
    "随着$ t $的增加，第一类错误和第二类错误的概率都在减小，这是好事。\n",
    "\n",
    "这是因为当$ g $是数据生成过程时，log$ (L(w^t)) $的大部分概率质量向$ -\\infty $移动；而当数据由$ f $生成时，log$ (L(w^t)) $趋向于$ \\infty $。\n",
    "\n",
    "log$ (L(w^t)) $在$ f $和$ q $下的这种不同行为使得区分$ q=f $和$ q=g $成为可能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6c2cf2",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
    "fig.suptitle('distribution of $log(L(w^t))$ under f or g', fontsize=15)\n",
    "\n",
    "for i, t in enumerate([1, 7, 14, 21]):\n",
    "    nr = i // 2\n",
    "    nc = i % 2\n",
    "\n",
    "    axs[nr, nc].axvline(np.log(c), color=\"k\", ls=\"--\")\n",
    "\n",
    "    hist_f, x_f = np.histogram(np.log(l_seq_f[:, t]), 200, density=True)\n",
    "    hist_g, x_g = np.histogram(np.log(l_seq_g[:, t]), 200, density=True)\n",
    "\n",
    "    axs[nr, nc].plot(x_f[1:], hist_f, label=\"dist under f\")\n",
    "    axs[nr, nc].plot(x_g[1:], hist_g, label=\"dist under g\")\n",
    "\n",
    "    for i, (x, hist, label) in enumerate(zip([x_f, x_g], [hist_f, hist_g], [\"Type I error\", \"Type II error\"])):\n",
    "        ind = x[1:] <= np.log(c) if i == 0 else x[1:] > np.log(c)\n",
    "        axs[nr, nc].fill_between(x[1:][ind], hist[ind], alpha=0.5, label=label)\n",
    "\n",
    "    axs[nr, nc].legend()\n",
    "    axs[nr, nc].set_title(f\"t={t}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cdbcdf",
   "metadata": {},
   "source": [
    "下图更清楚地显示，当我们固定阈值$ c $时，检测概率随着$ t $的增加而单调增加，而虚警概率则单调减少。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5678b3",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "PD = np.empty(T)\n",
    "PFA = np.empty(T)\n",
    "\n",
    "for t in range(T):\n",
    "    PD[t] = np.sum(l_seq_g[:, t] < c) / N\n",
    "    PFA[t] = np.sum(l_seq_f[:, t] < c) / N\n",
    "\n",
    "plt.plot(range(T), PD, label=\"Probability of detection\")\n",
    "plt.plot(range(T), PFA, label=\"Probability of false alarm\")\n",
    "plt.xlabel(\"t\")\n",
    "plt.title(\"$c=1$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48545ed9",
   "metadata": {},
   "source": [
    "对于给定的样本量 $ t $，阈值 $ c $ 唯一确定了两种类型错误的概率。\n",
    "\n",
    "如果对于固定的 $ t $，我们现在释放并移动 $ c $，我们将得到检测概率作为虚警概率的函数。\n",
    "\n",
    "这就产生了所谓的[接收者操作特征曲线](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)。\n",
    "\n",
    "下面，我们绘制不同样本量 $ t $ 的接收者操作特征曲线。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74383774",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "PFA = np.arange(0, 100, 1)\n",
    "\n",
    "for t in range(1, 15, 4):\n",
    "    percentile = np.percentile(l_seq_f[:, t], PFA)\n",
    "    PD = [np.sum(l_seq_g[:, t] < p) / N for p in percentile]\n",
    "\n",
    "    plt.plot(PFA / 100, PD, label=f\"t={t}\")\n",
    "\n",
    "plt.scatter(0, 1, label=\"perfect detection\")\n",
    "plt.plot([0, 1], [0, 1], color='k', ls='--', label=\"random detection\")\n",
    "\n",
    "plt.arrow(0.5, 0.5, -0.15, 0.15, head_width=0.03)\n",
    "plt.text(0.35, 0.7, \"better\")\n",
    "plt.xlabel(\"虚警概率\")\n",
    "plt.ylabel(\"检测概率\")\n",
    "plt.legend()\n",
    "plt.title(\"接收者操作特征曲线\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896d334f",
   "metadata": {},
   "source": [
    "注意随着 $ t $ 的增加，对于给定的判别阈值 $ c $，我们可以确保获得更高的检测概率和更低的虚警概率。\n",
    "\n",
    "当 $ t \\rightarrow + \\infty $ 时，我们接近完美检测曲线，该曲线在蓝点处呈直角。\n",
    "\n",
    "对于给定的样本量 $ t $，判别阈值 $ c $ 决定了接收者操作特征曲线上的一个点。\n",
    "\n",
    "权衡两种类型错误的概率是由测试设计者决定的。\n",
    "\n",
    "但我们知道如何选择最小样本量来达到给定的概率目标。\n",
    "\n",
    "通常，频率学派的目标是在虚警概率有上限的情况下获得高检测概率。\n",
    "\n",
    "下面我们展示一个例子，其中我们将虚警概率固定在 $ 0.05 $。\n",
    "\n",
    "做出决策所需的样本量由一个\n",
    "\n",
    "目标检测概率，例如 $ 0.9 $，如下图所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb51dda3",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "PFA = 0.05\n",
    "PD = np.empty(T)\n",
    "\n",
    "for t in range(T):\n",
    "\n",
    "    c = np.percentile(l_seq_f[:, t], PFA * 100)\n",
    "    PD[t] = np.sum(l_seq_g[:, t] < c) / N\n",
    "\n",
    "plt.plot(range(T), PD)\n",
    "plt.axhline(0.9, color=\"k\", ls=\"--\")\n",
    "\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"检测概率\")\n",
    "plt.title(f\"虚警概率={PFA}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c5fb7e",
   "metadata": {},
   "source": [
    "美国海军显然在第二次世界大战期间使用类似这样的程序来选择质量控制测试的样本大小 $ t $。\n",
    "\n",
    "一位被命令执行此类测试的海军上尉对此产生了疑虑，他向米尔顿·弗里德曼提出了这些疑虑，我们在[这篇讲座](https://python.quantecon.org/wald_friedman.html)中对此进行了描述。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a05dd1",
   "metadata": {},
   "source": [
    "## Kullback–Leibler 散度\n",
    "\n",
    "现在让我们考虑一种既不是 $ g $ 也不是 $ f $ 生成数据的情况。\n",
    "\n",
    "而是由第三个分布 $ h $ 生成。\n",
    "\n",
    "让我们观察当 $ h $ 支配数据时，累积似然比 $ f/g $ 的表现。\n",
    "\n",
    "这里的一个关键工具被称为 **Kullback–Leibler 散度**。\n",
    "\n",
    "它也被称为**相对熵**。\n",
    "\n",
    "它用来衡量一个概率分布与另一个概率分布的差异程度。\n",
    "\n",
    "在我们的应用中，我们想要衡量 $ f $ 或 $ g $ 与 $ h $ 的差异。\n",
    "\n",
    "与我们相关的两个 Kullback–Leibler 散度是 $ K_f $ 和 $ K_g $，定义如下：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "$$\n",
    "\n",
    "\\begin{aligned}\n",
    "K_{f}   &=E_{h}\\left[\\log\\left(\\frac{f\\left(w\\right)}{h\\left(w\\right)}\\right)\\frac{f\\left(w\\right)}{h\\left(w\\right)}\\right] \\\n",
    "&=\\int\\log\\left(\\frac{f\\left(w\\right)}{h\\left(w\\right)}\\right)\\frac{f\\left(w\\right)}{h\\left(w\\right)}h\\left(w\\right)dw \\\n",
    "&=\\int\\log\\left(\\frac{f\\left(w\\right)}{h\\left(w\\right)}\\right)f\\left(w\\right)dw\n",
    "\\end{aligned}\n",
    "\\$\\$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "K_{g}   &=E_{h}\\left[\\log\\left(\\frac{g\\left(w\\right)}{h\\left(w\\right)}\\right)\\frac{g\\left(w\\right)}{h\\left(w\\right)}\\right] \\\\\n",
    "    &=\\int\\log\\left(\\frac{g\\left(w\\right)}{h\\left(w\\right)}\\right)\\frac{g\\left(w\\right)}{h\\left(w\\right)}h\\left(w\\right)dw \\\\\n",
    "    &=\\int\\log\\left(\\frac{g\\left(w\\right)}{h\\left(w\\right)}\\right)g\\left(w\\right)dw\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "当 $ K_g < K_f $ 时，$ g $ 比 $ f $ 更接近 $ h $。\n",
    "\n",
    "- 在这种情况下，我们会发现 $ L\\left(w^t\\right) \\rightarrow 0 $。  \n",
    "\n",
    "\n",
    "当 $ K_g > K_f $ 时，$ f $ 比 $ g $ 更接近 $ h $。\n",
    "\n",
    "- 在这种情况下，我们会发现 $ L\\left(w^t\\right) \\rightarrow + \\infty $  \n",
    "\n",
    "\n",
    "我们现在将尝试一个$ h $也是贝塔分布的情况\n",
    "\n",
    "我们首先设置参数$ G_a $和$ G_b $，使得\n",
    "$ h $更接近$ g $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e846b2",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "H_a, H_b = 3.5, 1.8\n",
    "\n",
    "h = jit(lambda x: p(x, H_a, H_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241893af",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "x_range = np.linspace(0, 1, 100)\n",
    "plt.plot(x_range, f(x_range), label='f')\n",
    "plt.plot(x_range, g(x_range), label='g')\n",
    "plt.plot(x_range, h(x_range), label='h')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e5dad0",
   "metadata": {},
   "source": [
    "让我们通过求积分计算Kullback-Leibler差异。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a0b2cd",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def KL_integrand(w, q, h):\n",
    "\n",
    "    m = q(w) / h(w)\n",
    "\n",
    "    return np.log(m) * q(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ee5c21",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def compute_KL(h, f, g):\n",
    "\n",
    "    Kf, _ = quad(KL_integrand, 0, 1, args=(f, h))\n",
    "    Kg, _ = quad(KL_integrand, 0, 1, args=(g, h))\n",
    "\n",
    "    return Kf, Kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575ca77f",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "Kf, Kg = compute_KL(h, f, g)\n",
    "Kf, Kg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bb4c0e",
   "metadata": {},
   "source": [
    "我们有 $ K_g < K_f $。\n",
    "\n",
    "接下来，我们可以通过模拟来验证我们关于 $ L\\left(w^t\\right) $ 的猜想。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb2bc13",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "l_arr_h = simulate(H_a, H_b)\n",
    "l_seq_h = np.cumprod(l_arr_h, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b2c255",
   "metadata": {},
   "source": [
    "下图绘制了随时间变化的路径分数$ L\\left(w^t\\right) $在区间$ [0,0.01] $内的比例。\n",
    "\n",
    "注意当$ g $比$ f $更接近$ h $时，该比例如预期般收敛到1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8022e624",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "N, T = l_arr_h.shape\n",
    "plt.plot(range(T), np.sum(l_seq_h <= 0.01, axis=0) / N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc07d7c",
   "metadata": {},
   "source": [
    "我们也可以尝试一个比$ g $更接近$ f $的$ h $，这样$ K_g $就会大于$ K_f $。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9835b75a",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "H_a, H_b = 1.2, 1.2\n",
    "h = jit(lambda x: p(x, H_a, H_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13c4e2f",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "Kf, Kg = compute_KL(h, f, g)\n",
    "Kf, Kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5bed34",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "l_arr_h = simulate(H_a, H_b)\n",
    "l_seq_h = np.cumprod(l_arr_h, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4be24e",
   "metadata": {},
   "source": [
    "现在$ L\\left(w^t\\right) $的概率质量在10000以上的部分趋向于$ +\\infty $。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6632e7",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "N, T = l_arr_h.shape\n",
    "plt.plot(range(T), np.sum(l_seq_h > 10000, axis=0) / N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57e7273",
   "metadata": {},
   "source": [
    "## 后续内容\n",
    "\n",
    "似然过程在贝叶斯学习中扮演着重要角色，正如在[这篇讲座](https://python.quantecon.org/likelihood_bayes.html)中所描述的，并在[这篇讲座](https://python.quantecon.org/odu.html)中得到应用。\n",
    "\n",
    "似然比过程在[这篇讲座](https://python-advanced.quantecon.org/additive_functionals.html)中再次出现，其中包含了另一个关于上述似然比过程**特殊性质**的说明。"
   ]
  }
 ],
 "metadata": {
  "date": 1749097994.1073341,
  "filename": "likelihood_ratio_process.md",
  "kernelspec": {
   "display_name": "Python",
   "language": "python3",
   "name": "python3"
  },
  "title": "似然比过程"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}