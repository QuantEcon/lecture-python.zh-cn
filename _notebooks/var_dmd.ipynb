{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8aca94c7",
   "metadata": {},
   "source": [
    "# 向量自回归和动态模态分解\n",
    "\n",
    "本节讲座中，我们将应用在 [奇异值分解](https://python.quantecon.org/svd_intro.html) 中学到的计算方法来研究：\n",
    "\n",
    "- 一阶向量自回归 (VARs)  \n",
    "- 动态模态分解 (DMDs)  \n",
    "- 一阶向量自回归和动态模态分解之间的联系  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f6e7e4",
   "metadata": {},
   "source": [
    "## 一阶向量自回归\n",
    "\n",
    "我们想要拟合一个**一阶向量自回归**\n",
    "\n",
    "\n",
    "<a id='equation-eq-varfirstorder'></a>\n",
    "$$\n",
    "X_{t+1} = A X_t + C \\epsilon_{t+1}, \\quad \\epsilon_{t+1} \\perp X_t \\tag{6.1}\n",
    "$$\n",
    "\n",
    "其中，$ \\epsilon_{t+1} $ 是一个独立同分布的随机向量序列 $ m \\times 1 $ 在时间$ t+1 $ 的分量，且该序列有零均值向量和单位协方差矩阵；而 $ m \\times 1 $ 的向量 $ X_t $ 是：\n",
    "\n",
    "\n",
    "<a id='equation-eq-xvector'></a>\n",
    "$$\n",
    "X_t = \\begin{bmatrix}  X_{1,t} & X_{2,t} & \\cdots & X_{m,t}     \\end{bmatrix}^\\top \\tag{6.2}\n",
    "$$\n",
    "\n",
    "其中 $ \\cdot ^\\top $ 表示共轭转置，$ X_{i,t} $ 是时间 $ t $ 时的变量 $ i $。\n",
    "\n",
    "我们想要拟合方程 [(6.1)](#equation-eq-varfirstorder)。\n",
    "\n",
    "我们的数据则存储在一个 $ m \\times (n+1) $ 的矩阵 $ \\tilde X $ 中\n",
    "\n",
    "$$\n",
    "\\tilde X =  \\begin{bmatrix} X_1 \\mid X_2 \\mid \\cdots \\mid X_n \\mid X_{n+1} \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "其中对于 $ t = 1, \\ldots, n +1 $时，$ m \\times 1 $ 的向量 $ X_t $ 由 [(6.2)](#equation-eq-xvector) 给出。\n",
    "\n",
    "因此，我们想要估计一个系统 [(6.1)](#equation-eq-varfirstorder)，它由 $ m $ 个最小二乘回归组成，将**所有变量**对**所有变量**的一阶滞后值进行回归。\n",
    "\n",
    "[(6.1)](#equation-eq-varfirstorder) 的第 $ i $ 个方程是将 $ X_{i,t+1} $ 对向量 $ X_t $ 进行回归。\n",
    "\n",
    "我们按如下步骤进行。\n",
    "\n",
    "从 $ \\tilde X $ 中，我们构造以下两个 $ m \\times n $ 矩阵\n",
    "\n",
    "$$\n",
    "X =  \\begin{bmatrix} X_1 \\mid X_2 \\mid \\cdots \\mid X_{n}\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "和\n",
    "\n",
    "$$\n",
    "X' =  \\begin{bmatrix} X_2 \\mid X_3 \\mid \\cdots \\mid X_{n+1}\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "这里的 $ ' $ 是矩阵 $ X' $ 的名称的一部分，并不表示矩阵转置。\n",
    "\n",
    "我们使用 $ \\cdot^\\top $ 来表示矩阵转置或其在复矩阵中的扩展。\n",
    "\n",
    "在构造 $ X $ 和 $ X' $ 的过程中，我们都从 $ \\tilde X $ 中删除了某一列，$ X $ 是删除最后一列，$ X' $ 则是删除第一列。\n",
    "\n",
    "显然，$ X $ 和 $ X' $ 都是 $ m \\times n $ 的矩阵。\n",
    "\n",
    "我们用 $ p \\leq \\min(m, n) $ 表示 $ X $ 的秩。\n",
    "\n",
    "我们感兴趣的两种情况是：\n",
    "\n",
    "- $ n > > m $，即时间序列观测值的数量 $ n $ 远大于变量的数量 $ m $  \n",
    "- $ m > > n $，即变量的数量 $ m $ 远大于时间序列观测值的数量 $ n $  \n",
    "\n",
    "\n",
    "在考虑了这两种特殊情况的一般情况中，有一个通用的公式描述了 $ A $ 的最小二乘估计量 $ \\hat A $。\n",
    "\n",
    "但重要的细节有所不同。\n",
    "\n",
    "这个通用的公式是：\n",
    "\n",
    "\n",
    "<a id='equation-eq-commona'></a>\n",
    "$$\n",
    "\\hat A = X' X^+ \\tag{6.3}\n",
    "$$\n",
    "\n",
    "其中 $ X^+ $ 是 $ X $ 的广义逆矩阵，或伪逆。\n",
    "\n",
    "关于**穆尔-彭罗斯广义逆矩阵**的详细信息，请参见[穆尔-彭罗斯广义逆矩阵](https://baike.baidu.com/item/%E7%A9%86%E5%B0%94-%E5%BD%AD%E7%BD%97%E6%96%AF%E5%B9%BF%E4%B9%89%E9%80%86%E7%9F%A9%E9%98%B5/22770999?fr=aladdin)\n",
    "\n",
    "在我们的两种情况下，广义逆矩阵适用的公式有所不同。\n",
    "\n",
    "**短胖型情况：**\n",
    "\n",
    "当$ n >> m $时，即时间序列的观测值$ n $远多于变量的数量$ m $，且当$ X $具有线性独立的**行**时，$ X X^\\top $的逆矩阵存在，且广义逆矩阵$ X^+ $为\n",
    "\n",
    "$$\n",
    "X^+ = X^\\top  (X X^\\top )^{-1}\n",
    "$$\n",
    "\n",
    "这里$ X^+ $是一个满足$ X X^+ = I_{m \\times m} $的**右逆**，。\n",
    "\n",
    "在这种情况下，我们用于估计总体回归系数矩阵$ A $的最小二乘估计量的公式[(6.3)](#equation-eq-commona)就变为\n",
    "\n",
    "\n",
    "<a id='equation-eq-ahatform101'></a>\n",
    "$$\n",
    "\\hat A = X' X^\\top  (X X^\\top )^{-1} \\tag{6.4}\n",
    "$$\n",
    "\n",
    "这个计算最小二乘回归系数的公式在计量经济学中被广泛地使用。\n",
    "\n",
    "它也被用于估计向量自回归。\n",
    "\n",
    "公式[(6.4)](#equation-eq-ahatform101)的右边，正比于$ X_{t+1} $和$ X_t $的经验交叉二阶矩矩，乘以$ X_t $二阶矩阵的逆矩阵。\n",
    "\n",
    "**高瘦型情况：**\n",
    "\n",
    "当$ m > > n $时，即属性数量$ m $远大于时间序列的观测值$ n $，且当$ X $的**列**线性独立时，$ X^\\top X $的逆矩阵存在，且广义逆矩阵$ X^+ $为\n",
    "\n",
    "$$\n",
    "X^+ = (X^\\top X)^{-1} X^\\top\n",
    "$$\n",
    "\n",
    "这里$ X^+ $是一个满足$ X^+ X = I_{n \\times n} $的**左逆**，。\n",
    "\n",
    "在这种情况下，我们用于估计$ A $的最小二乘估计公式[(6.3)](#equation-eq-commona)变为\n",
    "\n",
    "\n",
    "<a id='equation-eq-hataversion0'></a>\n",
    "$$\n",
    "\\hat A = X' (X^\\top X)^{-1} X^\\top \\tag{6.5}\n",
    "$$\n",
    "\n",
    "请比较[(6.4)](#equation-eq-ahatform101)和[(6.5)](#equation-eq-hataversion0)中$ \\hat A $的表达式。\n",
    "\n",
    "这里我们特别关注公式[(6.5)](#equation-eq-hataversion0)。\n",
    "\n",
    "$ \\hat A $的第$ i $行是一个$ m \\times 1 $的向量，其中包含了$ X_{i,t+1} $对$ X_{j,t}, j = 1, \\ldots, m $回归的系数。\n",
    "\n",
    "如果我们使用公式[(6.5)](#equation-eq-hataversion0)来计算$ \\hat A X $，我们发现\n",
    "\n",
    "$$\n",
    "\\hat A X = X'\n",
    "$$\n",
    "\n",
    "因此回归方程**完全拟合**。\n",
    "\n",
    "这是**欠定最小二乘**模型中典型的结果。\n",
    "\n",
    "再次重申，**高瘦**情况(见[奇异值分解](https://python.quantecon.org/svd_intro.html))指观测的数量$ n $相对于向量$ X_t $属性的数量$ m $较小时，我们想要拟合方程[(6.1)](#equation-eq-varfirstorder)。\n",
    "\n",
    "我们面临着最小二乘估计量是欠定的，且回归方程完全拟合的事实。\n",
    "\n",
    "接下来，我们想要更加高效地计算广义逆矩阵$ X^+ $。\n",
    "\n",
    "广义逆矩阵$ X^+ $将是我们$ A $估计量的一个组成部分。\n",
    "\n",
    "作为对$ A $的估计量$ \\hat A $，我们想要形成一个$ m \\times m $的矩阵，来解决最小二乘最佳拟合问题\n",
    "\n",
    "\n",
    "<a id='equation-eq-alseqn'></a>\n",
    "$$\n",
    "\\hat A = \\textrm{argmin}_{\\check A} || X' - \\check  A X ||_F \\tag{6.6}\n",
    "$$\n",
    "\n",
    "其中 $ || \\cdot ||_F $ 表示矩阵的Frobenius（或欧几里得）范数。\n",
    "\n",
    "Frobenius范数定义为\n",
    "\n",
    "$$\n",
    "||A||_F = \\sqrt{ \\sum_{i=1}^m \\sum_{j=1}^m |A_{ij}|^2 }\n",
    "$$\n",
    "\n",
    "方程[(6.6)](#equation-eq-alseqn)右侧的最小值解为\n",
    "\n",
    "\n",
    "<a id='equation-eq-hataform'></a>\n",
    "$$\n",
    "\\hat A =  X'  X^{+} \\tag{6.7}\n",
    "$$\n",
    "\n",
    "其中（可能是巨大的）$ n \\times m $ 的矩阵 $ X^{+} = (X^\\top  X)^{-1} X^\\top $ 同样是 $ X $ 的广义逆矩阵。\n",
    "\n",
    "对于我们感兴趣的一些情况，$ X^\\top  X $ 可能接近奇异，这种情况会使某些数值算法变得不准确。\n",
    "\n",
    "为了应对这种可能性，我们将使用高效的算法来构建公式[(6.5)](#equation-eq-hataversion0)中 $ \\hat A $ 的**降秩近似**。\n",
    "\n",
    "这种近似方式，让我们的向量自回归估计不再完全拟合。\n",
    "\n",
    "$ \\hat A $ 的第 $ i $ 行是一个 $ m \\times 1 $ 的回归系数向量，表示 $ X_{i,t+1} $ 对 $ X_{j,t}, j = 1, \\ldots, m $ 的回归。\n",
    "\n",
    "一种高效计算广义逆矩阵$ X^+ $的方式是从奇异值分解开始\n",
    "\n",
    "\n",
    "<a id='equation-eq-svddmd'></a>\n",
    "$$\n",
    "X =  U \\Sigma  V^\\top \\tag{6.8}\n",
    "$$\n",
    "\n",
    "这里我们提醒自己，这个**简化**SVD中，$ X $是一个$ m \\times n $的数据矩阵，$ U $是一个$ m \\times p $的矩阵，$ \\Sigma $是一个$ p \\times p $的矩阵，而$ V $是一个$ n \\times p $的矩阵。\n",
    "\n",
    "通过以下一系列等式，我们可以有效地构造相关的广义逆矩阵$ X^+ $。\n",
    "\n",
    "\n",
    "<a id='equation-eq-efficientpseudoinverse'></a>\n",
    "$$\n",
    "\\begin{aligned}\n",
    "X^{+} & = (X^\\top  X)^{-1} X^\\top  \\\\\n",
    "  & = (V \\Sigma U^\\top  U \\Sigma V^\\top )^{-1} V \\Sigma U^\\top  \\\\\n",
    "  & = (V \\Sigma \\Sigma V^\\top )^{-1} V \\Sigma U^\\top  \\\\\n",
    "  & = V \\Sigma^{-1} \\Sigma^{-1} V^\\top  V \\Sigma U^\\top  \\\\\n",
    "  & = V \\Sigma^{-1} U^\\top  \n",
    "\\end{aligned} \\tag{6.9}\n",
    "$$\n",
    "\n",
    "（由于$ m > > n $，在简化SVD中$ V^\\top  V = I_{p \\times p} $，因此我们可以将前面的一系列等式同时用于简化SVD和完整SVD。）\n",
    "\n",
    "因此，我们将使用方程[(6.8)](#equation-eq-svddmd)中$ X $的奇异值分解来构造$ X $的广义逆矩阵$ X^+ $，计算方法为：\n",
    "\n",
    "\n",
    "<a id='equation-eq-xplusformula'></a>\n",
    "$$\n",
    "X^{+} =  V \\Sigma^{-1}  U^\\top \\tag{6.10}\n",
    "$$\n",
    "\n",
    "其中矩阵$ \\Sigma^{-1} $是通过将$ \\Sigma $中的每个非零元素替换为$ \\sigma_j^{-1} $构造而成。\n",
    "\n",
    "我们可以将公式[(6.10)](#equation-eq-xplusformula)与公式[(6.7)](#equation-eq-hataform)结合使用来计算回归系数矩阵$ \\hat A $。\n",
    "\n",
    "因此，我们对$ m \\times m $的系数矩阵$ A $的估计量$ \\hat A = X' X^+ $为：\n",
    "\n",
    "\n",
    "<a id='equation-eq-ahatsvdformula'></a>\n",
    "$$\n",
    "\\hat A = X' V \\Sigma^{-1}  U^\\top \\tag{6.11}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d39092",
   "metadata": {},
   "source": [
    "## 动态模态分解(DMD)\n",
    "\n",
    "接下来我们将研究一个特殊情况 – 当变量数量$ m >> n $时的情形。\n",
    "\n",
    "**动态模态分解**可以用于处理这种”高瘦型”矩阵。\n",
    "\n",
    "假设有一个$ m \\times (n+1) $的数据矩阵$ \\tilde X $，它包含了比时间周期$ n+1 $多得多的属性（或变量）$ m $。\n",
    "\n",
    "动态模态分解由[[Schmid, 2010](https://python.quantecon.org/zreferences.html#id27)]首次提出，\n",
    "\n",
    "你可以在 [[Kutz *et al.*, 2016](https://python.quantecon.org/zreferences.html#id50)] 和 [[Brunton and Kutz, 2019](https://python.quantecon.org/zreferences.html#id266)]（第7.2节）中阅读有关动态模态分解的内容。\n",
    "\n",
    "**动态模态分解**（DMD）的目标是找到最小二乘回归系数矩阵$ \\hat A $的一个低秩近似，其中近似矩阵的秩$ r $小于原始矩阵的秩$ p $。\n",
    "\n",
    "这个近似可以通过公式[(6.11)](#equation-eq-ahatsvdformula)来构造。\n",
    "\n",
    "我们将逐步构建一种适合应用的表示。\n",
    "\n",
    "我们将通过三种不同的表示方式来描述一阶线性动态系统（即我们的向量自回归），从而实现这一点。\n",
    "\n",
    "**三种表示的指南：** 在实践中，我们主要关注表示3。\n",
    "\n",
    "我们使用前两种表示来呈现一些有用的中间推导，这些步骤有助于我们理解表示3的内在原理。\n",
    "\n",
    "在应用中，我们将只使用**DMD模态**的一小部分子集来近似动态。\n",
    "\n",
    "我们使用这样一个小的DMD模态子集来构建对$ A $的降秩近似。\n",
    "\n",
    "为此，我们需要使用与表示法3相关的**简化**SVD，而不是与表示法1和2相关的**完整**SVD。\n",
    "\n",
    "**快速指南：** 如果您想直接应用这些方法，可以直接跳到表示法3。\n",
    "\n",
    "第一次阅读时，您可以跳过铺垫性的表示法1和2。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7390d560",
   "metadata": {},
   "source": [
    "## 表示法1\n",
    "\n",
    "在这个表示法中，我们将使用$ X $的**完整**SVD。\n",
    "\n",
    "我们使用$ U $的$ m $个**列**，即$ U^\\top $的$ m $个**行**，来定义一个$ m \\times 1 $的向量$ \\tilde b_t $：\n",
    "\n",
    "\n",
    "<a id='equation-eq-tildexdef2'></a>\n",
    "$$\n",
    "\\tilde b_t = U^\\top  X_t . \\tag{6.12}\n",
    "$$\n",
    "\n",
    "原始数据$ X_t $可以表示为：\n",
    "\n",
    "\n",
    "<a id='equation-eq-xdecoder'></a>\n",
    "$$\n",
    "X_t = U \\tilde b_t \\tag{6.13}\n",
    "$$\n",
    "\n",
    "（这里我们使用$ b $来提醒自己我们正在创建一个**基**向量。）\n",
    "\n",
    "由于我们现在使用的是**完全**SVD，$ U U^\\top  = I_{m \\times m} $。\n",
    "\n",
    "因此从方程[(6.12)](#equation-eq-tildexdef2)可以得出，我们可以用$ \\tilde b_t $重新构造$ X_t $。\n",
    "\n",
    "特别地，\n",
    "\n",
    "- 方程 [(6.12)](#equation-eq-tildexdef2) 作为一个**编码器**，将 $ m \\times 1 $ 向量 $ X_t $ **旋转**成一个 $ m \\times 1 $ 的向量 $ \\tilde b_t $  \n",
    "- 方程 [(6.13)](#equation-eq-xdecoder) 作为一个**解码器**，通过旋转 $ m \\times 1 $ 向量 $ \\tilde b_t $ 来**重新构造** $ m \\times 1 $ 的向量 $ X_t $  \n",
    "\n",
    "\n",
    "为 $ m \\times 1 $ 的基向量 $ \\tilde b_t $ 定义一个转移矩阵：\n",
    "\n",
    "\n",
    "<a id='equation-eq-atilde0'></a>\n",
    "$$\n",
    "\\tilde A = U^\\top  \\hat A U \\tag{6.14}\n",
    "$$\n",
    "\n",
    "我们可以通过以下方式表示 $ \\hat A $：\n",
    "\n",
    "$$\n",
    "\\hat A = U \\tilde A U^\\top\n",
    "$$\n",
    "\n",
    "$ m \\times 1 $ 的基向量 $ \\tilde b_t $ 的动态由以下方程支配：\n",
    "\n",
    "$$\n",
    "\\tilde b_{t+1} = \\tilde A \\tilde b_t\n",
    "$$\n",
    "\n",
    "为了构建基于 $ X_1 $ 的 $ X_t $ 未来值的预测 $ \\overline X_t $，我们可以对这个方程的两边应用解码器（即旋转器），从而推导出：\n",
    "\n",
    "$$\n",
    "\\overline X_{t+1} = U \\tilde A^t U^\\top  X_1\n",
    "$$\n",
    "\n",
    "这里我们用 $ \\overline X_{t+1}, t \\geq 1 $ 表示预测值。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762df585",
   "metadata": {},
   "source": [
    "## 表示法 2\n",
    "\n",
    "这种表示方法与[[Schmid, 2010](https://python.quantecon.org/zreferences.html#id27)]最初提出的方法有关。\n",
    "\n",
    "它可以被视为推导表示3的一个中间步骤。\n",
    "\n",
    "与表示1一样，我们继续：\n",
    "\n",
    "- 使用**完整**SVD而**不是**简化SVD  \n",
    "\n",
    "\n",
    "在[奇异值分解](https://python.quantecon.org/svd_intro.html)课程中我们学到:\n",
    "\n",
    "- (a) 对于完整SVD，$ U U^\\top = I_{m \\times m} $和$ U^\\top U = I_{p \\times p} $都是单位矩阵  \n",
    "- (b) 对于$ X $的简化SVD，$ U^\\top U $不是单位矩阵。  \n",
    "\n",
    "\n",
    "这个区别很重要，因为我们后面会使用简化SVD而不是完整SVD。这意味着我们需要处理$ U^\\top U $不是单位矩阵的情况。\n",
    "\n",
    "但现在，让我们假设我们使用的是完整SVD，这样条件(a)和(b)都得到满足。\n",
    "\n",
    "对方程[(6.14)](#equation-eq-atilde0)中定义的$ m \\times m $矩阵$ \\tilde A = U^\\top  \\hat A U $进行特征分解：\n",
    "\n",
    "\n",
    "<a id='equation-eq-tildeaeigen'></a>\n",
    "$$\n",
    "\\tilde A = W \\Lambda W^{-1} \\tag{6.15}\n",
    "$$\n",
    "\n",
    "其中$ \\Lambda $是特征值的对角矩阵，$ W $是一个$ m \\times m $的矩阵，其每一列都对应于$ \\Lambda $中行(特征值)的特征向量。\n",
    "\n",
    "当$ U U^\\top  = I_{m \\times m} $时（这在$ X $的完全SVD中是成立的），可得：\n",
    "\n",
    "\n",
    "<a id='equation-eq-eqeigahat'></a>\n",
    "$$\n",
    "\\hat A = U \\tilde A U^\\top  = U W \\Lambda W^{-1} U^\\top \\tag{6.16}\n",
    "$$\n",
    "\n",
    "根据方程[(6.16)](#equation-eq-eqeigahat)，对角矩阵$ \\Lambda $包含$ \\hat A $的特征值，而$ \\hat A $对应的特征向量是矩阵$ UW $的列。\n",
    "\n",
    "因此，我们的一阶向量自回归所捕获的$ X_t $动态的系统部分（即非随机部分）可以描述为：\n",
    "\n",
    "$$\n",
    "X_{t+1} = U W \\Lambda W^{-1} U^\\top   X_t\n",
    "$$\n",
    "\n",
    "将上述方程两边同时乘以$ W^{-1} U^\\top $，得到：\n",
    "\n",
    "$ W^{-1} U^\\top  X_{t+1} = \\Lambda W^{-1} U^\\top  X_t $\\$\n",
    "\n",
    "或\n",
    "\n",
    "$$\n",
    "\\hat b_{t+1} = \\Lambda \\hat b_t\n",
    "$$\n",
    "\n",
    "其中，我们的**编码器**是\n",
    "\n",
    "$$\n",
    "\\hat b_t = W^{-1} U^\\top  X_t\n",
    "$$\n",
    "\n",
    "我们的**解码器**是\n",
    "\n",
    "$$\n",
    "X_t = U W \\hat b_t\n",
    "$$\n",
    "\n",
    "我们可以使用这种表示来构建一个基于$ X_1 $的$ X_{t+1} $的预测器$ \\overline X_{t+1} $：\n",
    "\n",
    "\n",
    "<a id='equation-eq-dssebookrepr'></a>\n",
    "$$\n",
    "\\overline X_{t+1} = U W \\Lambda^t W^{-1} U^\\top  X_1 \\tag{6.17}\n",
    "$$\n",
    "\n",
    "实际上，\n",
    "[[Schmid, 2010](https://python.quantecon.org/zreferences.html#id27)]定义了一个$ m \\times m $的矩阵$ \\Phi_s $为\n",
    "\n",
    "\n",
    "<a id='equation-eq-phisfull'></a>\n",
    "$$\n",
    "\\Phi_s = UW \\tag{6.18}\n",
    "$$\n",
    "\n",
    "和一个广义逆矩阵\n",
    "\n",
    "\n",
    "<a id='equation-eq-phisfullinv'></a>\n",
    "$$\n",
    "\\Phi_s^+ = W^{-1}U^\\top \\tag{6.19}\n",
    "$$\n",
    "\n",
    "[[Schmid, 2010](https://python.quantecon.org/zreferences.html#id27)]随后将方程[(6.17)](#equation-eq-dssebookrepr)表示为\n",
    "\n",
    "\n",
    "<a id='equation-eq-schmidrep'></a>\n",
    "$$\n",
    "\\overline X_{t+1} = \\Phi_s \\Lambda^t \\Phi_s^+ X_1 \\tag{6.20}\n",
    "$$\n",
    "\n",
    "基向量的分量$ \\hat b_t = W^{-1} U^\\top  X_t \\equiv \\Phi_s^+ X_t $是\n",
    "DMD**投影模态**。\n",
    "\n",
    "要理解为什么它们被称为**投影模态**，注意到\n",
    "\n",
    "$$\n",
    "\\Phi_s^+ = ( \\Phi_s^\\top  \\Phi_s)^{-1} \\Phi_s^\\top\n",
    "$$\n",
    "\n",
    "所以 $ m \\times p $ 的矩阵\n",
    "\n",
    "$$\n",
    "\\hat b =  \\Phi_s^+ X\n",
    "$$\n",
    "\n",
    "是 $ m \\times n $ 矩阵 $ X $ 在 $ m \\times p $ 矩阵 $ \\Phi_s $ 上的回归系数矩阵。\n",
    "\n",
    "我们将在讨论由 Tu 等人 [[Tu *et al.*, 2014](https://python.quantecon.org/zreferences.html#id36)] 提出的表示法3时进一步讨论。\n",
    "\n",
    "当我们想要使用简化SVD时（这在实践中经常出现），使用表示法3更为合适。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cbaffa",
   "metadata": {},
   "source": [
    "## 表示法3\n",
    "\n",
    "与构建表示法1和表示法2的程序不同（它们都使用了**完整**SVD），我们现在使用**简化**SVD。\n",
    "\n",
    "同样，令 $ p \\leq \\textrm{min}(m,n) $ 为 $ X $ 的秩。\n",
    "\n",
    "构造一个**简化**SVD\n",
    "\n",
    "$$\n",
    "X = \\tilde U \\tilde \\Sigma \\tilde V^\\top ,\n",
    "$$\n",
    "\n",
    "其中现在 $ \\tilde U $ 是 $ m \\times p $ 的矩阵，$ \\tilde \\Sigma $ 是 $ p \\times p $ 的矩阵，而 $ \\tilde V^\\top $ 是 $ p \\times n $ 的矩阵。\n",
    "\n",
    "我们的 $ A $ 的最小范数最小二乘近似器现在的表示为\n",
    "\n",
    "\n",
    "<a id='equation-eq-ahatwithtildes'></a>\n",
    "$$\n",
    "\\hat A = X' \\tilde V \\tilde \\Sigma^{-1} \\tilde U^\\top \\tag{6.21}\n",
    "$$\n",
    "\n",
    "**计算$ \\hat A $的主要特征向量**\n",
    "\n",
    "我们首先参照构建表示法1时使用的步骤，通过以下方式为旋转的$ p \\times 1 $状态$ \\tilde b_t $定义一个转移矩阵：\n",
    "\n",
    "\n",
    "<a id='equation-eq-atildered'></a>\n",
    "$$\n",
    "\\tilde A =\\tilde  U^\\top  \\hat A \\tilde U \\tag{6.22}\n",
    "$$\n",
    "\n",
    "**作为投影系数的解释**\n",
    "\n",
    "[[Brunton and Kutz, 2022](https://python.quantecon.org/zreferences.html#id51)]指出$ \\tilde A $可以被理解为$ \\hat A $在$ \\tilde U $中$ p $个模态上的投影。\n",
    "\n",
    "要验证这一点，首先注意到，由于$ \\tilde U^\\top  \\tilde U = I $，因此：\n",
    "\n",
    "\n",
    "<a id='equation-eq-tildeaverify'></a>\n",
    "$$\n",
    "\\tilde A = \\tilde U^\\top  \\hat A \\tilde U = \\tilde U^\\top  X' \\tilde V \\tilde \\Sigma^{-1} \\tilde U^\\top  \\tilde U \n",
    "= \\tilde U^\\top  X' \\tilde V \\tilde \\Sigma^{-1} \\tilde U^\\top \\tag{6.23}\n",
    "$$\n",
    "\n",
    "接下来，我们将使用标准最小二乘公式计算$ \\hat A $在$ \\tilde U $上的投影的回归系数\n",
    "\n",
    "$$\n",
    "(\\tilde U^\\top  \\tilde U)^{-1} \\tilde U^\\top  \\hat A = (\\tilde U^\\top  \\tilde U)^{-1} \\tilde U^\\top  X' \\tilde V \\tilde \\Sigma^{-1} \\tilde U^\\top  = \n",
    "\\tilde U^\\top  X' \\tilde V \\tilde \\Sigma^{-1} \\tilde U^\\top   = \\tilde A .\n",
    "$$\n",
    "\n",
    "至此，我们验证了$ \\tilde A $是$ \\hat A $在$ \\tilde U $上的最小二乘投影。\n",
    "\n",
    "**一个逆运算的挑战**\n",
    "\n",
    "因为我们使用的是简化SVD，所以$ \\tilde U \\tilde U^\\top  \\neq I $。\n",
    "\n",
    "因此，\n",
    "\n",
    "$$\n",
    "\\hat A \\neq \\tilde U \\tilde A \\tilde U^\\top ,\n",
    "$$\n",
    "\n",
    "所以我们不能简单地用$ \\tilde A $和$ \\tilde U $计算$ \\hat A $。\n",
    "\n",
    "**死胡同**\n",
    "\n",
    "我们可以先抱着最好的希望，继续构造$ p \\times p $矩阵$ \\tilde A $的特征分解：\n",
    "\n",
    "\n",
    "<a id='equation-eq-tildeaeigenred'></a>\n",
    "$$\n",
    "\\tilde A =  \\tilde  W  \\Lambda \\tilde  W^{-1} \\tag{6.24}\n",
    "$$\n",
    "\n",
    "其中$ \\Lambda $是包含$ p $个特征值的对角矩阵，$ \\tilde W $的列是对应的特征向量。\n",
    "\n",
    "仿照表示法2中的步骤，我们可以轻松计算出一个$ m \\times p $的矩阵\n",
    "\n",
    "\n",
    "<a id='equation-eq-phisred'></a>\n",
    "$$\n",
    "\\tilde \\Phi_s = \\tilde U \\tilde W \\tag{6.25}\n",
    "$$\n",
    "\n",
    "该矩阵对应到完整SVD中的[(6.18)](#equation-eq-phisfull)。\n",
    "\n",
    "此时，当$ \\hat A $由公式[(6.21)](#equation-eq-ahatwithtildes)给出时，计算$ \\hat A \\tilde \\Phi_s $很有意思：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\hat A \\tilde \\Phi_s & = (X' \\tilde V \\tilde \\Sigma^{-1} \\tilde U^\\top ) (\\tilde U \\tilde W) \\\\\n",
    "  & = X' \\tilde V \\tilde \\Sigma^{-1} \\tilde  W \\\\\n",
    "  & \\neq (\\tilde U \\tilde  W) \\Lambda \\\\\n",
    "  & = \\tilde \\Phi_s \\Lambda\n",
    "  \\end{aligned}\n",
    "$$\n",
    "\n",
    "$ \\hat A \\tilde \\Phi_s \\neq \\tilde \\Phi_s \\Lambda $意味着，与表示法2中的相应情况不同，$ \\tilde \\Phi_s = \\tilde U \\tilde W $的列**不是**$ \\hat A $对应于矩阵$ \\Lambda $对角线上特征值的特征向量。\n",
    "\n",
    "**一种可行的方法**\n",
    "\n",
    "我们继续寻找**能够**通过简化SVD计算的$ \\hat A $的特征向量，这里不妨定义一个$ m \\times p $的矩阵$ \\Phi $：\n",
    "\n",
    "\n",
    "<a id='equation-eq-phiformula'></a>\n",
    "$$\n",
    "\\Phi \\equiv \\hat A \\tilde \\Phi_s = X' \\tilde V \\tilde \\Sigma^{-1}  \\tilde  W \\tag{6.26}\n",
    "$$\n",
    "\n",
    "不难发现，$ \\Phi $的列**确实是**$ \\hat A $的特征向量。\n",
    "\n",
    "这是Tu等人[[Tu *et al.*, 2014](https://python.quantecon.org/zreferences.html#id36)]证明的一个结果，我们下面来介绍。\n",
    "\n",
    "**命题** $ \\Phi $的$ p $列是$ \\hat A $的特征向量。\n",
    "\n",
    "**证明：** 根据公式[(6.26)](#equation-eq-phiformula)，我们有\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "  \\hat A \\Phi & =  (X' \\tilde  V \\tilde  \\Sigma^{-1} \\tilde  U^\\top ) (X' \\tilde  V \\Sigma^{-1} \\tilde  W) \\cr\n",
    "  & = X' \\tilde V \\tilde  \\Sigma^{-1} \\tilde A \\tilde  W \\cr\n",
    "  & = X' \\tilde  V \\tilde  \\Sigma^{-1}\\tilde  W \\Lambda \\cr\n",
    "  & = \\Phi \\Lambda \n",
    "  \\end{aligned}\n",
    "$$\n",
    "\n",
    "因此\n",
    "\n",
    "\n",
    "<a id='equation-eq-aphilambda'></a>\n",
    "$$\n",
    "\\hat A \\Phi = \\Phi \\Lambda \\tag{6.27}\n",
    "$$\n",
    "\n",
    "令 $ \\phi_i $ 为 $ \\Phi $ 的第 $ i $ 列，$ \\lambda_i $ 为分解式 [(6.24)](#equation-eq-tildeaeigenred) 中 $ \\tilde A $ 对应的第 $ i $ 个特征值。\n",
    "\n",
    "将等式 [(6.27)](#equation-eq-aphilambda) 两边的 $ m \\times 1 $ 向量对应项相等得到：\n",
    "\n",
    "$$\n",
    "\\hat A \\phi_i = \\lambda_i \\phi_i .\n",
    "$$\n",
    "\n",
    "这个等式证实了 $ \\phi_i $ 是 $ \\hat A $ 的特征向量，对应于 $ \\tilde A $ 和 $ \\hat A $ 的特征值 $ \\lambda_i $。\n",
    "\n",
    "证明至此完成。\n",
    "\n",
    "另见 [[Brunton and Kutz, 2022](https://python.quantecon.org/zreferences.html#id51)] (第238页)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f46266",
   "metadata": {},
   "source": [
    "### $ \\check b $ 的解码器作为线性投影\n",
    "\n",
    "根据特征分解 [(6.27)](#equation-eq-aphilambda) ，我们可以将 $ \\hat A $ 表示为：\n",
    "\n",
    "\n",
    "<a id='equation-eq-aform12'></a>\n",
    "$$\n",
    "\\hat A = \\Phi \\Lambda \\Phi^+ . \\tag{6.28}\n",
    "$$\n",
    "\n",
    "从公式 [(6.28)](#equation-eq-aform12) 我们可以推导出 $ p \\times 1 $ 向量 $ \\check b_t $ 的动态：\n",
    "\n",
    "$$\n",
    "\\check b_{t+1} = \\Lambda \\check b_t\n",
    "$$\n",
    "\n",
    "其中\n",
    "\n",
    "\n",
    "<a id='equation-eq-decoder102'></a>\n",
    "$$\n",
    "\\check b_t  = \\Phi^+ X_t \\tag{6.29}\n",
    "$$\n",
    "\n",
    "由于 $ m \\times p $ 矩阵 $ \\Phi $ 有 $ p $ 个线性独立的列，$ \\Phi $ 的广义逆矩阵为\n",
    "\n",
    "$$\n",
    "\\Phi^{+} = (\\Phi^\\top  \\Phi)^{-1} \\Phi^\\top\n",
    "$$\n",
    "\n",
    "因此\n",
    "\n",
    "\n",
    "<a id='equation-eq-checkbform'></a>\n",
    "$$\n",
    "\\check b = (\\Phi^\\top  \\Phi)^{-1} \\Phi^\\top  X \\tag{6.30}\n",
    "$$\n",
    "\n",
    "$ p \\times n $ 矩阵 $ \\check b $ 可以被视为是 $ m \\times n $ 的矩阵 $ X $ 在 $ m \\times p $ 的矩阵 $ \\Phi $ 上的最小二乘回归系数矩阵，因此\n",
    "\n",
    "\n",
    "<a id='equation-eq-xcheck'></a>\n",
    "$$\n",
    "\\check X = \\Phi \\check b \\tag{6.31}\n",
    "$$\n",
    "\n",
    "是 $ X $ 在 $ \\Phi $ 上的最小二乘投影的 $ m \\times n $ 矩阵。\n",
    "\n",
    "**$ X $ 的方差分解**\n",
    "\n",
    "根据这个 QuantEcon 讲座 [https://python-advanced.quantecon.org/orth_proj.html](https://python-advanced.quantecon.org/orth_proj.html) 中讨论的最小二乘的投影理论，我们可以将 $ X $ 表示为 $ X $ 在 $ \\Phi $ 上的投影 $ \\check X $ 和误差矩阵的和。\n",
    "\n",
    "要验证这一点，注意到最小二乘投影 $ \\check X $ 与 $ X $ 的关系是\n",
    "\n",
    "$$\n",
    "X = \\check X + \\epsilon\n",
    "$$\n",
    "\n",
    "或\n",
    "\n",
    "\n",
    "<a id='equation-eq-xbcheck'></a>\n",
    "$$\n",
    "X = \\Phi \\check b + \\epsilon \\tag{6.32}\n",
    "$$\n",
    "\n",
    "其中 $ \\epsilon $ 是一个 $ m \\times n $ 的最小二乘误差矩阵，满足最小二乘正交条件 $ \\epsilon^\\top \\Phi =0 $ 或\n",
    "\n",
    "\n",
    "<a id='equation-eq-orthls'></a>\n",
    "$$\n",
    "(X - \\Phi \\check b)^\\top \\Phi = 0_{m \\times p} \\tag{6.33}\n",
    "$$\n",
    "\n",
    "重新整理正交条件 [(6.33)](#equation-eq-orthls) 得到 $ X^\\top \\Phi = \\check b \\Phi^\\top \\Phi $，这就推导出公式 [(6.30)](#equation-eq-checkbform)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef3bb17",
   "metadata": {},
   "source": [
    "### 一种近似方法\n",
    "\n",
    "我们现在描述一种不使用公式 [(6.29)](#equation-eq-decoder102)的近似计算 $ p \\times 1 $ 的向量 $ \\check b_t $ 的方法。\n",
    "\n",
    "具体来说，以下论述改编自 [[Brunton and Kutz, 2022](https://python.quantecon.org/zreferences.html#id51)]（第240页）提供的一种高效计算方法，从而近似 $ \\check b_t $。\n",
    "\n",
    "为方便起见，我们将在时间 $ t=1 $ 应用该方法。\n",
    "\n",
    "对于 $ t=1 $，根据方程 [(6.32)](#equation-eq-xbcheck)，我们有\n",
    "\n",
    "\n",
    "<a id='equation-eq-x1proj'></a>\n",
    "$$\n",
    "\\check X_1 = \\Phi \\check b_1 \\tag{6.34}\n",
    "$$\n",
    "\n",
    "其中 $ \\check b_1 $ 是一个 $ p \\times 1 $ 的向量。\n",
    "\n",
    "回顾上面表示1中的 $ X_1 = U \\tilde b_1 $,其中 $ \\tilde b_1 $ 是表示1的时间1基向量,而 $ U $ 来自完整SVD分解 $ X = U \\Sigma V^\\top $。\n",
    "\n",
    "从方程 [(6.32)](#equation-eq-xbcheck) 可以得出:\n",
    "\n",
    "$$\n",
    "U \\tilde b_1 = X' \\tilde V \\tilde \\Sigma^{-1} \\tilde  W \\check b_1 + \\epsilon_1\n",
    "$$\n",
    "\n",
    "其中 $ \\epsilon_1 $ 是方程 [(6.32)](#equation-eq-xbcheck) 中的最小二乘误差向量。\n",
    "\n",
    "因此可得:\n",
    "\n",
    "$$\n",
    "\\tilde b_1 = U^\\top  X' V \\tilde \\Sigma^{-1} \\tilde W \\check b_1 + U^\\top  \\epsilon_1\n",
    "$$\n",
    "\n",
    "将误差项 $ U^\\top  \\epsilon_1 $ 替换为零,并将完整SVD中的 $ U $ 替换为简化SVD中的 $ \\tilde U $,我们得到 $ \\tilde b_1 $ 的近似值 $ \\hat b_1 $:\n",
    "\n",
    "$$\n",
    "\\hat b_1 = \\tilde U^\\top  X' \\tilde V \\tilde \\Sigma^{-1} \\tilde  W \\check b_1\n",
    "$$\n",
    "\n",
    "回顾方程 [(6.23)](#equation-eq-tildeaverify) 中的 $ \\tilde A = \\tilde U^\\top  X' \\tilde V \\tilde \\Sigma^{-1} $。\n",
    "\n",
    "因此可得:\n",
    "\n",
    "$$\n",
    "\\hat  b_1 = \\tilde   A \\tilde W \\check b_1\n",
    "$$\n",
    "\n",
    "因此，根据 $ \\tilde A $ 的特征分解 [(6.24)](#equation-eq-tildeaeigenred)，我们有\n",
    "\n",
    "$$\n",
    "\\hat b_1 = \\tilde W \\Lambda \\check b_1\n",
    "$$\n",
    "\n",
    "因此，\n",
    "\n",
    "$$\n",
    "\\hat b_1 = ( \\tilde W \\Lambda)^{-1} \\tilde b_1\n",
    "$$\n",
    "\n",
    "或者\n",
    "\n",
    "\n",
    "<a id='equation-eq-beqnsmall'></a>\n",
    "$$\n",
    "\\hat b_1 = ( \\tilde W \\Lambda)^{-1} \\tilde U^\\top  X_1 , \\tag{6.35}\n",
    "$$\n",
    "\n",
    "这是对以下方程 [(6.29)](#equation-eq-decoder102) 中初始向量 $ \\check b_1 $ 的计算效率较高的近似：\n",
    "\n",
    "\n",
    "<a id='equation-eq-bphieqn'></a>\n",
    "$$\n",
    "\\check b_1= \\Phi^{+} X_1 \\tag{6.36}\n",
    "$$\n",
    "\n",
    "（为了强调 [(6.35)](#equation-eq-beqnsmall) 是一个近似值，DMD的使用者有时将基向量 $ \\check b_t  = \\Phi^+ X_t $ 的分量称为**精确**DMD模态，将 $ \\hat b_t = ( \\tilde W \\Lambda)^{-1} \\tilde U^\\top  X_t $ 的分量称为**近似**模态。）\n",
    "\n",
    "在给定 $ X_t $ 的条件下，我们可以通过精确模态计算解码后的 $ \\check X_{t+j},   j = 1, 2, \\ldots $ ：\n",
    "\n",
    "\n",
    "<a id='equation-eq-checkxevoln'></a>\n",
    "$$\n",
    "\\check X_{t+j} = \\Phi \\Lambda^j \\Phi^{+} X_t \\tag{6.37}\n",
    "$$\n",
    "\n",
    "或者通过近似模态计算解码的 $ \\hat X_{t+j} $:\n",
    "\n",
    "\n",
    "<a id='equation-eq-checkxevoln2'></a>\n",
    "$$\n",
    "\\hat X_{t+j} = \\Phi \\Lambda^j (\\tilde W \\Lambda)^{-1}  \\tilde U^\\top  X_t . \\tag{6.38}\n",
    "$$\n",
    "\n",
    "然后我们可以使用解码后的 $ \\check X_{t+j} $ 或 $ \\hat X_{t+j} $ 来预测 $ X_{t+j} $。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032b35cb",
   "metadata": {},
   "source": [
    "### 使用更少的模态\n",
    "\n",
    "在实际应用中，我们通常只使用少数几个模态，通常不多于三个。\n",
    "\n",
    "前面的一些公式假设中，我们保留了与 $ X $ 的奇异值相关的所有 $ p $ 个模态。\n",
    "\n",
    "我们可以调整公式，描述只保留 $ r < p $ 个最大奇异值的情况。\n",
    "\n",
    "在这种情况下，我们只需将 $ \\tilde \\Sigma $ 替换为相应的 $ r\\times r $ 奇异值矩阵，将 $ \\tilde U $ 替换为对应于 $ r $ 个最大奇异值的 $ m \\times r $ 的矩阵，将 $ \\tilde V $ 替换为对应于 $ r $ 个最大奇异值的 $ n \\times r $ 的矩阵。\n",
    "\n",
    "上述所有重要公式都有其对应的形式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63526f9c",
   "metadata": {},
   "source": [
    "## Python代码来源\n",
    "\n",
    "你可以在[这里](https://mathlab.sissa.it/pydmd)找到DMD的Python实现。"
   ]
  }
 ],
 "metadata": {
  "date": 1761257076.7286055,
  "filename": "var_dmd.md",
  "kernelspec": {
   "display_name": "Python",
   "language": "python3",
   "name": "python3"
  },
  "title": "向量自回归和动态模态分解"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}